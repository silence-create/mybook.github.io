<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/mybook.github.io/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/mybook.github.io/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/mybook.github.io/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/mybook.github.io/images/logo.svg" color="#222">

<link rel="stylesheet" href="/mybook.github.io/css/main.css">


<link rel="stylesheet" href="/mybook.github.io/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"silence-create.github.io","root":"/mybook.github.io/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":true,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":true,"preload":true},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="依只若只的博客">
<meta property="og:url" content="https://silence-create.github.io/mybook.github.io/xxxxxx/index.html">
<meta property="og:site_name" content="依只若只的博客">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="徐川">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://silence-create.github.io/mybook.github.io/xxxxxx/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>依只若只的博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/mybook.github.io/atom.xml" title="依只若只的博客" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/mybook.github.io/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">依只若只的博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">程序员技术栈</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/mybook.github.io/home/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/mybook.github.io/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://silence-create.github.io/mybook.github.io/2024/05/20/C++/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/mybook.github.io/images/avatar.gif">
      <meta itemprop="name" content="徐川">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="依只若只的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/mybook.github.io/2024/05/20/C++/" class="post-title-link" itemprop="url">C++</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-05-20 12:01:11 / 修改时间：14:11:59" itemprop="dateCreated datePublished" datetime="2024-05-20T12:01:11+08:00">2024-05-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h1><h2 id="C-C-内存分布"><a href="#C-C-内存分布" class="headerlink" title="C&#x2F;C++内存分布"></a>C&#x2F;C++内存分布</h2><p>BSS段（bss）：通常是指用来存放程序中未初始化的全局变量的一块内存区域。BSS段属于静态内存分配。<br>数据段（data）：通常是指用来存放程序中已初始化的全局变量的一块内存区域。数据段属于静态内存分配。<br>全局数据区(静态存储区)：全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域，未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。程序结束释放。<br>代码段（code &#x2F;text）：通常是指用来存放程序执行代码的一块内存区域。这部分区域的大小在程序运行前就已经确定，并且内存区域通常属于只读, 某些架构也允许代码段为可写，即允许修改程序。在代码段中，也有可能包含一些只读的常数变量，例如字符串常量等。<br>堆（heap）：堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减。当进程调用malloc等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）；当利用free等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减）<br>栈(stack)：存放函数的局部变量、函数参数、返回地址等，由编译器自动分配和释放，是用户存放程序临时创建的局部变量，也就是说我们函数括弧“{}”中定义的变量（但不包括static声明的变量，static意味着在数据段中存放变量）。除此以外，在函数被调用时，其参数也会被压入发起调用的进程栈中，并且待到调用结束后，函数的返回值也会被存放回栈中。由于栈的先进先出特点，所以栈特别方便用来保存&#x2F;恢复调用现场。从这个意义上讲，我们可以把堆栈看成一个寄存、交换临时数据的内存区。<br>从操作系统的本身来讲，以上存储区在内存中的分布是如下形式(从低地址到高地址)：.text 段 –&gt; .data 段 –&gt; .bss 段 –&gt; 堆 –&gt; unused –&gt; 栈 –&gt; env</p>
<h1 id="—————–请稍等———————–"><a href="#—————–请稍等———————–" class="headerlink" title="—————–请稍等———————–"></a>—————–请稍等———————–</h1><link rel="stylesheet" href="/mybook.github.io/css/spoiler.css" type="text/css"><script src="/mybook.github.io/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://silence-create.github.io/mybook.github.io/2024/05/20/Go/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/mybook.github.io/images/avatar.gif">
      <meta itemprop="name" content="徐川">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="依只若只的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/mybook.github.io/2024/05/20/Go/" class="post-title-link" itemprop="url">Golang</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-05-20 12:01:11 / 修改时间：14:12:14" itemprop="dateCreated datePublished" datetime="2024-05-20T12:01:11+08:00">2024-05-20</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Golang"><a href="#Golang" class="headerlink" title="Golang"></a>Golang</h1><h2 id="数值（-16-个）"><a href="#数值（-16-个）" class="headerlink" title="数值（ 16 个）"></a>数值（ 16 个）</h2><h3 id="整型（-12-个）"><a href="#整型（-12-个）" class="headerlink" title="整型（ 12 个）"></a>整型（ 12 个）</h3><p>byte int int8 int16 int32 int64 </p>
<p>uint unint8 uint16 uint32 uint64 uintprt </p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center">uint8</td>
<td align="center">0 到 255</td>
</tr>
<tr>
<td align="center">uint16</td>
<td align="center">0 到 65535</td>
</tr>
<tr>
<td align="center">uint32</td>
<td align="center">0 到 4294967295</td>
</tr>
<tr>
<td align="center">unit64</td>
<td align="center">(0 到 18446744073709551615)</td>
</tr>
<tr>
<td align="center">int8</td>
<td align="center">-128 到 127</td>
</tr>
<tr>
<td align="center">int16</td>
<td align="center">-32768 到 32767</td>
</tr>
<tr>
<td align="center">int32</td>
<td align="center">-2147483648 到 2147483647</td>
</tr>
<tr>
<td align="center">int64</td>
<td align="center">(-9223372036854775808 到 9223372036854775807)</td>
</tr>
</tbody></table>
<h3 id="浮点型（-2个）"><a href="#浮点型（-2个）" class="headerlink" title="浮点型（ 2个）"></a>浮点型（ 2个）</h3><p>float32 float64 </p>
<h3 id="复数型（-2个）"><a href="#复数型（-2个）" class="headerlink" title="复数型（ 2个）"></a>复数型（ 2个）</h3><p>complex64    complex128 </p>
<h3 id="字符和字符串型（-2个）"><a href="#字符和字符串型（-2个）" class="headerlink" title="字符和字符串型（ 2个）"></a>字符和字符串型（ 2个）</h3><p>string   rune </p>
<h3 id="接口型（-1个）"><a href="#接口型（-1个）" class="headerlink" title="接口型（ 1个）"></a>接口型（ 1个）</h3><p>error </p>
<h3 id="布尔型（1个）"><a href="#布尔型（1个）" class="headerlink" title="布尔型（1个）"></a>布尔型（1个）</h3><p>bool </p>
<p>token 是构成源程序的基本不可再分割的单元。</p>
<p>变量表示指向的内存可以被修改，常量表示指向的内存不能被修改。</p>
<p>需要注意的是 { 不能单独放在一行，在运行时会产生错误</p>
<p>字符串是常量，可以通过类 数组 索引访问其字节单元，但是不能修改某个字节的值。</p>
<p>Go语言基本的复合数据类型有指针、数组、切片、字典（ map ）、通道、结构和接口，它们的字面量格式如下&#96;</p>
<p> :&#x3D; 是一个声明语句。intVal :&#x3D; 1 相等于：</p>
<p>Go 函数可以返回多个值</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">var intVal int </span><br><span class="line">intVal =1 </span><br></pre></td></tr></table></figure>

<p>可以将 var f string &#x3D; “Runoob” 简写为 f :&#x3D; “Runoob”：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pointerType  	／／指针类型使用＊后面跟其指向的类型名</span><br><span class="line">[n] elementType 	／／数纽类型使用［ ）后面跟数纽元素类型来表示， 表示该数组的长度</span><br><span class="line">[] elementType 		／／ 切片类型使用［］后面跟切片元素类型来表示</span><br><span class="line">map [keyType)valueType 	//map 类型使用 map ［键类型］值类型来表</span><br><span class="line">chan valueType 	／／通道使 ch an 后面跟远远元素类型来表示</span><br><span class="line">struct &#123; 	／／结构类型使 str uct ｛｝将各个结构字段扩起来表示</span><br><span class="line">    feildType feildType</span><br><span class="line">    feildType feildType </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">interface ｛／／接 口类型使用 interface ｛｝将各个方法括起来表示</span><br><span class="line">methodl ( inputParams) ( returnParams)</span><br><span class="line">method2 (inputParams) (returnParams)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="———-请稍等————–"><a href="#———-请稍等————–" class="headerlink" title="———-请稍等————–"></a>———-请稍等————–</h1><link rel="stylesheet" href="/mybook.github.io/css/spoiler.css" type="text/css"><script src="/mybook.github.io/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://silence-create.github.io/mybook.github.io/2024/05/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/mybook.github.io/images/avatar.gif">
      <meta itemprop="name" content="徐川">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="依只若只的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/mybook.github.io/2024/05/17/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">计算机网络</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2024-05-17 15:44:23 / 修改时间：15:18:29" itemprop="dateCreated datePublished" datetime="2024-05-17T15:44:23+08:00">2024-05-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="OSI七层模型-TCP-IP五层网络模型"><a href="#OSI七层模型-TCP-IP五层网络模型" class="headerlink" title="OSI七层模型&amp;TCP&#x2F;IP五层网络模型"></a>OSI七层模型&amp;TCP&#x2F;IP五层网络模型</h1><p><img data-src="/mybook.github.io/4214940125131.png"></p>
<p><img data-src="/mybook.github.io/399031810246845.png"></p>
<p><strong>传输层，给应⽤数据前⾯增加了 TCP 头；⽹络层，给 TCP 数据包前⾯增加了 IP 头；⽹络接⼝层，给 IP 数据包前后分别增加了帧头和帧尾；</strong><br><strong>网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。</strong></p>
<h1 id="输入网址到网页显示，期间发生了什么？"><a href="#输入网址到网页显示，期间发生了什么？" class="headerlink" title="输入网址到网页显示，期间发生了什么？"></a>输入网址到网页显示，期间发生了什么？</h1><p><img data-src="/mybook.github.io/520723210259680.png"></p>
<h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><p><strong>解析URL</strong><br>当没有路径名时，就代表访问根目录下事先设置的默认文件，也就是 &#x2F;index.html 或者 &#x2F;default.html</p>
<p><img data-src="/mybook.github.io/16953510256235.png"></p>
<p><strong>生成HTTP请求</strong></p>
<p><img data-src="/mybook.github.io/398233710251989.png"></p>
<h2 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h2><p>在这一流程中，<strong>需要查询服务器域名对应的 IP 地址</strong>，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。在域名中，越靠右的位置表示其层级越高。</p>
<ul>
<li>根 DNS 服务器（.）</li>
<li>顶级域 DNS 服务器（.com）</li>
<li>权威 DNS 服务器（server.com）</li>
</ul>
<p><img data-src="/mybook.github.io/186484410269869.png"></p>
<p>DNS 域名解析，只指路不带路。浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」。</p>
<p>流程示例：<br>客户端-&gt;缓存-&gt;本地DNS服务器-&gt;根域服务器(.)-&gt;顶级域名服务器(.com)-&gt;权威DNS服务器(server.com)</p>
<p>通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的协议栈。</p>
<p><img data-src="/mybook.github.io/589825710267473.png"></p>
<h2 id="TCP和UDP"><a href="#TCP和UDP" class="headerlink" title="TCP和UDP"></a>TCP和UDP</h2><p>如果 HTTP 请求消息比较长，超过了<strong>MSS(TCP 最大报文段长度)</strong> ，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。这样即使中途有一个分块丢失或损坏了，只需要重新发送这一个分块，而不用重新发送整个数据包。在 TCP 协议中，我们把每个分块称为一个 TCP 段（TCP Segment）</p>
<p><img data-src="/mybook.github.io/411031010258978.png"></p>
<p>至此，网络报文如图：</p>
<p><img data-src="/mybook.github.io/483730811241294.png"></p>
<h2 id="IP"><a href="#IP" class="headerlink" title="IP"></a>IP</h2><p>网络层负责将数据从一个设备传输到另一个设备，该如何找到对方呢？因此，网络层需要有区分设备的编号。一般用 IP 地址给设备进行编号，对于 IPv4 协议， IP 地址共 32 位，分成了四段（比如，192.168.100.1），每段是 8 位。只有一个单纯的 IP 地址虽然做到了区分设备，但是寻址起来就特别麻烦，全世界那么多台设备，难道一个一个去匹配？这显然不科学。</p>
<p>因此，需要将 IP 地址分成两种意义：<br>一个是网络号，负责标识该 IP 地址是属于哪个「子网」的；<br>一个是主机号，负责标识同一「子网」下的不同主机；</p>
<p>需要配合子网掩码才能算出 IP 地址 的网络号和主机号。10.100.122.0&#x2F;24，后面的&#x2F;24表示就是 255.255.255.0 子网掩码，255.255.255.0 二进制是「11111111-11111111-11111111-00000000」，为了简化子网掩码的表示，用&#x2F;24代替255.255.255.0。将 10.100.122.2 和 255.255.255.0 进行按位与运算，就可以得到网络号，</p>
<p>因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的协议号，要填写为 06（十六进制），表示协议为 TCP</p>
<p><img data-src="/mybook.github.io/240855510268045.png"></p>
<p>IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 <strong>MTU(以太网中一般为 1500 字节)</strong> 就会再次进行分片，得到一个即将发送到网络的 IP 报文。</p>
<p><img data-src="/mybook.github.io/471094610250257.png"></p>
<p>至此，网络报文如图：</p>
<p><img data-src="/mybook.github.io/146291011252832.png"></p>
<h2 id="MAC"><a href="#MAC" class="headerlink" title="MAC"></a>MAC</h2><p>生成了 IP 头部之后，接下来要交给网络接口层（Link Layer）在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。</p>
<p><img data-src="/mybook.github.io/442861411243551.png"></p>
<p>电脑上的以太网接口，Wi-Fi接口，以太网交换机、路由器上的千兆，万兆以太网口，还有网线，它们都是以太网的组成部分。所以说，网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。</p>
<p>IP 头部中的接收方 IP 地址表示网络包的目的地，通过这个地址我们就可以判断要将包发到哪里，但在以太网的世界中，这个思路是行不通的。以太网在判断网络包目的地时和 IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到 MAC 地址。MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。</p>
<p><img data-src="/mybook.github.io/557811511262706.png"></p>
<p>ARP 协议会在以太网中以广播的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。</p>
<p>操作系统会把本次查询结果放到一块叫做 ARP 缓存的内存空间留着以后用，不过缓存的时间就几分钟。在发包时先查询 ARP 缓存，如果其中已经保存了对方的 MAC 地址，就不需要发送 ARP 查询，直接使用 ARP 缓存中的地址。而当 ARP 缓存中不存在对方 MAC 地址时，则发送 ARP 广播查询。</p>
<p>一般在 TCP&#x2F;IP 通信里，MAC 包头的协议类型只使用：0800 ： IP 协议，0806 ： ARP 协议</p>
<p>至此，网络报文如图：</p>
<p><img data-src="/mybook.github.io/189722011242358.png"></p>
<h2 id="网卡"><a href="#网卡" class="headerlink" title="网卡"></a>网卡</h2><p>网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，<strong>在末尾加上用于检测错误的帧校验序列</strong>。</p>
<p><img data-src="/mybook.github.io/291732611240804.png"></p>
<h2 id="交换机"><a href="#交换机" class="headerlink" title="交换机"></a>交换机</h2><p>交换机的设计是将网络包原样转发到目的地。交换机工作在 MAC 层，也称为二层网络设备。<strong>交换机的端口不具有 MAC 地址</strong>。交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。</p>
<p>交换机的 MAC 地址表主要包含两个信息：<br>一个是设备的 MAC 地址，另一个是该设备连接在交换机的哪个端口上。</p>
<p><img data-src="/mybook.github.io/352223211270622.png"></p>
<p>交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口，如果交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。</p>
<h2 id="路由器"><a href="#路由器" class="headerlink" title="路由器"></a>路由器</h2><p>路由器是基于 IP 设计的，俗称三层网络设备，<strong>路由器的各个端口都具有 MAC 地址和 IP 地址</strong>；<br>而交换机是基于以太网设计的，俗称二层网络设备，<strong>交换机的端口不具有 MAC 地址</strong>。</p>
<p>路由器的端口具有 MAC 地址，因此它就能够成为以太网的发送方和接收方；同时还具有 IP 地址，从这个意义上来说，它和计算机的网卡是一样的。当转发包时，首先路由器端口会接收发给自己的以太网包，然后路由表查询转发目标，再由相应的端口作为发送方将以太网包发送出去。</p>
<p><strong>完成包接收操作之后，路由器就会去掉包开头的 MAC 头部</strong>。MAC 头部的作用就是将包送达路由器，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。</p>
<p><img data-src="/mybook.github.io/72064011249556.png"></p>
<p>根据路由表的网关列判断对方的地址。<br>如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，还未抵达终点，还需继续需要路由器转发。<br>如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明已抵达终点。</p>
<p>在网络包传输的过程中，<strong>源 IP 和目标 IP 始终是不会变的</strong>，一直变化的是 MAC 地址，<strong>因为需要 MAC 地址在以太网内进行两个设备之间的包传输</strong>。</p>
<h2 id="服务器与客户端"><a href="#服务器与客户端" class="headerlink" title="服务器与客户端"></a>服务器与客户端</h2><p><img data-src="/mybook.github.io/322135509240558.png"></p>
<h1 id="TCP和UDP-1"><a href="#TCP和UDP-1" class="headerlink" title="TCP和UDP"></a>TCP和UDP</h1><h2 id="UDP与TCP比较"><a href="#UDP与TCP比较" class="headerlink" title="UDP与TCP比较"></a>UDP与TCP比较</h2><table>
<thead>
<tr>
<th align="center">特点</th>
<th align="center">TCP</th>
<th align="center">UDP</th>
</tr>
</thead>
<tbody><tr>
<td align="center">连接</td>
<td align="center">面向连接</td>
<td align="center">不需要连接，即刻传输</td>
</tr>
<tr>
<td align="center">服务对象</td>
<td align="center">一对一</td>
<td align="center">一对一、一对多、多对多</td>
</tr>
<tr>
<td align="center">可靠性</td>
<td align="center">可靠交付数据，数据可以无差错、不丢失、不重复、按序到达</td>
<td align="center">尽最大努力交付数据，不保证可靠交付数据</td>
</tr>
<tr>
<td align="center">拥塞控制、流量控制</td>
<td align="center">有</td>
<td align="center">没有</td>
</tr>
<tr>
<td align="center">首部开销</td>
<td align="center">没有使用「选项」字段时是 20 个字节，较长</td>
<td align="center">8 个字节，较小</td>
</tr>
<tr>
<td align="center">传输方式</td>
<td align="center">流式传输,保证顺序和可靠</td>
<td align="center">一个包一个包的发送，有边界，可能丢包和乱序</td>
</tr>
<tr>
<td align="center">分片不同</td>
<td align="center">大于MSS大小，在传输层进行分片，丢失了一个分片，只需要传输丢失的这个分片</td>
<td align="center">大于 MTU 大小在IP层进行分片</td>
</tr>
</tbody></table>
<h2 id="UDP"><a href="#UDP" class="headerlink" title="UDP"></a>UDP</h2><h3 id="UDP头部"><a href="#UDP头部" class="headerlink" title="UDP头部"></a>UDP头部</h3><p><img data-src="/mybook.github.io/1340921605603.png"></p>
<ol>
<li>⽬标和源端⼝：主要是告诉 UDP 协议应该把报⽂发给哪个进程。</li>
<li>包⻓度：该字段保存了 UDP ⾸部的⻓度跟数据的⻓度之和。</li>
<li>校验和：校验和是为了提供可靠的 UDP 首部和数据而设计，防止收到在网络传输中受损的 UDP 包。</li>
</ol>
<h3 id="UDP特点"><a href="#UDP特点" class="headerlink" title="UDP特点"></a>UDP特点</h3><ol>
<li><strong>面向无连接</strong><br>首先 UDP 是不需要和 TCP一样在发送数据前进行三次握手建立连接的，想发数据就可以开始发送了。并且也只是数据报文的搬运工，不会对数据报文进行任何拆分和拼接操作。<br>在发送端，应用层将数据传递给传输层的 UDP 协议，UDP 只会给数据增加一个 UDP 头标识下是 UDP 协议，然后就传递给网络层了<br>在接收端，网络层将数据传递给传输层，UDP 只去除 IP 报文头就传递给应用层，不会任何拼接操作</li>
<li><strong>有单播，多播，广播的功能</strong><br>UDP 不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说 UDP 提供了单播，多播，广播的功能。</li>
<li><strong>UDP是面向报文的</strong><br>发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付IP层。UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。因此，应用程序必须选择合适大小的报文</li>
<li><strong>不可靠性</strong><br>首先不可靠性体现在无连接上，通信都不需要建立连接，想发就发，这样的情况肯定不可靠。并且收到什么数据就传递什么数据，并且也不会备份数据，发送数据也不会关心对方是否已经正确接收到数据了。<br>再者网络环境时好时坏，但是 UDP 因为没有拥塞控制，一直会以恒定的速度发送数据。即使网络条件不好，也不会对发送速率进行调整。这样实现的弊端就是在网络条件不好的情况下可能会导致丢包，但是优点也很明显，在某些实时性要求高的场景（比如电话会议）就需要使用 UDP 而不是 TCP。</li>
<li><strong>头部开销小，传输数据报文时是很高效的</strong><br>因此 UDP 的头部开销小，只有八字节，相比 TCP 的至少二十字节要少得多，在传输数据报文时是很高效的</li>
</ol>
<h2 id="TCP"><a href="#TCP" class="headerlink" title="TCP"></a>TCP</h2><h3 id="TCP头部"><a href="#TCP头部" class="headerlink" title="TCP头部"></a>TCP头部</h3><p><img data-src="/mybook.github.io/2092909816511.png"></p>
<ol>
<li>序列号：在建⽴连接时由计算机⽣成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送⼀次数据，就「累加」⼀次该「数据字节数」的⼤⼩。⽤来解决⽹络包乱序问题。</li>
<li>确认应答号：指下⼀次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。⽤来解决丢包的问题。</li>
<li>头部长度:标识该TCP头部有多少个32bit字(4字节)。4位最大能表示15，所以TCP头部最长是60字节。</li>
<li>窗口大小：是TCP流量控制的一个手段。它告诉对方本段的TCP接受缓冲区的情况，控制对方的发送的速度。</li>
<li>校验和：由发送端填充，接收端对TCP报文端执行CRC算法以校验TCP报文段在传输过程是否损坏。(数据和头部全部校验的。)</li>
<li>紧急指针：发送端向接受端发送紧急数据使用的。</li>
<li>控制位：</li>
</ol>
<ul>
<li>URG：表示紧急指针是否有效</li>
<li>ACK：该位为 1 时，「确认应答」的字段变为有效，TCP 规定除了最初建⽴连接时的 SYN 包之外该位必须设置为 1 。</li>
<li>RST：该位为 1 时，表示 TCP 连接中出现异常必须强制断开连接</li>
<li>PSH：提示接收端应用程序应该立即从TCP接受缓冲区读走数据，为之后的接受的数据腾出位置。</li>
<li>SYN：该位为 1 时，表示希望建⽴连接，并在其「序列号」的字段进⾏序列号初始值的设定。</li>
<li>FIN：该位为 1 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双⽅的主机之间就可以相互交换 FIN 位为 1 的 TCP 段。</li>
</ul>
<h3 id="TCP特点"><a href="#TCP特点" class="headerlink" title="TCP特点"></a>TCP特点</h3><ol>
<li><strong>面向连接</strong><br>面向连接，是指发送数据之前必须在两端建立连接。建立连接的方法是“三次握手”，这样能建立可靠的连接。建立连接，是为数据的可靠传输打下了基础。</li>
<li><strong>仅支持单播传输</strong><br>每条TCP传输连接只能有两个端点，只能进行点对点的数据传输，不支持多播和广播传输方式。</li>
<li><strong>面向字节流</strong><br>TCP不像UDP一样那样一个个报文独立地传输，而是在不保留报文边界的情况下以字节流方式进行传输。<br>消息是「没有边界」的，所以⽆论我们消息有多⼤都可以进⾏传输。并且消息是「有序的」，当「前⼀个」消息没有收到的时候，即使它先收到了后⾯的字节，那么也不能扔给应⽤层去处理，同时对「重复」的报⽂会⾃动丢弃。</li>
<li><strong>可靠传输</strong><br>对于可靠传输，判断丢包，误码靠的是TCP的段编号以及确认号。TCP为了保证报文传输的可靠，就给每个包一个序号，同时序号也保证了传送到接收端实体的包的按序接收。然后接收端实体对已成功收到的字节发回一个相应的确认(ACK)；如果发送端实体在合理的往返时延(RTT)内未收到确认，那么对应的数据（假设丢失了）将会被重传。</li>
<li><strong>提供拥塞控制</strong><br>当网络出现拥塞的时候，TCP能够减小向网络注入数据的速率和数量，缓解拥塞</li>
<li><strong>TCP提供全双工通信</strong><br>TCP允许通信双方的应用程序在任何时候都能发送数据，因为TCP连接的两端都设有缓存，用来临时存放双向通信的数据。当然，TCP可以立即发送一个数据段，也可以缓存一段时间以便一次发送更多的数据段（最大的数据段大小取决于MSS）</li>
</ol>
<h3 id="TCP四元组"><a href="#TCP四元组" class="headerlink" title="TCP四元组"></a>TCP四元组</h3><p><strong>TCP 四元组可以唯一的确定一个连接</strong>，四元组包括如下：<br>源地址、源端口、目的地址、目的端口</p>
<p>源地址和目的地址的字段（32 位）是在 IP 头部中，作用是通过 IP 协议发送报文给对方主机。<br>源端口和目的端口的字段（16 位）是在 TCP 头部中，作用是告诉 TCP 协议应该把报文发给哪个进程。</p>
<h3 id="TCP三次握手"><a href="#TCP三次握手" class="headerlink" title="TCP三次握手"></a>TCP三次握手</h3><p><img data-src="/mybook.github.io/21412016243506.png"></p>
<ol>
<li>服务端主动监听某个端口，处于 LISTEN 状态</li>
<li>客户端会随机初始化序号（client_isn），将此序号置于 TCP 首部的「序号」字段中，同时把 SYN 标志位置为 1，表示 SYN 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 SYN-SENT 状态。</li>
</ol>
<p><img data-src="/mybook.github.io/232160215268656.png"></p>
<ol start="3">
<li>服务端收到客户端的 SYN 报文后，首先服务端也随机初始化自己的序号（server_isn），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 client_isn + 1, 接着把 SYN 和 ACK 标志位置为 1。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 SYN-RCVD 状态。</li>
</ol>
<p><img data-src="/mybook.github.io/391953015263792.png"></p>
<ol start="4">
<li>客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 ACK 标志位置为 1 ，其次「确认应答号」字段填入 server_isn + 1 ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 ESTABLISHED 状态。</li>
</ol>
<p><img data-src="/mybook.github.io/354023115257338.png"></p>
<ol start="5">
<li>服务端收到客户端的应答报文后，也进入 ESTABLISHED 状态。</li>
</ol>
<p>从上面的过程可以发现第三次握手是可以携带数据的，前两次握手是不可以携带数据的。</p>
<h4 id="TCP-半连接和全连接队列"><a href="#TCP-半连接和全连接队列" class="headerlink" title="TCP 半连接和全连接队列"></a>TCP 半连接和全连接队列</h4><p>在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：</p>
<p>半连接队列，也称 SYN 队列；<br>全连接队列，也称 accept 队列；</p>
<p>服务端收到客户端发起的 SYN 请求后，内核会把该连接存储到半连接队列，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握⼿的 ACK 后，内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调⽤ accept 函数时把连接取出来。</p>
<p><img data-src="/mybook.github.io/137551216255655.png"></p>
<h5 id="全连接队列满了会发生什么"><a href="#全连接队列满了会发生什么" class="headerlink" title="全连接队列满了会发生什么"></a>全连接队列满了会发生什么</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ss -lnt</span><br></pre></td></tr></table></figure>

<p>当服务端并发处理大量请求时，如果 TCP 全连接队列过小，就容易溢出。发生 TCP 全连接队溢出的时候，后续的请求就会被丢弃，这样就会出现服务端请求数量上不去的现象。</p>
<p><img data-src="/mybook.github.io/473141516248225.png"></p>
<p>实际上，丢弃连接只是 Linux 的默认行为，我们还可以选择向客户端发送 RST 复位报文，告诉客户端连接已经建立失败。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$</span><span class="language-bash"><span class="built_in">cat</span> /proc/sys/net/ipv4/tcp_abort_on-overflow</span></span><br><span class="line">0    #默认值为0</span><br></pre></td></tr></table></figure>
<p>0 ：如果全连接队列满了，那么 server 扔掉 client 发过来的 ack ；<br>1 ：如果全连接队列满了，server 发送一个 reset 包给 client，表示废掉这个握手过程和这个连接；</p>
<p>如果要想知道客户端连接不上服务端，是不是服务端 TCP 全连接队列满的原因，那么可以把 tcp_abort_on_overflow 设置为 1，这时如果在客户端异常中可以看到很多 connection reset by peer 的错误，那么就可以证明是由于服务端 TCP 全连接队列溢出的问题。</p>
<p><strong>但是通常情况下，应当把 tcp_abort_on_overflow 设置为 0，因为这样更有利于应对突发流量</strong>。当 TCP 全连接队列满导致服务器丢掉了 ACK，与此同时，客户端的连接状态却是 ESTABLISHED，进程就在建立好的连接上发送请求。只要服务器没有为请求回复 ACK，请求就会被多次重发。如果服务器上的进程只是短暂的繁忙造成 accept 队列满，那么当 TCP 全连接队列有空位时，<strong>再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接</strong>。</p>
<p>TCP 全连接队列的最大值取决于 somaxconn 和 backlog 之间的最小值</p>
<ul>
<li>somaxconn默认值是 128，Linux 内核参数：&#x2F;proc&#x2F;sys&#x2F;net&#x2F;core&#x2F;somaxconn</li>
<li>backlog 是 listen(int sockfd, int backlog) 函数中的 backlog 大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；</li>
</ul>
<h5 id="半连接队列满了会发生什么"><a href="#半连接队列满了会发生什么" class="headerlink" title="半连接队列满了会发生什么"></a>半连接队列满了会发生什么</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">netstat -natp | grep SYN_RECV | wc -l</span><br></pre></td></tr></table></figure>









<h4 id="为什么不是两次握手或四次握手？"><a href="#为什么不是两次握手或四次握手？" class="headerlink" title="为什么不是两次握手或四次握手？"></a>为什么不是两次握手或四次握手？</h4><h5 id="防止旧的重复连接初始化造成混乱-主要原因）"><a href="#防止旧的重复连接初始化造成混乱-主要原因）" class="headerlink" title="防止旧的重复连接初始化造成混乱(主要原因）"></a>防止旧的重复连接初始化造成混乱(主要原因）</h5><p>若客户端向服务端发送的连接请求丢失，客户端等待应答超时后就会再次发送连接请求，此时，上一个连接请求就是『失效的』。<br>如果是历史连接（序列号过期或超时），则第三次握⼿发送的报⽂是 RST 报⽂，以此中⽌历史连接；<br>如果不是历史连接，则第三次发送的报⽂是 ACK 报⽂，通信双⽅就会成功建⽴连接；</p>
<p><img data-src="/mybook.github.io/504923715250472.png"></p>
<p>如果采用两次握手建立 TCP 连接的场景下，服务端在向客户端发送数据前，并没有阻止掉历史连接，导致服务端建立了一个历史连接，又白白发送了数据，妥妥地浪费了服务端的资源。因此，最好就是在服务端发送数据前，也就是建立连接之前，要阻止掉历史连接:</p>
<p><img data-src="/mybook.github.io/334995315241002.png"></p>
<p>如果客户端第三次发送的ACK丢了，会发生什么</p>
<h5 id="同步双⽅的初始序列号"><a href="#同步双⽅的初始序列号" class="headerlink" title="同步双⽅的初始序列号"></a>同步双⽅的初始序列号</h5><p>当客户端发送携带「初始序列号」的 SYN 报⽂的时候，需要服务端回⼀个 ACK 应答报⽂，表示客户端的 SYN 报⽂已被服务端成功接收，那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，这样⼀来⼀回，才能确保双⽅的初始序列号能被可靠的同步。序列号是可靠传输的一个关键因素，它的作用：</p>
<ul>
<li>接收方可以去除重复的数据；</li>
<li>接收方可以根据数据包的序列号按序接收；</li>
<li>可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；</li>
</ul>
<p><img data-src="/mybook.github.io/323262616252453.png"></p>
<p>四次握手其实也能够可靠的同步双方的初始化序号，但由于第二步和第三步可以优化成一步，所以就成了「三次握手」。而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。</p>
<h5 id="可以避免资源浪费"><a href="#可以避免资源浪费" class="headerlink" title="可以避免资源浪费"></a>可以避免资源浪费</h5><p>假设采用“两次握手”，服务端重复接受无用的连接请求 SYN 报文。服务端不清楚客户端是否收到了自己发送的建立连接的 ACK 确认报文，所以每收到一个 SYN 就只能先主动建立一个连接，而造成重复分配资源</p>
<h4 id="第一次握手失败，会发生什么"><a href="#第一次握手失败，会发生什么" class="headerlink" title="第一次握手失败，会发生什么"></a>第一次握手失败，会发生什么</h4><p>如果客户端迟迟收不到服务端的 SYN-ACK 报文（第二次握手），就会触发「超时重传」机制，重传 SYN 报文，而且重传的 SYN 报文的序列号都是一样的。</p>
<p>在 Linux 里，客户端的 SYN 报文最大重传次数由 tcp_syn_retries内核参数控制，这个参数是可以自定义的，默认值一般是 5。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> /proc/sys/net/ipv4/tcp_syn_retries</span></span><br><span class="line">5</span><br></pre></td></tr></table></figure>
<p>通常，第一次超时重传是在 1 秒后，第二次超时重传是在 2 秒，第三次超时重传是在 4 秒后，第四次超时重传是在 8 秒后，第五次是在超时重传 16 秒后。没错，每次超时的时间是上一次的 2 倍。</p>
<h4 id="第二次握手丢失了，会发生什么"><a href="#第二次握手丢失了，会发生什么" class="headerlink" title="第二次握手丢失了，会发生什么"></a>第二次握手丢失了，会发生什么</h4><p>第二次握手的 SYN-ACK 报文其实有两个目的 ：</p>
<ul>
<li>第二次握手里的 ACK， 是对第一次握手的确认报文；</li>
<li>第二次握手里的 SYN，是服务端发起建立 TCP 连接的报文；</li>
</ul>
<p>如果客户端迟迟没有收到第二次握手，那么客户端就觉得可能自己的 SYN 报文（第一次握手）丢失了，于是客户端就会触发超时重传机制，重传 SYN 报文。<br>如果第二次握手丢失了，服务端就收不到第三次握手，于是服务端这边会触发超时重传机制，重传 SYN-ACK 报文。</p>
<p>在 Linux 下，SYN-ACK 报文的最大重传次数由 tcp_synack_retries内核参数决定，默认值是 5。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> /proc/sys/net/ipv4/tcp_synack_retries</span></span><br><span class="line">5</span><br></pre></td></tr></table></figure>
<p><strong>因此，当第二次握手丢失了，客户端和服务端都会重传</strong></p>
<h4 id="第三次握手丢失了，会发生什么"><a href="#第三次握手丢失了，会发生什么" class="headerlink" title="第三次握手丢失了，会发生什么"></a>第三次握手丢失了，会发生什么</h4><p>第三次握手的 ACK 是对第二次握手的 SYN 的确认报文，所以当第三次握手丢失了，如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。<br><strong>注意，ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文。</strong></p>
<h4 id="什么是-SYN-攻击？如何避免-SYN-攻击？"><a href="#什么是-SYN-攻击？如何避免-SYN-攻击？" class="headerlink" title="什么是 SYN 攻击？如何避免 SYN 攻击？"></a>什么是 SYN 攻击？如何避免 SYN 攻击？</h4><p><img data-src="/mybook.github.io/319484809245340.png"></p>
<p>假设攻击者短时间伪造不同 IP 地址的 SYN 报文，服务端每接收到一个 SYN 报文，就进入SYN_RCVD 状态，但服务端发送出去的 ACK + SYN 报文，无法得到未知 IP 主机的 ACK 应答，久而久之就会<strong>占满服务端的半连接队列</strong>，使得服务端不能为正常用户服务。</p>
<p>不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，默认情况都会丢弃报文。SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃，导致客户端无法和服务端建立连接。</p>
<p><strong>避免 SYN 攻击方式：</strong></p>
<ol>
<li><p>调大 netdev_max_backlog；<br>当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。控制该队列的最大值如下参数，默认值是 1000，我们要适当调大该参数的值，比如设置为 10000：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.core.netdev_max_backlog = 10000</span><br></pre></td></tr></table></figure></li>
<li><p>增大 TCP 半连接队列；<br>要同时增大下面这三个参数：<br>增大 net.ipv4.tcp_max_syn_backlog<br>增大 listen() 函数中的 backlog<br>增大 net.core.somaxconn</p>
</li>
<li><p><span id="target4">开启 tcp_syncookies</span>；<br>开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接。0 值，表示关闭该功能；1 值，表示仅当 SYN 半连接队列放不下时，再启用它；2 值，表示无条件开启功能；<br><img data-src="/mybook.github.io/385275809245949.png"></p>
</li>
</ol>
<p>当 「 SYN 队列」满之后，后续服务端收到 SYN 包，不会丢弃，而是根据算法，<strong>计算出一个 cookie 值；将 cookie 值放到第二次握手报文的「序列号」里</strong>，然后服务端回第二次握手给客户端；服务端接收到客户端的应答报文时，服务端会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」。最后应用程序通过调用 accpet() 接口，从「 Accept 队列」取出的连接。</p>
<ol start="4">
<li>减少 SYN+ACK 重传次数<br>当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。<br>可以减少 SYN-ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。</li>
</ol>
<h4 id="SYN-报文什么时候情况下会被丢弃"><a href="#SYN-报文什么时候情况下会被丢弃" class="headerlink" title="SYN 报文什么时候情况下会被丢弃?"></a>SYN 报文什么时候情况下会被丢弃?</h4><p>SYN 报文被丢弃的两种场景：</p>
<ol>
<li>开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃</li>
</ol>
<ul>
<li>tcp_timestamps 选项开启之后， PAWS 机制会自动开启，它的作用是防止 TCP 包中的序列号发生绕回。<a href="#target2">点击此处跳转到TCP时间戳和序列号回绕(PAWS)</a></li>
<li><strong>tcp_tw_recycle 在使用了 NAT 的网络下是不安全的</strong>！对于服务器来说，如果同时开启了recycle 和 timestamps 选项，则会开启一种称之为「 per-host 的 PAWS 机制」。per-host 是对「对端 IP 做 PAWS 检查」，而非对「IP + 端口」四元组做 PAWS 检查。</li>
<li>如果客户端网络环境是用了 NAT 网关，那么<strong>客户端环境的每一台机器通过 NAT 网关后，都会是相同的 IP 地址</strong>，在服务端看来，就好像只是在跟一个客户端打交道一样，无法区分出来。当客户端 A 通过 NAT 网关和服务器建立 TCP 连接，然后服务器主动关闭并且快速回收 TIME-WAIT 状态的连接后，客户端 B 也通过 NAT 网关和服务器建立 TCP 连接，注意客户端 A 和 客户端 B 因为经过相同的 NAT 网关，所以是用相同的 IP 地址与服务端建立 TCP 连接，<strong>如果客户端 B 的 timestamp 比 客户端 A 的 timestamp 小，那么由于服务端的 per-host 的 PAWS 机制的作用，服务端就会丢弃客户端主机 B 发来的 SYN 包。tcp_tw_recycle 在 Linux 4.12 版本后，直接取消了这一参数。</strong></li>
</ul>
<ol start="2">
<li>TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃</li>
</ol>
<h4 id="已建立连接的TCP，收到SYN会发生什么？"><a href="#已建立连接的TCP，收到SYN会发生什么？" class="headerlink" title="已建立连接的TCP，收到SYN会发生什么？"></a>已建立连接的TCP，收到SYN会发生什么？</h4><p>如果客户端掉线了，服务器不知道，客户端再上线的时候发起了SYN握手，服务器如何应对？</p>
<ol>
<li><p>客户端的 SYN 报文里的端口号与历史连接不相同<br>此时服务端会认为是新的连接要建立，于是就会通过三次握手来建立新的连接。那旧连接里处于 Established 状态的服务端最后会怎么样呢？<br>如果服务端发送了数据包给客户端，由于客户端的连接已经被关闭了，此时客户的内核就会回 RST 报文，服务端收到后就会释放连接。如果服务端一直没有发送数据包给客户端，在超过一段时间后，TCP 保活机制就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。</p>
</li>
<li><p>客户端的 SYN 报文里的端口号与历史连接相同<br><strong>处于 Established 状态的服务端，如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。接着，客户端收到这个 Challenge ACK，发现确认号（ack num）并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接</strong>。<br>RFC 793 文档里的第 34 页里，有说到这个例子。</p>
</li>
</ol>
<p><img data-src="/mybook.github.io/58691818266061.png"></p>
<h3 id="TCP四次挥手"><a href="#TCP四次挥手" class="headerlink" title="TCP四次挥手"></a>TCP四次挥手</h3><p><img data-src="/mybook.github.io/584384110255117.png"></p>
<p><img data-src="/mybook.github.io/513040811240805.png"></p>
<p>服务端在收到 FIN 报文的时候，TCP 协议栈会为 FIN 包插入一个文件结束符 EOF 到接收缓冲区中，服务端应用程序可以通过 read 调用来感知这个 FIN 包，<strong>这个 EOF 会被放在已排队等候的其他已接收的数据之后</strong>，所以必须要得继续 read 接收缓冲区已接收的数据；</p>
<p>当服务端在 read 数据的时候，最后自然就会读到 EOF，接着 <strong>read() 就会返回 0，这时服务端应用程序如果有数据要发送的话，就发完数据后才调用关闭连接的函数，如果服务端应用程序没有数据要发送的话，可以直接调用关闭连接的函数，这时服务端就会发一个 FIN 包</strong>，这个 FIN 报文代表服务端不会再发送数据了，之后处于 LAST_ACK 状态；</p>
<p><strong>是否要发送第三次挥手的控制权不在内核，而是在被动关闭方（上图的服务端）的应用程序</strong>，因为应用程序可能还有数据要发送，由应用程序决定什么时候调用关闭连接的函数，当调用了关闭连接的函数，内核就会发送 FIN 报文了，</p>
<h4 id="为什么挥手需要四次？"><a href="#为什么挥手需要四次？" class="headerlink" title="为什么挥手需要四次？"></a>为什么挥手需要四次？</h4><ul>
<li>关闭连接时，客户端向服务端发送 FIN 时，<strong>仅仅表示客户端不再发送数据了但是还能接收数据</strong>。</li>
<li>服务端收到客户端的 FIN 报文时，先回一个 ACK 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 FIN 报文给客户端来表示同意现在关闭连接。</li>
</ul>
<h5 id="可以变成三次挥手吗？"><a href="#可以变成三次挥手吗？" class="headerlink" title="可以变成三次挥手吗？"></a>可以变成三次挥手吗？</h5><p><strong>但是在特定情况下，四次挥手是可以变成三次挥手的</strong>，能不能把第二次的 ACK 报文， 放到第三次 FIN 报文一起发送？</p>
<p><img data-src="/mybook.github.io/236384910244415.png"></p>
<p>「没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。</p>
<h5 id="TCP延迟确认"><a href="#TCP延迟确认" class="headerlink" title="TCP延迟确认"></a>TCP延迟确认</h5><ul>
<li>当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方</li>
<li>当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送</li>
<li>如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK</li>
</ul>
<p><img data-src="/mybook.github.io/333440611240666.png"></p>
<p>例如：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> TCP_DELACK_MAX	((unsigned)(HZ/5))	<span class="comment">/* maximal time to delay before sending an ACK */</span></span></span><br><span class="line"><span class="built_in">static_assert</span>((<span class="number">1</span> &lt;&lt; ATO_BITS) &gt; TCP_DELACK_MAX);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> HZ &gt;= 100</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TCP_DELACK_MIN	((unsigned)(HZ/25))	<span class="comment">/* minimal time to delay before sending an ACK */</span></span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[lepos@apptest132 boot]$ cat /boot/config-3.10.0-693.el7.x86_64 | grep &#x27;CONFIG_HZ=&#x27;</span><br><span class="line">CONFIG_HZ=1000</span><br></pre></td></tr></table></figure>
<p>最大延迟确认时间是 200 ms，最短延迟确认时间是 40 ms</p>
<p>如果要关闭 TCP 延迟确认机制，可以在 Socket 设置里启用 TCP_QUICKACK。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1 表示开启 TCP_QUICKACK，即关闭 TCP 延迟确认机制</span></span><br><span class="line"><span class="type">int</span> value = <span class="number">1</span>;</span><br><span class="line"><span class="built_in">setsockopt</span>(socketfd, IPPROTO_TCP, TCP_QUICKACK, (<span class="type">char</span>*)&amp; value, <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br></pre></td></tr></table></figure>


<h4 id="第一次挥手丢失了，会发生什么？"><a href="#第一次挥手丢失了，会发生什么？" class="headerlink" title="第一次挥手丢失了，会发生什么？"></a>第一次挥手丢失了，会发生什么？</h4><p>如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会触发超时重传机制，重传 FIN 报文，重发次数由 tcp_orphan_retries 参数控制。</p>
<ul>
<li><font color="BlueGreen">当客户端超时重传已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次挥手（ACK 报文），那么客户端就会断开连接。</font></li>
</ul>
<h4 id="第二次挥手丢失了，会发生什么？"><a href="#第二次挥手丢失了，会发生什么？" class="headerlink" title="第二次挥手丢失了，会发生什么？"></a>第二次挥手丢失了，会发生什么？</h4><p><strong>ACK 报文是不会重传的</strong>，所以如果服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数。</p>
<ul>
<li><font color="BlueGreen">当客户端超时重传已达到最大重传次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到服务端的第二次挥手（ACK 报文），那么客户端就会断开连接。</font></li>
</ul>
<h4 id="第三次挥手丢失了，会发生什么？"><a href="#第三次挥手丢失了，会发生什么？" class="headerlink" title="第三次挥手丢失了，会发生什么？"></a>第三次挥手丢失了，会发生什么？</h4><p>内核是没有权利替代进程关闭连接，必须由进程主动调用 close 函数来触发服务端发送 FIN 报文。如果迟迟收不到这个 ACK，服务端就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。</p>
<ul>
<li><font color="YellowGreen">服务端重传第三次挥手报文的次数达到了重传最大次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第四次挥手（ACK报文），那么服务端就会断开连接。</font></li>
<li>客户端因为是通过 close 函数关闭连接的，处于 FIN_WAIT_2 状态是有时长限制的，如果 tcp_fin_timeout （默认值是 60 秒）时间内还是没能收到服务端的第三次挥手（FIN 报文），那么客户端就会断开连接。</li>
</ul>
<h4 id="第四次挥手丢失了，会发生什么？"><a href="#第四次挥手丢失了，会发生什么？" class="headerlink" title="第四次挥手丢失了，会发生什么？"></a>第四次挥手丢失了，会发生什么？</h4><p><strong>ACK 报文是不会重传的</strong>，如果第四次挥手的 ACK 报文没有到达服务端，服务端就会重发 FIN 报文，重发次数仍然由前面介绍过的 tcp_orphan_retries 参数控制。</p>
<ul>
<li><font color="YellowGreen">服务端重传第三次挥手报文的次数达到了重传最大次数，于是再等待一段时间（时间为上一次超时时间的 2 倍），如果还是没能收到客户端的第四次挥手（ACK报文），那么服务端就会断开连接。</font></li>
<li>客户端在收到第三次挥手后，就会进入 TIME_WAIT 状态，开启时长为 2MSL 的定时器，如果途中再次收到第三次挥手（FIN 报文）后，就会重置定时器，<strong>当等待 2MSL 时长后，客户端就会断开连接</strong>。</li>
</ul>
<h4 id="粗暴关闭vs优雅关闭"><a href="#粗暴关闭vs优雅关闭" class="headerlink" title="粗暴关闭vs优雅关闭"></a>粗暴关闭vs优雅关闭</h4><h5 id="close函数–粗暴关闭"><a href="#close函数–粗暴关闭" class="headerlink" title="close函数–粗暴关闭"></a>close函数–粗暴关闭</h5><p>同时 socket 关闭发送方向和读取方向，也就是 socket 不再有发送和接收数据的能力。如果有多进程&#x2F;多线程共享同一个 socket，如果有一个进程调用了 close 关闭只是让 socket 引用计数 -1，并不会导致 socket 不可用，同时也不会发出 FIN 报文，其他进程还是可以正常读写该 socket，直到引用计数变为 0，才会发出 FIN 报文。</p>
<p>如果客户端是用 close 函数来关闭连接，那么在 TCP 四次挥手过程中，如果收到了服务端发送的数据，由于客户端已经不再具有发送和接收数据的能力，所以客户端的内核会回 RST 报文给服务端，然后内核会释放连接，<strong>这时就不会经历完成的 TCP 四次挥手，所以调用 close 是粗暴的关闭</strong>。<br>当服务端收到 RST 后，内核就会释放连接，当服务端应用程序再次发起读操作或者写操作时，就能感知到连接已经被释放了：</p>
<ul>
<li>如果是读操作，则会返回 RST 的报错，也就是我们常见的Connection reset by peer。</li>
<li>如果是写操作，那么程序会产生 SIGPIPE 信号，应用层代码可以捕获并处理信号，如果不处理，则默认情况下进程会终止，异常退出。</li>
</ul>
<p><img data-src="/mybook.github.io/185051015257934.png"></p>
<h5 id="shutdown函数–优雅关闭"><a href="#shutdown函数–优雅关闭" class="headerlink" title="shutdown函数–优雅关闭"></a>shutdown函数–优雅关闭</h5><p>可以指定 socket 只关闭发送方向而不关闭读取方向，也就是 socket 不再有发送数据的能力，但是还是具有接收数据的能力。如果有多进程&#x2F;多线程共享同一个 socket，shutdown 则不管引用计数，直接使得该 socket 不可用，然后发出 FIN 报文，如果有别的进程企图使用该 socket，将会受到影响。<br>shutdown 函数因为可以指定只关闭发送方向而不关闭读取方向，所以即使在 TCP 四次挥手过程中，如果收到了服务端发送的数据，客户端也是可以正常读取到该数据的，<strong>然后就会经历完整的 TCP 四次挥手，所以调用 shutdown 是优雅的关闭</strong>。</p>
<p><img data-src="/mybook.github.io/11861215259229.png"></p>
<h4 id="TIME-WAIT"><a href="#TIME-WAIT" class="headerlink" title="TIME_WAIT"></a>TIME_WAIT</h4><p>MSL(最大分段生存期)，指明TCP报文在Internet上最长生存时间，每个具体的TCP实现都必须选择一个确定的MSL值</p>
<p>因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 字段，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。<br><strong>MSL 应该要大于等于 TTL 消耗为 0 的时间，以确保报文已被自然消亡</strong>。TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着<strong>Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了</strong>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> TCP_TIMEWAIT_LEN (60*HZ) <span class="comment">/* how long to wait to destroy TIME-WAIT </span></span></span><br><span class="line"><span class="comment"><span class="meta">                                    state, about 60 seconds  */</span></span></span><br></pre></td></tr></table></figure>
<h5 id="TIME-WAIT的作用"><a href="#TIME-WAIT的作用" class="headerlink" title="TIME_WAIT的作用"></a>TIME_WAIT的作用</h5><ol>
<li>保证「被动关闭连接」的一方，能被正确的关闭<br>如果被动关闭⽅没有收到断开连接的最后的 ACK 报⽂，就会触发超时重发 Fin 报⽂，另⼀⽅接收到 FIN 后，会触发 ACK 给被动关闭⽅， ⼀来⼀去正好 2 个 MSL。<br>2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端⼜接收到了服务端重发的 FIN 报⽂，那么 2MSL 时间将重新计时。<strong>可以看到 2MSL时长，这其实是相当于至少允许报文丢失一次</strong>。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。<br>假设客户端没有 TIME_WAIT 状态，而是在发完最后一次回 ACK 报文就直接进入 CLOSE 状态，如果该 ACK 报文丢失了，服务端则重传的 FIN 报文，而这时客户端已经进入到关闭状态了，在收到服务端重传的 FIN 报文后，就会回 RST 报文。</li>
</ol>
<p><img data-src="/mybook.github.io/597362314252895.png"></p>
<ol start="2">
<li>防止历史连接中的数据，被后面相同四元组的连接错误的接收<br>在关闭一个TCP连接后，马上又重新建立起一个相同的IP地址和端口之间的TCP连接，后一个连接被称为前一个连接的化身 ，那么有可能出现这种情况，前一个连接的迷途重复分组在前一个连接终止后出现，从而被误解成从属于新的化身。为了避免这个情况，TCP不允许处于TIME_WAIT状态的连接启动一个新的化身，<strong>因为TIME_WAIT状态持续2MSL，足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。</strong><br>例如：服务端在关闭连接之前发送的 SEQ &#x3D; 301 报文，被网络延迟了。接着，服务端以相同的四元组重新打开了新连接，前面被延迟的 SEQ &#x3D; 301 这时抵达了客户端，而且该数据报文的序列号刚好在客户端接收窗口内，因此客户端会正常接收这个数据报文，但是这个数据报文是上一个连接残留下来的，这样就产生数据错乱等严重的问题。</li>
</ol>
<h5 id="TIME-WAIT-过多有什么危害？"><a href="#TIME-WAIT-过多有什么危害？" class="headerlink" title="TIME_WAIT 过多有什么危害？"></a>TIME_WAIT 过多有什么危害？</h5><p>第一是占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等；第二是占用端口资源</p>
<h5 id="如何解决客户端-TCP-连接-TIME-WAIT-过多，导致无法与同一个服务器建立连接的问题？"><a href="#如何解决客户端-TCP-连接-TIME-WAIT-过多，导致无法与同一个服务器建立连接的问题？" class="headerlink" title="如何解决客户端 TCP 连接 TIME_WAIT 过多，导致无法与同一个服务器建立连接的问题？"></a>如何解决客户端 TCP 连接 TIME_WAIT 过多，导致无法与同一个服务器建立连接的问题？</h5><p>如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。</p>
<h6 id="net-ipv4-tcp-tw-reuse"><a href="#net-ipv4-tcp-tw-reuse" class="headerlink" title="net.ipv4.tcp_tw_reuse"></a>net.ipv4.tcp_tw_reuse</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br></pre></td></tr></table></figure>
<p>开启了这个内核参数后，客户端调用 connect 函数时，如果选择到的端口，已经被相同四元组的连接占用的时候，就会判断该连接是否处于 TIME_WAIT 状态，如果该连接处于 TIME_WAIT 状态并且 TIME_WAIT 状态持续的时间超过了 1 秒，那么就会重用这个连接，然后就可以正常使用该端口了。该选项只适用于连接发起方</p>
<p>举个例子，假设客户端已经与服务器建立了一个 TCP 连接，并且这个状态处于 TIME_WAIT 状态：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">客户端地址:端口           服务端地址:端口         TCP 连接状态</span><br><span class="line">192.168.1.100:2222      172.19.11.21:8888     TIME_WAIT</span><br></pre></td></tr></table></figure>

<p>然后客户端又与该服务器（172.19.11.21:8888）发起了连接，在调用 connect 函数时，内核刚好选择了 2222 端口，接着发现已经被相同四元组的连接占用了：</p>
<ul>
<li>如果没有开启 net.ipv4.tcp_tw_reuse 内核参数，那么内核就会选择下一个端口，然后继续判断，直到找到一个没有被相同四元组的连接使用的端口， 如果端口资源耗尽还是没找到，那么 connect 函数就会返回错误。</li>
<li>如果开启了 net.ipv4.tcp_tw_reuse 内核参数，就会判断该四元组的连接状态是否处于 TIME_WAIT 状态，如果连接处于 TIME_WAIT 状态并且该状态持续的时间超过了 1 秒，那么就会重用该连接，于是就可以使用 2222 端口了，这时 connect 就会返回成功。</li>
</ul>
<p>再次提醒一次，开启了 net.ipv4.tcp_tw_reuse 内核参数，<strong>是客户端（连接发起方） 在调用 connect() 函数时才起作用</strong>，所以在服务端开启这个参数是没有效果的。</p>
<h6 id="net-ipv4-tcp-tw-recycle"><a href="#net-ipv4-tcp-tw-recycle" class="headerlink" title="net.ipv4.tcp_tw_recycle"></a>net.ipv4.tcp_tw_recycle</h6><p>如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收；<strong>慎用，NAT环境下会导致SYN被丢弃，且不安全</strong></p>
<p>要使得上面两个选项生效，有一个前提条件，就是要打开 TCP 时间戳，即 net.ipv4.tcp_timestamps&#x3D;1（默认即为 1)）。</p>
<h6 id="net-ipv4-tcp-max-tw-buckets"><a href="#net-ipv4-tcp-max-tw-buckets" class="headerlink" title="net.ipv4.tcp_max_tw_buckets"></a>net.ipv4.tcp_max_tw_buckets</h6><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_max_tw_buckets</span><br></pre></td></tr></table></figure>
<p>这个值默认为 18000，当系统中处于 TIME_WAIT 的连接一旦超过这个值时，系统就会将后面的 TIME_WAIT 连接状态重置，这个方法比较暴力。</p>
<h6 id="程序中使用-SO-LINGER"><a href="#程序中使用-SO-LINGER" class="headerlink" title="程序中使用 SO_LINGER"></a>程序中使用 SO_LINGER</h6><p>设置 socket 选项，来设置调用 close 关闭连接行为。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">linger</span> so_linger;</span><br><span class="line">so_linger.l_onoff = <span class="number">1</span>;</span><br><span class="line">so_linger.l_linger = <span class="number">0</span>;</span><br><span class="line"><span class="built_in">setsockopt</span>(s, SOL_SOCKET, SO_LINGER, &amp;so_linger,<span class="built_in">sizeof</span>(so_linger));</span><br></pre></td></tr></table></figure>
<p>如果l_onoff为非 0， 且l_linger值为 0，那么调用close后，会立该发送一个RST标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了TIME_WAIT状态，直接关闭。</p>
<p>《UNIX网络编程》：<strong>TIME_WAIT 是我们的朋友，它是有助于我们的，不要试图避免这个状态，而是应该弄清楚它。如果服务端要避免过多的 TIME_WAIT 状态的连接，就永远不要主动断开连接，让客户端去断开，由分布在各处的客户端去承受 TIME_WAIT。</strong></p>
<h5 id="服务器出现大量-TIME-WAIT-状态的原因有哪些？"><a href="#服务器出现大量-TIME-WAIT-状态的原因有哪些？" class="headerlink" title="服务器出现大量 TIME_WAIT 状态的原因有哪些？"></a>服务器出现大量 TIME_WAIT 状态的原因有哪些？</h5><p>什么场景下服务端会主动断开连接呢？</p>
<ol>
<li>HTTP 没有使用长连接（Keep-Alive）：<figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">Connection</span><span class="punctuation">: </span>Keep-Alive</span><br></pre></td></tr></table></figure></li>
</ol>
<ul>
<li><p><strong>客户端禁用了 HTTP Keep-Alive，服务端开启 HTTP Keep-Alive，谁是主动关闭方？</strong><br>当客户端禁用了 HTTP Keep-Alive，这时候 HTTP 请求的 header 就会有 Connection:close 信息，这时服务端在发完 HTTP 响应后，就会主动关闭连接。为什么要这么设计呢？HTTP 是请求-响应模型，发起方一直是客户端，HTTP Keep-Alive 的初衷是为客户端后续的请求重用连接，如果我们在某次 HTTP 请求-响应模型中，请求的 header 定义了 connection：close 信息，那不再重用这个连接的时机就只有在服务端了，所以我们在 HTTP 请求-响应这个周期的「末端」关闭连接是合理的。</p>
</li>
<li><p><strong>客户端开启了 HTTP Keep-Alive，服务端禁用了 HTTP Keep-Alive，谁是主动关闭方？</strong><br>当客户端开启了 HTTP Keep-Alive，而服务端禁用了 HTTP Keep-Alive，这时服务端在发完 HTTP 响应后，服务端也会主动关闭连接。为什么要这么设计呢？在服务端主动关闭连接的情况下，只要调用一次 close() 就可以释放连接，剩下的工作由内核 TCP 栈直接进行了处理，整个过程只有一次 syscall；<strong>如果是要求客户端关闭，则服务端在写完最后一个 response 之后需要把这个 socket 放入 readable 队列，调用 select &#x2F; epoll 去等待事件；然后调用一次 read() 才能知道连接已经被关闭，这其中是两次 syscall</strong>，多一次用户态程序被激活执行，而且 socket 保持时间也会更长。</p>
</li>
</ul>
<p>所以，根据大多数 Web 服务的实现，不管哪一方禁用了 HTTP Keep-Alive，都会导致服务端在处理完一个 HTTP 请求后，就主动关闭连接，此时服务端上就会出现大量的 TIME_WAIT 状态的连接。都是由服务端主动关闭连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。</p>
<ol start="2">
<li><p>HTTP 长连接超时<br>为了避免资源浪费的情况，web 服务软件一般都会提供一个参数，用来指定 HTTP 长连接的超时时间，如 nginx 提供的 keepalive_timeout 参数。<br>假设设置了 HTTP 长连接的超时时间是 60 秒，nginx 就会启动一个「定时器」，如果客户端在完后一个 HTTP 请求后，在 60 秒内都没有再发起新的请求，定时器的时间一到，nginx 就会触发回调函数来关闭该连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。</p>
</li>
<li><p>HTTP 长连接的请求数量达到上限<br>Web 服务端通常会有个参数，来定义一条 HTTP 长连接上最大能处理的请求数量，当超过最大限制时，就会主动关闭连接。<br>比如 nginx 的 keepalive_requests 这个参数，这个参数是指一个 HTTP 长连接建立之后，nginx 就会为这个连接设置一个计数器，记录这个 HTTP 长连接上已经接收并处理的客户端请求的数量。如果达到这个参数设置的最大值时，则 nginx 会主动关闭这个长连接，那么此时服务端上就会出现 TIME_WAIT 状态的连接。<br>对于一些 QPS 比较高的场景，比如超过 10000 QPS，甚至达到 30000 , 50000 甚至更高，如果 keepalive_requests 参数值是 100，这时候<strong>nginx 就会很频繁地关闭连接，那么此时服务端上就会出大量的 TIME_WAIT 状态</strong>。</p>
</li>
</ol>
<h5 id="服务器出现大量-CLOSE-WAIT-状态的原因有哪些？"><a href="#服务器出现大量-CLOSE-WAIT-状态的原因有哪些？" class="headerlink" title="服务器出现大量 CLOSE_WAIT 状态的原因有哪些？"></a>服务器出现大量 CLOSE_WAIT 状态的原因有哪些？</h5><p>当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用 close 函数关闭连接。需要排查代码</p>
<p>一个普通的 TCP 服务端的流程：</p>
<ol>
<li>创建服务端 socket，bind 绑定端口、listen 监听端口</li>
<li>将服务端 socket 注册到 epoll</li>
<li>epoll_wait 等待连接到来，连接到来时，调用 accpet 获取已连接的 socket</li>
<li>将已连接的 socket 注册到 epoll</li>
<li>epoll_wait 等待事件发生</li>
<li>对方连接关闭时，我方调用 close</li>
</ol>
<ul>
<li>第一个原因：第 2 步没有做，没有将服务端 socket 注册到 epoll，这样有新连接到来时，服务端没办法感知这个事件，也就无法获取到已连接的 socket，那服务端自然就没机会对 socket 调用 close 函数了。不过这种原因发生的概率比较小，这种属于明显的代码逻辑 bug，在前期 read view 阶段就能发现的了。</li>
<li>第二个原因： 第 3 步没有做，有新连接到来时没有调用 accpet 获取该连接的 socket，导致当有大量的客户端主动断开了连接，而服务端没机会对这些 socket 调用 close 函数，从而导致服务端出现大量 CLOSE_WAIT 状态的连接。发生这种情况可能是因为服务端在执行 accpet 函数之前，代码卡在某一个逻辑或者提前抛出了异常。</li>
<li>第三个原因：第 4 步没有做，通过 accpet 获取已连接的 socket 后，没有将其注册到 epoll，导致后续收到 FIN 报文的时候，服务端没办法感知这个事件，那服务端就没机会调用 close 函数了。发生这种情况可能是因为服务端在将已连接的 socket 注册到 epoll 之前，代码卡在某一个逻辑或者提前抛出了异常。</li>
<li>第四个原因：第 6 步没有做，当发现客户端关闭连接后，服务端没有执行 close 函数，可能是因为代码漏处理，或者是在执行 close 函数之前，代码卡在某一个逻辑，比如发生死锁等等。</li>
</ul>
<h5 id="如果已经建立了连接，但是客户端突然出现故障了怎么办？"><a href="#如果已经建立了连接，但是客户端突然出现故障了怎么办？" class="headerlink" title="如果已经建立了连接，但是客户端突然出现故障了怎么办？"></a>如果已经建立了连接，但是客户端突然出现故障了怎么办？</h5><p>客户端的主机发生了宕机。发生这种情况的时候，如果服务端一直不会发送数据给客户端，那么服务端是永远无法感知到客户端宕机这个事件的，也就是服务端的 TCP 连接将一直处于 ESTABLISH 状态，占用着系统资源。</p>
<p>为了避免这种情况，TCP使用保活机制：<br>定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用。每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.tcp_keepalive_time=<span class="number">7200</span> <span class="comment">//表示保活时间是 7200 秒（2小时），也就 2 小时内如果没有任何连接相关的活动，则会启动保活机制</span></span><br><span class="line">net.ipv4.tcp_keepalive_intvl=<span class="number">75</span>  <span class="comment">//表示每次检测间隔 75 秒</span></span><br><span class="line">net.ipv4.tcp_keepalive_probes=<span class="number">9</span>  <span class="comment">//表示检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。</span></span><br></pre></td></tr></table></figure>

<p>在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。我们可以自己在应用层实现一个心跳机制<br>tcp_keepalive_time + （tcp_keepalive_intvl * tcp_keepalive_probes）</p>
<p>如果开启了 TCP 保活，需要考虑以下几种情况：</p>
<ol>
<li>对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 TCP 保活时间会被重置，等待下一个 TCP 保活时间的到来。</li>
<li>对端主机宕机并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，会产生一个 RST 报文，这样很快就会发现 TCP 连接已经被重置。</li>
<li>是对端主机宕机（<em>注意不是进程崩溃，进程崩溃后操作系统在回收进程资源的时候，会发送 FIN 报文，而主机宕机则是无法感知的，所以需要 TCP 保活机制来探测对方是不是发生了主机宕机</em>），或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，没有响应，连续几次，达到保活探测次数后，TCP 会报告该 TCP 连接已经死亡。</li>
</ol>
<h5 id="如果已经建立了连接，但是服务端突然出现故障了怎么办？"><a href="#如果已经建立了连接，但是服务端突然出现故障了怎么办？" class="headerlink" title="如果已经建立了连接，但是服务端突然出现故障了怎么办？"></a>如果已经建立了连接，但是服务端突然出现故障了怎么办？</h5><p>在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手</p>
<h4 id="四次挥手中收到乱序的-FIN-包会如何处理？"><a href="#四次挥手中收到乱序的-FIN-包会如何处理？" class="headerlink" title="四次挥手中收到乱序的 FIN 包会如何处理？"></a>四次挥手中收到乱序的 FIN 包会如何处理？</h4><p>客户端只调用shutdown关闭写的情况下，假如服务端二三次挥手之间发送的数据被阻塞了，导致FIN先到达客户端，会发生什么？</p>
<p>在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，<strong>那么就被会加入到「乱序队列」，这个队列的数据结构是红黑树</strong>，并不会进入到 TIME_WAIT 状态。</p>
<p>等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。</p>
<p><img data-src="/mybook.github.io/395313709268159.png"></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">tcp_v4_rcv</span><span class="params">(<span class="keyword">struct</span> sk_buff *skb)</span></span>&#123;</span><br><span class="line">...</span><br><span class="line">    <span class="comment">//根据四元组查找相应连接的socket结构</span></span><br><span class="line">	sk = __inet_lookup_skb(&amp;tcp_hashinfo, skb, th-&gt;source, th-&gt;dest);</span><br><span class="line">	<span class="keyword">if</span> (!sk)</span><br><span class="line">		<span class="keyword">goto</span> no_tcp_socket;</span><br><span class="line">...</span><br><span class="line">    <span class="comment">//判断socket是否被user占用，如果没有占用，调用tcp_v4_do_rcv()</span></span><br><span class="line">	<span class="keyword">if</span> (!<span class="built_in">sock_owned_by_user</span>(sk)) &#123;</span><br><span class="line">		<span class="keyword">if</span> (!<span class="built_in">tcp_prequeue</span>(sk, skb))</span><br><span class="line">			ret = <span class="built_in">tcp_v4_do_rcv</span>(sk, skb);</span><br><span class="line">	&#125; </span><br><span class="line">	<span class="comment">//为了避免并发操作socket，将数据包放入backlog队列，放入失败或已满，丢弃数据包</span></span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">if</span> (<span class="built_in">unlikely</span>(<span class="built_in">sk_add_backlog</span>(sk, skb,</span><br><span class="line">					   sk-&gt;sk_rcvbuf + sk-&gt;sk_sndbuf))) &#123;</span><br><span class="line">		<span class="built_in">bh_unlock_sock</span>(sk);</span><br><span class="line">		<span class="built_in">NET_INC_STATS_BH</span>(net, LINUX_MIB_TCPBACKLOGDROP);</span><br><span class="line">		<span class="keyword">goto</span> discard_and_relse;</span><br><span class="line">	&#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">tcp_v4_do_rcv</span><span class="params">(<span class="keyword">struct</span> sock *sk, <span class="keyword">struct</span> sk_buff *skb)</span></span>&#123;</span><br><span class="line">...</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">tcp_rcv_state_process</span>(sk, skb, <span class="built_in">tcp_hdr</span>(skb), skb-&gt;len)) &#123;</span><br><span class="line">		rsk = sk;</span><br><span class="line">		<span class="keyword">goto</span> reset;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>shutdown 只关闭了写方向，所以会继续往下调用 tcp_data_queue 函数（因为 case TCP_FIN_WAIT2 代码块里并没有 break 语句，所以会走到该函数）。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">tcp_rcv_state_process</span><span class="params">(<span class="keyword">struct</span> sock *sk, <span class="keyword">struct</span> sk_buff *skb,</span></span></span><br><span class="line"><span class="params"><span class="function">			  <span class="type">const</span> <span class="keyword">struct</span> tcphdr *th, <span class="type">unsigned</span> <span class="type">int</span> len)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">	<span class="keyword">case</span> TCP_FIN_WAIT2:</span><br><span class="line">		<span class="comment">/* RFC 793 says to queue data in these states,</span></span><br><span class="line"><span class="comment">		 * RFC 1122 says we MUST send a reset.</span></span><br><span class="line"><span class="comment">		 * BSD 4.4 also does reset.</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		<span class="keyword">if</span> (sk-&gt;sk_shutdown &amp; RCV_SHUTDOWN) &#123;</span><br><span class="line">			<span class="keyword">if</span> (<span class="built_in">TCP_SKB_CB</span>(skb)-&gt;end_seq != <span class="built_in">TCP_SKB_CB</span>(skb)-&gt;seq &amp;&amp;</span><br><span class="line">			    <span class="built_in">after</span>(<span class="built_in">TCP_SKB_CB</span>(skb)-&gt;end_seq - th-&gt;fin, tp-&gt;rcv_nxt)) &#123;</span><br><span class="line">				<span class="built_in">NET_INC_STATS_BH</span>(<span class="built_in">sock_net</span>(sk), LINUX_MIB_TCPABORTONDATA);</span><br><span class="line">				<span class="built_in">tcp_reset</span>(sk);</span><br><span class="line">				<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">/* Fall through */</span></span><br><span class="line">	<span class="keyword">case</span> TCP_ESTABLISHED:</span><br><span class="line">		<span class="built_in">tcp_data_queue</span>(sk, skb);</span><br><span class="line">		queued = <span class="number">1</span>;</span><br><span class="line">		<span class="keyword">break</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/* tcp_data could move socket to TIME-WAIT */</span></span><br><span class="line">	<span class="keyword">if</span> (sk-&gt;sk_state != TCP_CLOSE) &#123;</span><br><span class="line">		<span class="built_in">tcp_data_snd_check</span>(sk);</span><br><span class="line">		<span class="built_in">tcp_ack_snd_check</span>(sk);</span><br><span class="line">	&#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">void</span> <span class="title">tcp_data_queue</span><span class="params">(<span class="keyword">struct</span> sock *sk, <span class="keyword">struct</span> sk_buff *skb)</span></span>&#123;</span><br><span class="line">...</span><br><span class="line">	<span class="comment">/*  Queue data for delivery to the user.</span></span><br><span class="line"><span class="comment">	 *  Packets in sequence go to the receive queue.</span></span><br><span class="line"><span class="comment">	 *  Out of sequence packets to the out_of_order_queue.</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="comment">//如果报文的序列号是有序的</span></span><br><span class="line">	<span class="keyword">if</span> (<span class="built_in">TCP_SKB_CB</span>(skb)-&gt;seq == tp-&gt;rcv_nxt) &#123;</span><br><span class="line">		<span class="keyword">if</span> (<span class="built_in">tcp_receive_window</span>(tp) == <span class="number">0</span>)</span><br><span class="line">			<span class="keyword">goto</span> out_of_window;</span><br><span class="line"></span><br><span class="line">		<span class="comment">/* Ok. In sequence. In window. */</span></span><br><span class="line">		<span class="keyword">if</span> (tp-&gt;ucopy.task == current &amp;&amp;</span><br><span class="line">		    tp-&gt;copied_seq == tp-&gt;rcv_nxt &amp;&amp; tp-&gt;ucopy.len &amp;&amp;</span><br><span class="line">		    <span class="built_in">sock_owned_by_user</span>(sk) &amp;&amp; !tp-&gt;urg_data) &#123;</span><br><span class="line">			<span class="type">int</span> chunk = <span class="built_in">min_t</span>(<span class="type">unsigned</span> <span class="type">int</span>, skb-&gt;len,</span><br><span class="line">					  tp-&gt;ucopy.len);</span><br><span class="line"></span><br><span class="line">			__set_current_state(TASK_RUNNING);</span><br><span class="line">...</span><br><span class="line">        <span class="comment">//如果有fin标识，会调用tcp_fin()</span></span><br><span class="line">		<span class="keyword">if</span> (<span class="built_in">TCP_SKB_CB</span>(skb)-&gt;tcp_flags &amp; TCPHDR_FIN)</span><br><span class="line">			<span class="built_in">tcp_fin</span>(sk);</span><br><span class="line">        <span class="comment">//检查乱序队列有没有数据</span></span><br><span class="line">		<span class="keyword">if</span> (!<span class="built_in">skb_queue_empty</span>(&amp;tp-&gt;out_of_order_queue)) &#123;</span><br><span class="line">		    <span class="comment">//检查乱序队列中是否有数据包可用，即是否在乱序队列中找到与当前数据包保持序列号连续的数据包</span></span><br><span class="line">			<span class="built_in">tcp_ofo_queue</span>(sk);</span><br><span class="line"></span><br><span class="line">			<span class="comment">/* RFC2581. 4.2. SHOULD send immediate ACK, when</span></span><br><span class="line"><span class="comment">			 * gap in queue is filled.</span></span><br><span class="line"><span class="comment">			 */</span></span><br><span class="line">			<span class="keyword">if</span> (<span class="built_in">skb_queue_empty</span>(&amp;tp-&gt;out_of_order_queue))</span><br><span class="line">				<span class="built_in">inet_csk</span>(sk)-&gt;icsk_ack.pingpong = <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">...</span><br><span class="line">		<span class="comment">/* If window is closed, drop tail of packet. But after</span></span><br><span class="line"><span class="comment">		 * remembering D-SACK for its head made in previous line.</span></span><br><span class="line"><span class="comment">		 */</span></span><br><span class="line">		<span class="keyword">if</span> (!<span class="built_in">tcp_receive_window</span>(tp))</span><br><span class="line">			<span class="keyword">goto</span> out_of_window;</span><br><span class="line">		<span class="keyword">goto</span> queue_and_out;</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="comment">//如果是乱序的，通过此函数加入乱序队列</span></span><br><span class="line">	<span class="built_in">tcp_data_queue_ofo</span>(sk, skb);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://elixir.bootlin.com/linux/v3.19.8/source/net/ipv4/tcp_input.c#L4214">tcp_input.c&#x2F;tcp_data_queue_ofo()</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">static void tcp_data_queue_ofo(struct sock *sk, struct sk_buff *skb)</span><br><span class="line">&#123;</span><br><span class="line">    //红黑树结构，有点复杂，自己研究</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="在TIME-WAIT状态的-TCP-连接，收到-SYN-后会发生什么？"><a href="#在TIME-WAIT状态的-TCP-连接，收到-SYN-后会发生什么？" class="headerlink" title="在TIME_WAIT状态的 TCP 连接，收到 SYN 后会发生什么？"></a>在TIME_WAIT状态的 TCP 连接，收到 SYN 后会发生什么？</h4><p>在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？</p>
<p>针对这个问题，<strong>关键是要看 SYN 的「序列号和时间戳」是否合法</strong><br>合法 SYN：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要大，并且 SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要大。<br>非法 SYN：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要小，或者 SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要小。</p>
<p><a href="#target2">点击此处跳转到TCP时间戳和序列号回绕(PAWS)</a></p>
<p>如果处于 TIME_WAIT 状态的连接收到「合法的 SYN 」后，<strong>就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态</strong>，接着就能进行建立连接过程。<br>如果处于 TIME_WAIT 状态的连接收到「非法的 SYN 」后，<strong>就会再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号，就回 RST 报文给服务端</strong>。</p>
<p>那么处于 TIME_WAIT 状态的连接，收到 RST 会断开连接吗？</p>
<p>net.ipv4.tcp_rfc1337 这个内核参数（默认情况是为 0）：<br>如果这个参数设置为 0， 收到 RST 报文会提前结束 TIME_WAIT 状态，释放连接。<br>如果这个参数设置为 1， 就会丢掉 RST 报文。</p>
<h3 id="TCP保活机制"><a href="#TCP保活机制" class="headerlink" title="TCP保活机制"></a>TCP保活机制</h3><p>TCP保活(KeepAlive)功能工作过程中，开启该功能的一端会发现对方处于以下四种状态之一：</p>
<ol>
<li><p>对方主机仍在工作，并且可以到达。此时请求端将保活计时器重置。如果在计时器超时之前应用程序通过该连接传输数据，计时器再次被设定为保活时间值。</p>
</li>
<li><p>对方主机已经崩溃，包括已经关闭或者正在重新启动。这时对方的TCP将不会响应。请求端不会接收到响应报文，并在经过保活时间间隔指定的时间后超时。超时前，请求端会持续发送探测报文，一共发送保活探测数指定次数的探测报文，如果请求端没有收到任何探测报文的响应，那么它将认为对方主机已经关闭，连接也将被断开。</p>
</li>
<li><p>客户主机崩溃并且已重启。在这种情况下，请求端会收到一个对其保活探测报文的响应，但这个响应是一个重置报文段RST，请求端将会断开连接。</p>
</li>
<li><p>对方主机仍在工作，但是由于某些原因不能到达请求端（例如网络无法传输，而且可能使用ICMP通知也可能不通知对方这一事实）。这种情况与状态2相同，因为TCP不能区分状态2与状态4，结果是都没有收到探测报文的响应。</p>
</li>
</ol>
<p>其存在以下两点主要弊端：</p>
<ol>
<li>在出现短暂的网络错误的时候，保活机制会使一个好的连接断开；</li>
<li>保活机制会占用不必要的带宽；</li>
</ol>
<h4 id="应用层自己实现的心跳包"><a href="#应用层自己实现的心跳包" class="headerlink" title="应用层自己实现的心跳包"></a>应用层自己实现的心跳包</h4><p>由应用程序自己发送心跳包来检测连接是否正常，大致的方法是：服务器在一个 Timer事件中定时 向客户端发送一个短小精悍的数据包，然后启动一个低级别的线程，在该线程中不断检测客户端的回应， 如果在一定时间内没有收到客户端的回应，即认为客户端已经掉线；同样，如果客户端在一定时间内没 有收到服务器的心跳包，则认为连接不可用。</p>
<h4 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h4><ol>
<li><p>TCP自带的KeepAlive使用简单，发送的数据包相比应用层心跳检测包更小，仅提供检测连接功能</p>
</li>
<li><p>应用层心跳包不依赖于传输层协议，无论传输层协议是TCP还是UDP都可以用</p>
</li>
<li><p>应用层心跳包可以定制，可以应对更复杂的情况或传输一些额外信息</p>
</li>
<li><p>KeepAlive仅代表连接保持着，而心跳包往往还代表客户端可正常工作</p>
</li>
</ol>
<h3 id="TCP可靠传输"><a href="#TCP可靠传输" class="headerlink" title="TCP可靠传输"></a>TCP可靠传输</h3><h4 id="超时重传"><a href="#超时重传" class="headerlink" title="超时重传"></a>超时重传</h4><p><img data-src="/mybook.github.io/289163016260231.png"></p>
<p>当超时时间 RTO 较大时，重发就慢，丢了老半天才重发，没有效率，性能差；<br>当超时时间 RTO 较小时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。<br>精确的测量超时时间 RTO 的值是非常重要的，这可让重传机制更高效。超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。</p>
<p> Linux 是如何计算 RTO 的呢？估计往返时间，通常需要采样以下两个：</p>
<ol>
<li>需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个平滑 RTT 的值，而且这个值还是要不断变化的，因为网络状况不断地变化。</li>
<li>除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有一个大的波动的话，很难被发现的情况。</li>
</ol>
<p>RFC6289 建议使用以下的公式计算 RTO：</p>
<p><img data-src="/mybook.github.io/589313816260408.png"></p>
<p>其中 SRTT 是计算平滑的RTT ，DevRTR 是计算平滑的RTT 与 最新 RTT 的差距。<br>在 Linux 下，α &#x3D; 0.125，β &#x3D; 0.25， μ &#x3D; 1，∂ &#x3D; 4。别问怎么来的，问就是大量实验中调出来的。<br>每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。</p>
<h4 id="快速重传"><a href="#快速重传" class="headerlink" title="快速重传"></a><span id="target1">快速重传</span></h4><p>快速重传机制，它不以时间为驱动，而是以数据驱动重传。</p>
<p><img data-src="/mybook.github.io/53474316245960.png"></p>
<ul>
<li>第一份 Seq1 先送到了，于是就 Ack 回 2；</li>
<li>结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；</li>
<li>后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；</li>
<li>发送端收到了三个 Ack &#x3D; 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。</li>
<li>最后，收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。</li>
</ul>
<p>此时会引出一个问题：只丢Seq2和Seq2、Seq3都丢失了，都是回复 ACK2 给发送方，但是发送方并不清楚这连续的 ACK2 是接收方收到哪个报文而回复的， 那是选择重传 Seq2 一个报文，还是重传 Seq2 之后已发送的所有报文呢</p>
<h4 id="SACK-选择性确认"><a href="#SACK-选择性确认" class="headerlink" title="SACK(选择性确认)"></a>SACK(选择性确认)</h4><p>需要在 TCP 头部「选项」字段里加一个 SACK 的东西，<strong>它可以将已收到的数据的信息发送给「发送方」</strong>，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以<strong>只重传丢失的数据</strong>。<br>发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 SACK 信息发现只有 200~299 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。</p>
<p><img data-src="/mybook.github.io/95104917262239.png"></p>
<p>如果要支持 SACK，必须双方都要支持。在 Linux 下，可以通过 net.ipv4.tcp_sack 参数打开这个功能（Linux 2.4 后默认打开）。</p>
<h4 id="Duplicate-SACK"><a href="#Duplicate-SACK" class="headerlink" title="Duplicate SACK"></a>Duplicate SACK</h4><p>Duplicate SACK 又称 D-SACK，其主要使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。</p>
<ul>
<li>「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）</li>
<li>于是「接收方」发现数据是重复收到的，于是回了一个 SACK &#x3D; 3000<del>3500，告诉「发送方」 3000</del>3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 D-SACK。</li>
<li>这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。</li>
</ul>
<p><img data-src="/mybook.github.io/154375917255284.png"></p>
<ul>
<li>数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。</li>
<li>而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；</li>
<li>所以「接收方」回了一个 SACK&#x3D;1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。</li>
<li>这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。</li>
</ul>
<p><img data-src="/mybook.github.io/511880018252051.png"></p>
<p>D-SACK 有这么几个好处：</p>
<ol>
<li>可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;</li>
<li>可以知道是不是「发送方」的数据包被网络延迟了;</li>
<li>可以知道网络中是不是把「发送方」的数据包给复制了;</li>
</ol>
<p>在 Linux 下可以通过 net.ipv4.tcp_dsack 参数开启&#x2F;关闭这个功能（Linux 2.4 后默认打开）。</p>
<h4 id="校验和"><a href="#校验和" class="headerlink" title="校验和"></a>校验和</h4><p>发送方：在发送数据之前计算检验和，并进行校验和的填充。<br>接收方：收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方的进行比对。<br>注意：如果接收方比对校验和与发送方不一致，那么数据一定传输有误。但是如果接收方比对校验和与发送方一致，数据不一定传输成功。</p>
<p><img data-src="/mybook.github.io/1864845172004.png"></p>
<h4 id="停止等待"><a href="#停止等待" class="headerlink" title="停止等待"></a>停止等待</h4><p>停止等待”就是每发送完一个分组就停止发送，等待对方的确认。在收到确认后再发送下一个分组<br>序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。这也是TCP传输可靠性的保证之一。</p>
<p><img data-src="/mybook.github.io/2651946189884.png"></p>
<h4 id="确认迟到"><a href="#确认迟到" class="headerlink" title="确认迟到"></a>确认迟到</h4><p><img data-src="/mybook.github.io/5192010194990.png"></p>
<ul>
<li>A收到重复的确认后，直接丢弃。</li>
<li>B收到重复的M1后，也直接丢弃重复的M1</li>
</ul>
<h4 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h4><p>窗口大小就是指无需等待确认应答，而可以继续发送数据的最大值。窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。</p>
<p>这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。<strong>通常窗口的大小是由接收方的窗口大小来决定的</strong>。</p>
<h5 id="累计确认"><a href="#累计确认" class="headerlink" title="累计确认"></a>累计确认</h5><p>假设窗口大小为 3 个 TCP 段，那么发送方就可以「连续发送」 3 个 TCP 段，并且中途若有 ACK 丢失，可以通过「下一个确认应答进行确认」。如下图：</p>
<p><img data-src="/mybook.github.io/301740718242382.png"></p>
<h5 id="滑动窗口协议"><a href="#滑动窗口协议" class="headerlink" title="滑动窗口协议"></a>滑动窗口协议</h5><p><strong>发送方：#2 和 #3就是发送方的滑动窗口</strong><br>#1 是已发送并收到 ACK确认的数据<br>#2 是已发送但未收到 ACK确认的数据<br>#3 是未发送但总大小在接收方处理范围内（接收方还有空间）<br>#4 是未发送但总大小超过接收方处理范围（接收方没有空间）<br><strong>滑动窗口在被连续确认后才进行滑动</strong>，当收到之前发送的数据 32<del>36 字节的 ACK 确认应答后，如果发送窗口的大小没有变化，则滑动窗口往右边移动5个字节，接下来 52</del>56 字节又变成了可用窗口，那么后续也就可以发送这5个字节的数据了。</p>
<p><img data-src="/mybook.github.io/450811110266181.png"></p>
<ul>
<li>SND.WND：表示发送窗口的大小（大小是由接收方指定的）；</li>
<li>SND.UNA：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。</li>
<li>SND.NXT：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。<br>那么可用窗口大小的计算就可以是：<strong>可用窗口大小 &#x3D; SND.WND -（SND.NXT - SND.UNA）</strong></li>
</ul>
<p><strong>接收方：#2就是接收窗口</strong><br>#1 + #2 是已成功接收并确认的数据（等待应用进程读取）；<br>#3 是未收到数据但可以接收的数据；<br>#4 未收到数据并不可以接收的数据；</p>
<p><img data-src="/mybook.github.io/576241410266813.png"></p>
<ul>
<li>RCV.WND：表示接收窗口的大小，它会通告给发送方。</li>
<li>RCV.NXT：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。</li>
</ul>
<p><img data-src="/mybook.github.io/341123510257549.png"></p>
<p><strong>思考丢包的情形？</strong><br><strong>为了防止丢包的情况产生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。</strong></p>
<h6 id="TCP的”死锁”"><a href="#TCP的”死锁”" class="headerlink" title="TCP的”死锁”"></a>TCP的”死锁”</h6><p>当发生窗口关闭时，接收方处理完数据后，会向发送方通告一个窗口非 0 的 ACK 报文，如果这个通告窗口的 ACK 报文在网络中丢失了，这会导致发送方一直等待接收方的非 0 窗口通知，接收方也一直等待发送方的数据，如不采取措施，这种相互等待的过程，会造成了死锁的现象。</p>
<p>只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。<strong>如果持续计时器超时，就会发送窗口探测报文</strong>，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。</p>
<h5 id="糊涂窗口综合症"><a href="#糊涂窗口综合症" class="headerlink" title="糊涂窗口综合症"></a>糊涂窗口综合症</h5><p>如果发送端为产生数据很慢的应用程序服务，例如一次产生一个字节。这个应用程序一次将一个字节的数据写入发送端的TCP的缓存。如果发送端的TCP没有特定的指令，它就产生只包括一个字节数据的报文段。结果有很多41字节的IP数据报就在互连网中传来传去。(大车拉少人)</p>
<p>就要同时解决两个问题就可以了：</p>
<ol>
<li>让接收方不通告小窗口给发送方</li>
<li>让发送方避免发送小数据</li>
</ol>
<p>接收方策略如下:<br>当「窗口大小」小于 MSS 与 1&#x2F;2 缓存大小中的最小值时，就会向发送方通告窗口为 0，也就阻止了发送方再发数据过来。</p>
<p>发送方策略如下:<br>防止发送端的TCP逐个字节地发送数据。必须强迫发送端的TCP收集数据，然后用一个更大的数据块来发送。发送端的TCP要等待多长时间呢？如果它等待过长，它就会使整个的过程产生较长的时延。如果它的等待时间不够长，它就可能发送较小的报文段。</p>
<p>使用 Nagle 算法，该算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才可以发送数据：</p>
<p>条件一：要等到窗口大小 &gt;&#x3D; MSS 并且 数据大小 &gt;&#x3D; MSS；<br>条件二：收到之前发送数据的 ack 回包；</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> 有数据要发送 &#123;</span><br><span class="line">    <span class="keyword">if</span> 可用窗口大小 &gt;= MSS <span class="keyword">and</span> 可发送的数据 &gt;= MSS &#123;</span><br><span class="line">    	立刻发送MSS大小的数据</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> 有未确认的数据 &#123;</span><br><span class="line">            将数据放入缓存等待接收ACK</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            立刻发送数据</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>注意，如果接收方不能满足「不通告小窗口给发送方」，那么即使开了 Nagle 算法，也无法避免糊涂窗口综合症，因为如果对端 ACK 回复很快的话（达到 Nagle 算法的条件二），Nagle 算法就不会拼接太多的数据包，这种情况下依然会有小数据包的传输，网络总体的利用率依然很低。所以，<strong>接收方得满足「不通告小窗口给发送方」+ 发送方开启 Nagle 算法，才能避免糊涂窗口综合症</strong>。</p>
<h4 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h4><h5 id="慢开始"><a href="#慢开始" class="headerlink" title="慢开始"></a>慢开始</h5><p>拥塞窗口cwnd，发送窗口swnd<br>慢开始算法的思路就是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是说由小到大逐渐增加拥塞窗口的大小。拥塞窗口的增长是指数级别的。慢启动的机制只是说明在开始的时候发送的少，发送的慢，但是增长的速度是非常快的。</p>
<p><img data-src="/mybook.github.io/520560911250408.png"></p>
<p>慢启动门限ssthresh状态变量。<br>当 cwnd &lt; ssthresh 时，使用慢启动算法。<br>当 cwnd &gt;&#x3D; ssthresh 时，就会使用「拥塞避免算法」。</p>
<h5 id="拥塞避免"><a href="#拥塞避免" class="headerlink" title="拥塞避免"></a>拥塞避免</h5><p>为了控制拥塞窗口的增长，不能使拥塞窗口单纯的加倍，设置一个<strong>拥塞窗口的阈值</strong>，当拥塞窗口大小超过阈值时，不能再按照指数来增长，而是线性的增长。<br>在慢启动开始的时候，慢启动的阈值等于窗口的最大值，一旦造成网络拥塞，发生超时重传时，慢启动的阈值会为原来的一半（这里的原来指的是发生网络拥塞时拥塞窗口的大小），同时拥塞窗口重置为 1</p>
<p><img data-src="/mybook.github.io/578581711264325.png"></p>
<h5 id="快速重传-1"><a href="#快速重传-1" class="headerlink" title="快速重传"></a>快速重传</h5><p><a href="#target1">点击此处跳转到快速重传</a></p>
<h5 id="快恢复"><a href="#快恢复" class="headerlink" title="快恢复"></a>快恢复</h5><p>考虑到如果网络出现拥塞的话就不会收到好几个重复的确认，所以发送方现在认为网络可能没有出现拥塞。所以此时不执行慢开始算法，而是将cwnd设置为ssthresh减半后的值，然后执行拥塞避免算法，使cwnd缓慢增大。</p>
<p><img data-src="/mybook.github.io/208812611270847.png"></p>
<h3 id="高性能TCP"><a href="#高性能TCP" class="headerlink" title="高性能TCP"></a>高性能TCP</h3><h4 id="TCP快速连接"><a href="#TCP快速连接" class="headerlink" title="TCP快速连接"></a>TCP快速连接</h4><p>客户端在向服务端发起 HTTP GET 请求时，一个完整的交互过程，需要 2.5 个 RTT 的时延。<strong>由于第三次握手是可以携带数据的</strong>，这时如果在第三次握手发起 HTTP GET 请求，需要 2 个 RTT 的时延。</p>
<p><img data-src="/mybook.github.io/8723711258187.png"></p>
<p>在 Linux 3.7 内核版本中，提供了 TCP Fast Open 功能，内核参数：net.ipv4.tcp_fastopen，0-关闭；1-作为客户端使用 Fast Open 功能；2-作为服务端使用 Fast Open 功能；3-无论作为客户端还是服务器，都可以使用 Fast Open 功能这个功能可以减少 TCP 连接建立的时延。</p>
<p><img data-src="/mybook.github.io/591953711245178.png"></p>
<p>在第一次建立连接的时候，服务端在第二次握手产生一个 Cookie （已加密）并通过 SYN、ACK 包一起发给客户端，在下次请求的时候，<strong>客户端在 SYN 包带上 Cookie 发给服务端，就提前可以跳过三次握手的过程</strong>，因为 Cookie 中维护了一些信息，服务端可以从 Cookie 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；</p>
<h4 id="如何理解是-TCP-面向字节流协议"><a href="#如何理解是-TCP-面向字节流协议" class="headerlink" title="如何理解是 TCP 面向字节流协议"></a>如何理解是 TCP 面向字节流协议</h4><p>当消息通过 UDP 协议传输时，<strong>操作系统不会对消息进行拆分</strong>，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是每个 UDP 报文就是一个用户消息的边界，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。<br>操作系统在收到 UDP 报文后，会将其插入到队列里，队列里的每一个元素就是一个 UDP 报文，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区。</p>
<p><img data-src="/mybook.github.io/263713616268767.png"></p>
<p>当用户消息通过 TCP 协议传输时，消息可能会被操作系统分组成多个的 TCP 报文，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。例如：”Hello World”、”Hello” + “ World”、”He”+”llo World”等各种情况，所以，我们不能认为一个用户消息对应一个 TCP 报文，正因为这样，所以 TCP 是面向字节流的协议。</p>
<h4 id="TCP粘包和拆包"><a href="#TCP粘包和拆包" class="headerlink" title="TCP粘包和拆包"></a>TCP粘包和拆包</h4><p>如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况，这时接收方不知道消息的边界的话，是无法读出有效的消息。</p>
<h5 id="TCP发生粘包和拆包原因"><a href="#TCP发生粘包和拆包原因" class="headerlink" title="TCP发生粘包和拆包原因"></a>TCP发生粘包和拆包原因</h5><ol>
<li>要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。</li>
<li>待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。</li>
<li>要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。</li>
<li>接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包</li>
</ol>
<h5 id="粘包的解决办法"><a href="#粘包的解决办法" class="headerlink" title="粘包的解决办法"></a>粘包的解决办法</h5><p>解决问题的关键在于<strong>如何给每个数据包添加边界信息</strong>，常用的方法有如下几个：</p>
<p>一般有三种方式分包的方式：</p>
<ol>
<li>固定长度的消息<br>规定一个消息的长度是 64 个字节，当接收方接满 64 个字节，就认为这个内容是一个完整且有效的消息。但是这种方式灵活性不高，实际中很少用。</li>
<li>特殊字符作为边界<br>HTTP 是一个非常好的例子。</li>
</ol>
<p><img data-src="/mybook.github.io/409224516247382.png"></p>
<ol start="3">
<li><p>自定义消息结构。<br>首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> &#123; </span><br><span class="line">    <span class="type">u_int32_t</span> message_length; </span><br><span class="line">    <span class="type">char</span> message_data[]; </span><br><span class="line">&#125; message;</span><br></pre></td></tr></table></figure>
</li>
<li><p>发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。</p>
</li>
</ol>
<h5 id="UDP协议是否会发生粘包问题"><a href="#UDP协议是否会发生粘包问题" class="headerlink" title="UDP协议是否会发生粘包问题"></a>UDP协议是否会发生粘包问题</h5><p>不会。UDP是基于报文发送的，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。</p>
<h4 id="有一个-IP-的服务端监听了一个端口，它的-TCP-的最大连接数是多少？"><a href="#有一个-IP-的服务端监听了一个端口，它的-TCP-的最大连接数是多少？" class="headerlink" title="有一个 IP 的服务端监听了一个端口，它的 TCP 的最大连接数是多少？"></a>有一个 IP 的服务端监听了一个端口，它的 TCP 的最大连接数是多少？</h4><p>客户端 IP 和端口是可变的，最大TCP连接数 &#x3D; 客户端的 IP 数 * 客户端的端口数</p>
<p>对 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，所以，服务端单机最大 TCP 连接数，约为 2 的 48 次方。</p>
<p>服务端最大并发 TCP 连接数远不能达到理论上限，会受以下因素影响：</p>
<ul>
<li>文件描述符限制，每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 Too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：<br>系统级：当前系统可打开的最大数量，通过 cat &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;file-max 查看；<br>用户级：指定用户可打开的最大数量，通过 cat &#x2F;etc&#x2F;security&#x2F;limits.conf 查看；<br>进程级：单个进程可打开的最大数量，通过 cat &#x2F;proc&#x2F;sys&#x2F;fs&#x2F;nr_open 查看；</li>
<li>内存限制，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。</li>
</ul>
<h4 id="TCP-和-UDP-可以同时绑定相同的端口吗？"><a href="#TCP-和-UDP-可以同时绑定相同的端口吗？" class="headerlink" title="TCP 和 UDP 可以同时绑定相同的端口吗？"></a>TCP 和 UDP 可以同时绑定相同的端口吗？</h4><p>可以，<strong>在操作系统的协议栈中，TCP和UDP是两个不同的模块</strong>，当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP&#x2F;UDP，所以可以根据这个信息确定送给哪个模块（TCP&#x2F;UDP）处理，送给 TCP&#x2F;UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。</p>
<p><img data-src="/mybook.github.io/406574211246216.png"></p>
<h4 id="多个-TCP-服务进程可以绑定同一个端口吗？"><a href="#多个-TCP-服务进程可以绑定同一个端口吗？" class="headerlink" title="多个 TCP 服务进程可以绑定同一个端口吗？"></a>多个 TCP 服务进程可以绑定同一个端口吗？</h4><p><strong>如果两个 TCP 服务进程同时绑定的 IP 地址和端口都相同，那么执行 bind() 时候就会出错，错误是“Address already in use”。</strong></p>
<p>注意，如果 TCP 服务进程 A 绑定的地址是 0.0.0.0 和端口 8888，而如果 TCP 服务进程 B 绑定的地址是 192.168.1.100 地址（或者其他地址）和端口 8888，那么执行 bind() 时候也会出错。这是因为 0.0.0.0 地址比较特殊，代表任意地址，意味着绑定了 0.0.0.0 地址，相当于把主机上的所有 IP 地址都绑定了。</p>
<h4 id="重启-TCP-服务进程时，为什么会有“Address-in-use”的报错信息？"><a href="#重启-TCP-服务进程时，为什么会有“Address-in-use”的报错信息？" class="headerlink" title="重启 TCP 服务进程时，为什么会有“Address in use”的报错信息？"></a>重启 TCP 服务进程时，为什么会有“Address in use”的报错信息？</h4><p>TCP四次挥手后，会在 TIME_WAIT 这个状态里停留一段时间，这个时间大约为 2MSL。</p>
<p>当 TCP 服务进程重启时，服务端会出现 TIME_WAIT 状态的连接，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行 bind() 函数的时候，就会返回了 Address already in use 的错误。</p>
<p>如何解决：<br>对 socket 设置 SO_REUSEADDR 属性，可以解决这个问题。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> on = <span class="number">1</span>;</span><br><span class="line"><span class="built_in">setsockopt</span>(listenfd, SOL_SOCKET, SO_REUSEADDR, &amp;on, <span class="built_in">sizeof</span>(on));</span><br></pre></td></tr></table></figure>
<p>如果当前启动进程绑定的 IP+PORT 与处于TIME_WAIT 状态的连接占用的 IP+PORT 存在冲突，但是新启动的进程使用了 SO_REUSEADDR 选项，那么该进程就可以绑定成功。</p>
<h4 id="客户端的端口可以重复使用吗？"><a href="#客户端的端口可以重复使用吗？" class="headerlink" title="客户端的端口可以重复使用吗？"></a>客户端的端口可以重复使用吗？</h4><p>TCP 连接是由四元组（源IP地址，源端口，目的IP地址，目的端口）唯一确认的，那么<strong>只要四元组中其中一个元素发生了变化，那么就表示不同的 TCP 连接的</strong>。所以如果客户端已使用端口 64992 与服务端 A 建立了连接，那么客户端要与服务端 B 建立连接，还是可以使用端口 64992 的，因为内核是通过四元祖信息来定位一个 TCP 连接的，并不会因为客户端的端口号相同，而导致连接冲突的问题。</p>
<h4 id="为什么每次建立-TCP-连接时，初始化的序列号都要求不一样呢？"><a href="#为什么每次建立-TCP-连接时，初始化的序列号都要求不一样呢？" class="headerlink" title="为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？"></a>为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？</h4><ol>
<li><p>为了防止历史报文被下一个相同四元组的连接接收（主要方面）；<br>如果每次建立连接，客户端和服务端的初始化序列号都是一样的话，很容易出现历史报文被下一个相同四元组的连接接收的问题。</p>
<p> <strong>已经有了TIME_WAIT 状态且持续 2 MSL 时长，历史报文不是早就消散了吗?</strong></p>
<blockquote>
<p>思考下面这种情况：</p>
</blockquote>
<p> 客户端和服务端建立一个 TCP 连接，在客户端发送数据包被网络阻塞了，然后超时重传了这个数据包，而此时服务端设备断电重启了，之前与客户端建立的连接就消失了，于是在收到客户端的数据包的时候就会发送 RST 报文。紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。</p>
</li>
</ol>
<p>如果每次建立连接客户端和服务端的初始化序列号都「不一样」，<strong>就有大概率因为历史报文的序列号「不在」对方接收窗口</strong>，从而很大程度上避免了历史报文，如果每次的初始化序列号一样，在对方接收窗口的概率就会变大。而且TCP产生的随机数是会基于时钟计时器递增的，基本不可能会随机成一样的初始化序列号。</p>
<hr>
<p><span id="target2"><strong>但是也不是完全避免：</strong></span></p>
<blockquote>
<ul>
<li>序列号(SEQ)，是 TCP 一个头部字段，标识了 TCP 发送端到 TCP 接收端的数据流的一个字节，因为 TCP 是面向字节流的可靠协议，为了保证消息的顺序性和可靠性，TCP 为每个传输方向上的每个字节都赋予了一个编号，以便于传输成功后确认、丢失后重传以及在接收端保证不会乱序。序列号是一个 32 位的无符号数，<strong>因此在到达 4G 之后再循环回到 0</strong>。</li>
<li>初始序列号(ISN)，在 TCP 建立连接的时候，客户端和服务端都会各自生成一个初始序列号，它是基于时钟生成的一个随机数，来保证每个连接都拥有不同的初始序列号。初始化序列号可被视为一个 32 位的计数器，该计数器的数值每 4 微秒加 1，<strong>循环一次需要 4.55 小时</strong>。</li>
</ul>
</blockquote>
<p><strong>序列号和初始化序列号并不是无限递增的，会发生回绕为初始值的情况</strong>，这意味着无法根据序列号来判断新老数据。为了解决这个问题，就需要有 TCP 时间戳。tcp_timestamps 参数是默认开启的，开启了 tcp_timestamps 参数，TCP 头部就会使用时间戳选项，它有两个好处，<strong>一个是便于精确计算 RTT ，另一个是能防止序列号回绕（PAWS）</strong>。<br>在开启 tcp_timestamps 选项情况下，一台机器发的所有 TCP 包都会带上发送时的时间戳，PAWS 要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，<strong>如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包</strong>。</p>
<ol start="2">
<li>为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收；</li>
</ol>
<h4 id="既然-IP-层会分片，为什么-TCP-层还需要-MSS-呢？"><a href="#既然-IP-层会分片，为什么-TCP-层还需要-MSS-呢？" class="headerlink" title="既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？"></a>既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？</h4><p><img data-src="/mybook.github.io/444213610272904.png"></p>
<p>如果一个 IP 分片丢失，整个 IP 报文的所有分片都得重传。<strong>因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。</strong><br>为了达到最佳的传输效能 TCP 协议在建立连接的时候通常要协商双方的 MSS 值，<strong>当 TCP 层发现数据超过 MSS 时，则就先会进行分片，当然由它形成的 IP 包的长度也就不会大于 MTU ，自然也就不用 IP 分片了。</strong><br>经过 TCP 层分片后，如果一个 TCP 分片丢失后，进行重发时也是以 MSS 为单位，而不用重传所有的分片，大大增加了重传的效率。</p>
<p><strong>UDP层的分片</strong></p>
<blockquote>
<ol>
<li>由于UDP是不需要保证可靠性的，那么它就不会保存发送的数据包，TCP之所以保存发送的数据包是因为要进行重传。所以UDP本身是没有像TCP一样的发送缓冲区的。这就导致了对UDP进行write系统调用的时候，实际上应用层的数据是直接传输到IP层，由于IP层本身也不会有缓冲区，数据就会直接写到链路层的输出队列中。</li>
<li>在这种情况下，IP层会不会对来自UDP的数据进行分片呢？这个取决于UDP数据报的大小。如果UDP数据报的大小大于链路层的MTU，那么IP层就会直接进行分片，然后在发送到链路层的输出队列中，反之，则不会进行分片，直接加上IP头部发送到链路层的输出队列中。</li>
</ol>
</blockquote>
<p><img data-src="/mybook.github.io/2871612129098.png"></p>
<h4 id="TCP-连接，一端断电和进程崩溃有什么区别？"><a href="#TCP-连接，一端断电和进程崩溃有什么区别？" class="headerlink" title="TCP 连接，一端断电和进程崩溃有什么区别？"></a>TCP 连接，一端断电和进程崩溃有什么区别？</h4><p>在没有开启 TCP keepalive，且双方一直没有数据交互的情况下，如果客户端的「主机崩溃」了，服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态，直到服务端重启进程。</p>
<p>进程崩溃，在 kill 掉进程后，服务端会发送 FIN 报文，与客户端进行四次挥手。</p>
<p>有数据传输的场景：</p>
<ol>
<li>客户端主机宕机，又迅速重启<br>只要有一方重启完成后，收到之前 TCP 连接的报文，都会回复 RST 报文，以断开连接。</li>
<li>客户端主机宕机，一直没有重启<br>这种情况，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/sys/net/ipv4/tcp_retries2</span><br><span class="line">15</span><br></pre></td></tr></table></figure>

<p>内核会根据 tcp_retries2 设置的值，计算出一个 timeout，如果重传间隔超过这个 timeout，则认为超过了阈值，就会停止重传，然后就会断开 TCP 连接。</p>
<h4 id="拔掉网线后，-原本的-TCP-连接还存在吗？"><a href="#拔掉网线后，-原本的-TCP-连接还存在吗？" class="headerlink" title="拔掉网线后， 原本的 TCP 连接还存在吗？"></a>拔掉网线后， 原本的 TCP 连接还存在吗？</h4><p>存在，TCP在内核中以struct socket结构体存在，当拔掉网线的时候，操作系统并不会变更该结构体的任何内容，所以 TCP 连接的状态也不会发生改变。所以拔网线的动作不会影响TCP的状态<br>后续：</p>
<ol>
<li><p>拔掉网线后，有数据传输，触发超时重传机制<br>如果在服务端重传报文的过程中，客户端刚好把网线插回去了，无事发生。<br>如果在服务端重传报文的过程中，客户端一直没有将网线插回去，服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，于是服务端的 TCP 连接就会断开。而等客户端插回网线后，如果客户端向服务端发送了数据，由于服务端已经没有与客户端相同四元祖的 TCP 连接了，因此服务端内核就会回复 RST 报文，客户端收到后就会释放该 TCP 连接。</p>
</li>
<li><p>拔掉网线后，没有数据传输<br>如果没有开启 TCP keepalive 机制，在客户端拔掉网线后，那么客户端和服务端的 TCP 连接将会一直保持存在。<br>如果开启了 TCP keepalive 机制，对端主机宕机，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，没有响应连续几次，达到保活探测次数后，TCP 会报告该连接已经死亡。</p>
</li>
</ol>
<h4 id="为什么-tcp-tw-reuse-默认是关闭的？"><a href="#为什么-tcp-tw-reuse-默认是关闭的？" class="headerlink" title="为什么 tcp_tw_reuse 默认是关闭的？"></a>为什么 tcp_tw_reuse 默认是关闭的？</h4><p>问题一：因为快速复用 TIME_WAIT 状态的端口，导致新连接可能<strong>被回绕序列号的 RST 报文断开了</strong>，而如果不跳过 TIME_WAIT 状态，而是停留 2MSL 时长，那么这个 RST 报文就不会出现下一个新的连接。</p>
<p><img data-src="/mybook.github.io/225572615273177.png"></p>
<p>前面被网络延迟 RST 报文这时抵达了客户端，而且 RST 报文的序列号在客户端的接收窗口内，由于防回绕序列号算法不会防止过期的 RST，所以 RST 报文会被客户端接受了，于是客户端的连接就断开了。</p>
<p>问题二：如果第四次挥手的 ACK 报文丢失了，服务端会触发超时重传，重传第三次挥手报文，处于 syn_sent 状态的客户端收到服务端重传第三次挥手报文，则会回 RST 给服务端。</p>
<p><img data-src="/mybook.github.io/347242915273272.png"></p>
<p>如果 TIME_WAIT 状态被快速复用后，刚好第四次挥手的 ACK 报文丢失了，那客户端复用 TIME_WAIT 状态后发送的 SYN 报文被处于 last_ack 状态的服务端收到了会发生什么呢？</p>
<p>处于 last_ack 状态的服务端收到了 SYN 报文后，会回复确认号与服务端上一次发送 ACK 报文一样的 ACK 报文，这个 ACK 报文称为 Challenge ACK ，并不是确认收到 SYN 报文。处于 syn_sent 状态的客户端收到服务端的 Challenge ACK 后，发现不是自己期望收到的确认号，于是就会回复 RST 报文，服务端收到后，就会断开连接。</p>
<h4 id="没有listen，能建立TCP连接吗？"><a href="#没有listen，能建立TCP连接吗？" class="headerlink" title="没有listen，能建立TCP连接吗？"></a>没有listen，能建立TCP连接吗？</h4><p>答案，是可以的，<strong>客户端是可以自己连自己的形成连接（TCP自连接），也可以两个客户端同时向对方发出请求建立连接（TCP同时打开）</strong>，这两个情况都有个共同点，就是没有服务端参与，也就是没有listen，就能建立连接。</p>
<p>执行 listen 方法时，会创建半连接队列和全连接队列。但是客户端没有listen方法，是如何做到的？<br>内核还有个全局 hash 表，可以用于存放 sock 连接的信息。这个全局 hash 表其实还细分为 ehash，bhash和listen_hash等。在 TCP 自连接的情况中，客户端在 connect 方法时，最后会将自己的连接信息放入到这个全局 hash 表中，然后将信息发出，消息在经过回环地址重新回到 TCP 传输层的时候，就会根据 IP + 端口信息，再一次从这个全局 hash 中取出信息。于是握手包一来一回，最后成功建立连接。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/types.h&gt;</span> </span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/socket.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;netinet/in.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;errno.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LOCAL_IP_ADDR		(0x7F000001) <span class="comment">// IP 127.0.0.1</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LOCAL_TCP_PORT		(34567) <span class="comment">// 端口</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">struct</span> <span class="title class_">sockaddr_in</span> local, peer;</span><br><span class="line">	<span class="type">int</span> ret;</span><br><span class="line">	<span class="type">char</span> buf[<span class="number">128</span>];</span><br><span class="line">	<span class="type">int</span> sock = <span class="built_in">socket</span>(AF_INET, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">	<span class="built_in">memset</span>(&amp;local, <span class="number">0</span>, <span class="built_in">sizeof</span>(local));</span><br><span class="line">	<span class="built_in">memset</span>(&amp;peer, <span class="number">0</span>, <span class="built_in">sizeof</span>(peer));</span><br><span class="line"></span><br><span class="line">	local.sin_family = AF_INET;</span><br><span class="line">	local.sin_port = <span class="built_in">htons</span>(LOCAL_TCP_PORT);</span><br><span class="line">	local.sin_addr.s_addr = <span class="built_in">htonl</span>(LOCAL_IP_ADDR);</span><br><span class="line"></span><br><span class="line">	peer = local;	</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> flag = <span class="number">1</span>;</span><br><span class="line">    ret = <span class="built_in">setsockopt</span>(sock, SOL_SOCKET, SO_REUSEADDR, &amp;flag, <span class="built_in">sizeof</span>(flag));</span><br><span class="line">    <span class="keyword">if</span> (ret == <span class="number">-1</span>) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Fail to setsocket SO_REUSEADDR: %s\n&quot;</span>, <span class="built_in">strerror</span>(errno));</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">	ret = <span class="built_in">bind</span>(sock, (<span class="type">const</span> <span class="keyword">struct</span> sockaddr *)&amp;local, <span class="built_in">sizeof</span>(local));</span><br><span class="line">	<span class="keyword">if</span> (ret) &#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;Fail to bind: %s\n&quot;</span>, <span class="built_in">strerror</span>(errno));</span><br><span class="line">		<span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	ret = <span class="built_in">connect</span>(sock, (<span class="type">const</span> <span class="keyword">struct</span> sockaddr *)&amp;peer, <span class="built_in">sizeof</span>(peer));</span><br><span class="line">	<span class="keyword">if</span> (ret) &#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;Fail to connect myself: %s\n&quot;</span>, <span class="built_in">strerror</span>(errno));</span><br><span class="line">		<span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;Connect to myself successfully\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//发送数据</span></span><br><span class="line">	<span class="built_in">strcpy</span>(buf, <span class="string">&quot;Hello, myself~&quot;</span>);</span><br><span class="line">	<span class="built_in">send</span>(sock, buf, <span class="built_in">strlen</span>(buf), <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">	<span class="built_in">memset</span>(buf, <span class="number">0</span>, <span class="built_in">sizeof</span>(buf));</span><br><span class="line">	</span><br><span class="line">	<span class="comment">//接收数据</span></span><br><span class="line">	<span class="built_in">recv</span>(sock, buf, <span class="built_in">sizeof</span>(buf), <span class="number">0</span>);</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">&quot;Recv the msg: %s\n&quot;</span>, buf);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">sleep</span>(<span class="number">1000</span>);</span><br><span class="line">	<span class="built_in">close</span>(sock);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到 TCP socket 成功的“连接”了自己，并发送和接收了数据包，netstat 的输出更证明了 TCP 的两端地址和端口是完全相同的。<br><img data-src="/mybook.github.io/245001518260552.png"></p>
<h4 id="没有accept，能建立TCP连接吗？"><a href="#没有accept，能建立TCP连接吗？" class="headerlink" title="没有accept，能建立TCP连接吗？"></a>没有accept，能建立TCP连接吗？</h4><p>可以，建立连接的过程中根本不需要accept()参与， 执行accept()只是为了从全连接队列里取出一条连接。</p>
<p><img data-src="/mybook.github.io/389671918249238.png"></p>
<p>虽然都叫队列，但其实全连接队列<code>icsk_accept_queue</code>是个链表，而半连接队列<code>syn_table</code>是个哈希表。思考为什么这么设计？</p>
<p>补充：前面提到了预防SYN攻击可以开启 syncookies 功能：<a href="#target4">点击此处跳转到syncookies功能</a>，那么，会有一个cookies队列吗？<br>不会，如果有这样一个队列的话，碰到SYN攻击也会被打满，它是通过通信双方的IP地址端口、时间戳、MSS等信息<strong>进行实时计算</strong>的，保存在TCP报头的seq里。</p>
<h5 id="cookies方案为什么不直接取代半连接队列？"><a href="#cookies方案为什么不直接取代半连接队列？" class="headerlink" title="cookies方案为什么不直接取代半连接队列？"></a>cookies方案为什么不直接取代半连接队列？</h5><ol>
<li><p>因为cookies方案服务端并不会保存连接信息，所以如果传输过程中数据包丢了，也不会重发第二次握手的信息。</p>
</li>
<li><p>编码解码cookies，都是比较耗CPU的，利用这一点，如果此时攻击者构造大量的第三次握手包（ACK包），进行ACK攻击(通过构造大量ACK包去消耗服务端资源的攻击)，同时带上各种瞎编的cookies信息，服务端收到ACK包后以为是正经cookies，憨憨地跑去解码（耗CPU），最后发现不是正经数据包后才丢弃。</p>
</li>
</ol>
<h4 id="TCP-序列号和确认号是如何变化的？"><a href="#TCP-序列号和确认号是如何变化的？" class="headerlink" title="TCP 序列号和确认号是如何变化的？"></a>TCP 序列号和确认号是如何变化的？</h4><p>万能公式<br>公式一：序列号 &#x3D; 上一次发送的序列号 + len（数据长度）。特殊情况，如果上一次发送的报文是 SYN 报文或者 FIN 报文，则改为 上一次发送的序列号 + 1。<br>公式二：确认号 &#x3D; 上一次收到的报文中的序列号 + len（数据长度）。特殊情况，如果收到的是 SYN 报文或者 FIN 报文，则改为上一次收到的报文中的序列号 + 1。</p>
<h3 id="TCP的缺陷"><a href="#TCP的缺陷" class="headerlink" title="TCP的缺陷"></a>TCP的缺陷</h3><h4 id="升级困难"><a href="#升级困难" class="headerlink" title="升级困难"></a>升级困难</h4><p>存在与操作系统内核的协议栈，升级新的TCP需要升级内核，很麻烦</p>
<h4 id="建立连接的延迟"><a href="#建立连接的延迟" class="headerlink" title="建立连接的延迟"></a>建立连接的延迟</h4><p>现在大多数网站都是使用 HTTPS 的，这意味着在 TCP 三次握手之后，还需要经过 TLS 四次握手后，才能进行 HTTP 数据的传输，这在一定程序上增加了数据传输的延迟。</p>
<h4 id="存在队头阻塞问题"><a href="#存在队头阻塞问题" class="headerlink" title="存在队头阻塞问题"></a>存在队头阻塞问题</h4><p>TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据。</p>
<h4 id="网络迁移需要重新建立-TCP-连接"><a href="#网络迁移需要重新建立-TCP-连接" class="headerlink" title="网络迁移需要重新建立 TCP 连接"></a>网络迁移需要重新建立 TCP 连接</h4><p>当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接</p>
<h3 id="TCP一定可靠吗？"><a href="#TCP一定可靠吗？" class="headerlink" title="TCP一定可靠吗？"></a>TCP一定可靠吗？</h3><h4 id="数据包的发送流程"><a href="#数据包的发送流程" class="headerlink" title="数据包的发送流程"></a>数据包的发送流程</h4><ol>
<li><p>为了发送数据包，两端首先会通过三次握手，建立TCP连接。</p>
</li>
<li><p>一个数据包，从聊天框里发出，消息会从聊天软件所在的<strong>用户空间拷贝到内核空间的发送缓冲区</strong>（send buffer），数据包就这样顺着<strong>传输层、网络层，进入到数据链路层，在这里数据包会经过流控（qdisc），再通过RingBuffer发到物理层的网卡</strong>。数据就这样顺着网卡发到了纷繁复杂的网络世界里。这里头数据会经过n多个路由器和交换机之间的跳转，<strong>最后到达目的机器的网卡处</strong>。</p>
</li>
<li><p>此时目的机器的网卡会<strong>通知DMA将数据包信息放到RingBuffer中</strong>，再触发一个硬中断给CPU，<strong>CPU触发软中断让ksoftirqd去RingBuffer收包</strong>，于是一个数据包就这样顺着物理层，数据链路层，网络层，传输层，<strong>最后从内核空间拷贝到用户空间里的聊天软件里</strong>。</p>
</li>
</ol>
<h4 id="何时会丢包？"><a href="#何时会丢包？" class="headerlink" title="何时会丢包？"></a>何时会丢包？</h4><h5 id="建立连接时丢包"><a href="#建立连接时丢包" class="headerlink" title="建立连接时丢包"></a>建立连接时丢包</h5><p>半连接队列和全连接队列已满，那新来的包就会被丢弃。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">全连接队列溢出次数</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">netstat -s | grep overflowed</span></span><br><span class="line">    4343 times the listen queue of a socket overflowed</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">半连接队列溢出次数</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">netstat -s | grep -i <span class="string">&quot;SYNs to LISTEN sockets dropped&quot;</span></span></span><br><span class="line">    109 times the listen queue of a socket overflowed </span><br></pre></td></tr></table></figure>

<h5 id="流量控制丢包"><a href="#流量控制丢包" class="headerlink" title="流量控制丢包"></a>流量控制丢包</h5><p>如果所有数据不加控制一股脑冲入到网卡，网卡会吃不消，让数据按一定的规则排个队依次处理，也就是所谓的qdisc(Queueing Disciplines，排队规则)，这也是我们常说的流量控制机制。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ifconfig eth0</span></span><br><span class="line">eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500</span><br><span class="line">        inet 172.21.66.69  netmask 255.255.240.0  broadcast 172.21.79.255</span><br><span class="line">        inet6 fe80::216:3eff:fe25:269f  prefixlen 64  scopeid 0x20&lt;link&gt;</span><br><span class="line">        ether 00:16:3e:25:26:9f  txqueuelen 1000  (Ethernet)</span><br><span class="line">        RX packets 6962682  bytes 1119047079 (1.0 GiB)</span><br><span class="line">        RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">        TX packets 9688919  bytes 2072511384 (1.9 GiB)</span><br><span class="line">        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</span><br></pre></td></tr></table></figure>

<p>txqueuelen后面的数字1000，其实就是流控队列的长度。当发送数据过快，流控队列长度txqueuelen又不够大时，就容易出现丢包现象。查看TX下的dropped字段，当它大于0时，则有可能是发生了流控丢包。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ifconfig eth0 txqueuelen 1500 //流控队列长度从1000提升为1500.</span></span><br></pre></td></tr></table></figure>


<h5 id="网卡丢包"><a href="#网卡丢包" class="headerlink" title="网卡丢包"></a>网卡丢包</h5><ol>
<li><p>网线质量差，接触不良等</p>
</li>
<li><p>RingBuffer过小导致丢包<br>上面提到，在接收数据时，会将数据暂存到RingBuffer接收缓冲区中，然后等着内核触发软中断慢慢收走。如果这个缓冲区过小，而这时候发送的数据又过快，就有可能发生溢出，此时也会产生丢包。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ifconfig</span></span><br><span class="line">eth0:  RX errors 0  dropped 0  overruns 0  frame 0</span><br><span class="line">//查看上面的overruns指标，它记录了由于RingBuffer长度不足导致的溢出次数。</span><br></pre></td></tr></table></figure></li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">ethtool -g eth0</span></span><br><span class="line">Ring parameters for eth0:</span><br><span class="line">Pre-set maximums:</span><br><span class="line">RX:        4096</span><br><span class="line">RX Mini:    0</span><br><span class="line">RX Jumbo:    0</span><br><span class="line">TX:        4096</span><br><span class="line">Current hardware settings:</span><br><span class="line">RX:        1024</span><br><span class="line">RX Mini:    0</span><br><span class="line">RX Jumbo:    0</span><br><span class="line">TX:        1024</span><br><span class="line"></span><br><span class="line">//RingBuffer最大支持4096的长度，但现在实际只用了1024。想要修改这个长度可以执行ethtool -G eth1 rx 4096 tx 4096将发送和接收RingBuffer的长度都改为4096。</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>网卡性能不足</li>
</ol>
<h5 id="接收缓冲区丢包"><a href="#接收缓冲区丢包" class="headerlink" title="接收缓冲区丢包"></a>接收缓冲区丢包</h5><p>使用TCP socket进行网络编程的时候，内核都会分配一个发送缓冲区和一个接收缓冲区。不管是接收缓冲区还是发送缓冲区，都能看到三个数值，分别对应缓冲区的最小值，默认值和最大值 （min、default、max）。缓冲区会在min和max之间动态调整。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看接收缓冲区</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sysctl net.ipv4.tcp_rmem</span></span><br><span class="line">net.ipv4.tcp_rmem = 4096    87380   6291456</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">查看发送缓冲区</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">sysctl net.ipv4.tcp_wmem</span></span><br><span class="line">net.ipv4.tcp_wmem = 4096    16384   4194304</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>当发送缓冲区满了，如果是阻塞调用，那就会等，等到缓冲区有空位可以发数据。如果是非阻塞调用，就会立刻返回一个 EAGAIN 错误信息，意思是 Try again。让应用程序下次再重试。这种情况下一般不会发生丢包。</li>
<li>当接受缓冲区满了，它的TCP接收窗口会变为0，也就是所谓的零窗口，并且会通过数据包里的win&#x3D;0，告诉发送端。一般这种情况下，发送端就该停止发消息了，但如果这时候确实还有数据发来，就会发生丢包。</li>
</ul>
<h5 id="两端之间的网络丢包"><a href="#两端之间的网络丢包" class="headerlink" title="两端之间的网络丢包"></a>两端之间的网络丢包</h5><p>路由器和交换机还有光缆啥的</p>
<h1 id="HTTP-1"><a href="#HTTP-1" class="headerlink" title="HTTP"></a>HTTP</h1><p>HTTP 是超⽂本传输协议，也就是HyperText Transfer Protocol。<br>HTTP 是⼀个在计算机世界⾥专⻔在「两点」之间「传输」⽂字、图⽚、⾳频、视频等「超⽂本」数据的「约定和规范」。</p>
<h2 id="HTTP请求报文"><a href="#HTTP请求报文" class="headerlink" title="HTTP请求报文"></a>HTTP请求报文</h2><p><img data-src="/mybook.github.io/2040302816596.png"><br>Get请求例子，使用Charles抓取的request：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">GET /562f25980001b1b106000338.jpg HTTP/1.1</span><br><span class="line">Host    img.mukewang.com</span><br><span class="line">User-Agent    Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36</span><br><span class="line">Accept    image/webp,image/*,*/*;q=0.8</span><br><span class="line">Referer    http://www.imooc.com/</span><br><span class="line">Accept-Encoding    gzip, deflate, sdch</span><br><span class="line">Accept-Language    zh-CN,zh;q=0.8</span><br></pre></td></tr></table></figure>
<h3 id="请求行"><a href="#请求行" class="headerlink" title="请求行"></a>请求行</h3><p>用来说明请求方法，要访问的资源以及所使用的HTTP版本。GET说明请求方法为GET，jpg为要访问的资源，该行的最后一部分说明使用的是HTTP1.1版本。</p>
<h4 id="请求方法"><a href="#请求方法" class="headerlink" title="请求方法"></a>请求方法</h4><ol>
<li>GET<br>传递参数长度受限制，因为传递的参数是直接表示在地址栏中，而特定浏览器和服务器对url的长度是有限制的。因此，GET不适合用来传递私密数据，也不适合拿来传递大量数据。一般的HTTP请求大多都是GET。</li>
<li>POST<br>POST把传递的数据封装在HTTP请求数据中，以名称&#x2F;值的形式出现，可以传输大量数据，对数据量没有限制，也不会显示在URL中。表单的提交用的是POST。<br>GET ⽅法是安全且幂等的，因为它是「只读」操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。<br>POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。</li>
<li>HEAD<br>HEAD跟GET相似，不过服务端接收到HEAD请求时只返回响应头，不发送响应内容。所以，如果只需要查看某个页面的状态时，用HEAD更高效，因为省去了传输页面内容的时间。</li>
<li>DELETE<br>删除某一个资源。</li>
<li>OPTIONS<br>用于获取当前URL所支持的方法。若请求成功，会在HTTP头中包含一个名为“Allow”的头，值是所支持的方法，如“GET, POST”。</li>
<li>PUT<br>把一个资源存放在指定的位置上。本质上来讲， PUT和POST极为相似，都是向服务器发送数据，但它们之间有一个重要区别，PUT通常指定了资源的存放位置，而POST则没有，POST的数据存放位置由服务器自己决定。</li>
<li>TRACE<br>回显服务器收到的请求，主要用于测试或诊断。</li>
<li>CONNECT<br>CONNECT方法是HTTP&#x2F;1.1协议预留的，能够将连接改为管道方式的代理服务器。通常用于SSL加密服务器的链接与非加密的HTTP代理服务器的通信。</li>
</ol>
<h3 id="请求头部"><a href="#请求头部" class="headerlink" title="请求头部"></a>请求头部</h3><p>请求头部由关键字&#x2F;值对组成，每行一对<br>User-Agent : 产生请求的浏览器类型<br>Accept : 客户端希望接受的数据类型，比如 Accept：text&#x2F;xml（application&#x2F;json）表示希望接受到的是xml（json）类型<br>Content-Type：发送端发送的实体数据的数据类型。比如，Content-Type：text&#x2F;html（application&#x2F;json）表示发送的是html类型。<br>Host : 请求的主机名，允许多个域名同处一个IP地址，即虚拟主机<br>Referer：表示当前请求是从哪个资源发起的；或者是请求的上一步的地址。<br>Referer是常用于网站的访问统计，比如我在很多地方都做了广告链接到我网站的主页，这时候我就可以通过Referer来查看哪些地方跳转过来的人多，就说广告的效果好。</p>
<h3 id="空行"><a href="#空行" class="headerlink" title="空行"></a>空行</h3><p>请求头部后面的空行是必须的，即使第四部分的请求数据为空，也必须有空行。</p>
<h3 id="请求数据"><a href="#请求数据" class="headerlink" title="请求数据"></a>请求数据</h3><p>请求数据也叫主体，可以添加任意的其他数据。</p>
<h2 id="HTTP响应报文"><a href="#HTTP响应报文" class="headerlink" title="HTTP响应报文"></a>HTTP响应报文</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Date: Fri, 22 May 2009 06:07:21 GMT</span><br><span class="line">Content-Type: text/html; charset=UTF-8</span><br><span class="line"></span><br><span class="line">&lt;html&gt;</span><br><span class="line">      &lt;head&gt;&lt;/head&gt;</span><br><span class="line">      &lt;body&gt;</span><br><span class="line">            &lt;!--body goes here--&gt;</span><br><span class="line">      &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>
<h3 id="状态行"><a href="#状态行" class="headerlink" title="状态行"></a>状态行</h3><p>由HTTP协议版本号， 状态码， 状态消息 三部分组成。（HTTP&#x2F;1.1）表明HTTP版本为1.1版本，状态码为200，状态消息为（ok）</p>
<h4 id="状态码"><a href="#状态码" class="headerlink" title="状态码"></a>状态码</h4><p><img data-src="/mybook.github.io/3665347114429.png"></p>
<h3 id="响应头"><a href="#响应头" class="headerlink" title="响应头"></a>响应头</h3><p>用来说明客户端要使用的一些附加信息<br>Date:生成响应的日期和时间；Content-Type:指定了MIME类型的HTML(text&#x2F;html),编码类型是UTF-8</p>
<h3 id="空行-1"><a href="#空行-1" class="headerlink" title="空行"></a>空行</h3><p>第三部分：空行，消息报头后面的空行是必须的</p>
<h3 id="响应体"><a href="#响应体" class="headerlink" title="响应体"></a>响应体</h3><p>服务器返回给客户端的文本信息。空行后面的html部分为响应正文。</p>
<h3 id="HTTP-1-1"><a href="#HTTP-1-1" class="headerlink" title="HTTP&#x2F;1.1"></a>HTTP&#x2F;1.1</h3><h4 id="HTTP优点"><a href="#HTTP优点" class="headerlink" title="HTTP优点"></a>HTTP优点</h4><p>HTTP 最凸出的优点是「简单、灵活和易于扩展、应⽤⼴泛和跨平台」。</p>
<ol>
<li>简单<br>HTTP 基本的报⽂格式就是 header + body ，头部信息也是 key-value 简单⽂本的形式，易于理解</li>
<li>灵活和易于扩展<br>HTTP协议⾥的各类请求⽅法、URI&#x2F;URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发⼈员⾃定义和扩充。同时 HTTP 由于是⼯作在应⽤层（ OSI 第七层），则它下层可以随意变化。</li>
<li>应⽤⼴泛和跨平台</li>
</ol>
<h4 id="HTTP缺点"><a href="#HTTP缺点" class="headerlink" title="HTTP缺点"></a>HTTP缺点</h4><p>HTTP 协议⾥有优缺点⼀体的双刃剑，分别是「⽆状态、明⽂传输」，同时还有⼀⼤缺点「不安全」。<br>⽆状态双刃剑⽆状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存⽤来对外提供服务。<br>⽆状态的坏处，既然服务器没有记忆能⼒，它在完成有关联性的操作时会⾮常麻烦。</p>
<h4 id="HTTP-1-1-的特点"><a href="#HTTP-1-1-的特点" class="headerlink" title="HTTP&#x2F;1.1 的特点"></a>HTTP&#x2F;1.1 的特点</h4><ol>
<li>⻓连接<br>早期 HTTP&#x2F;1.0 性能上的⼀个很⼤的问题，那就是每发起⼀个请求，都要新建⼀次 TCP 连接（三次握⼿），⽽且是串⾏请求，做了⽆谓的 TCP 连接建⽴和断开，增加了通信开销。<br>为了解决上述 TCP 连接问题，HTTP&#x2F;1.1 提出了⻓连接的通信⽅式，也叫持久连接。这种⽅式的好处在于减少了TCP 连接的复建⽴和断开所造成的额外开销，减轻了服务器端的负载。<mark>持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态。</mark></li>
<li>管道⽹络传输<br>HTTP&#x2F;1.1 采⽤了⻓连接的⽅式，这使得管道（pipeline）⽹络传输成为了可能。<br>即可在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间。<br>举例来说，客户端需要请求两个资源。以前的做法是，在同⼀个TCP连接⾥⾯，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。管道机制则是允许浏览器同时发出 A 请求和 B 请求。</li>
<li>队头阻塞<br>但是服务器还是按照顺序，先回应 A 请求，完成后再回应 B 请求。要是前⾯的回应特别慢，后⾯就会有许多请求排队等着。这称为「队头堵塞」。<br>「请求 - 应答」的模式加剧了 HTTP 的性能问题。因为当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致客户端⼀直请求不到数据，这也就是「队头阻塞」。好⽐上班的路上塞⻋。</li>
</ol>
<h4 id="HTTP-1-1-相⽐-HTTP-1-0-性能上的改进："><a href="#HTTP-1-1-相⽐-HTTP-1-0-性能上的改进：" class="headerlink" title="HTTP&#x2F;1.1 相⽐ HTTP&#x2F;1.0 性能上的改进："></a>HTTP&#x2F;1.1 相⽐ HTTP&#x2F;1.0 性能上的改进：</h4><ol>
<li>使⽤ TCP ⻓连接的⽅式改善了 HTTP&#x2F;1.0 短连接造成的性能开销。</li>
<li>⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间。</li>
</ol>
<h4 id="HTTP-1-1性能瓶颈："><a href="#HTTP-1-1性能瓶颈：" class="headerlink" title="HTTP&#x2F;1.1性能瓶颈："></a>HTTP&#x2F;1.1性能瓶颈：</h4><ol>
<li>请求 &#x2F; 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分；</li>
<li>发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多；</li>
<li>服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞；</li>
<li>没有请求优先级控制；</li>
<li>请求只能从客户端开始，服务器只能被动响应。</li>
</ol>
<h3 id="HTTP-2"><a href="#HTTP-2" class="headerlink" title="HTTP&#x2F;2"></a>HTTP&#x2F;2</h3><h4 id="HTTP-2-相⽐-HTTP-1-1-性能上的改进："><a href="#HTTP-2-相⽐-HTTP-1-1-性能上的改进：" class="headerlink" title="HTTP&#x2F;2 相⽐ HTTP&#x2F;1.1 性能上的改进："></a>HTTP&#x2F;2 相⽐ HTTP&#x2F;1.1 性能上的改进：</h4><ol>
<li>头部压缩<br>HTTP&#x2F;2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀样的或是相似的，那么，协议会帮你消除重复的部分。<br>这就是所谓的 HPACK 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。</li>
<li>⼆进制格式<br>HTTP&#x2F;2 不再像 HTTP&#x2F;1.1 ⾥的纯⽂本形式的报⽂，⽽是全⾯采⽤了⼆进制格式，头信息和数据体都是⼆进制，并且统称为帧（frame）：头信息帧和数据帧。</li>
<li>数据流<br>HTTP&#x2F;2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。<br>每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独⼀⽆⼆的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数。<br>客户端还可以指定数据流的优先级。优先级⾼的请求，服务器就先响应该请求。</li>
<li>多路复⽤<br>HTTP&#x2F;2 是可以在⼀个连接中并发多个请求或回应，⽽不⽤按照顺序⼀⼀对应。移除了 HTTP&#x2F;1.1 中的串⾏请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，⼤幅度提⾼了连接的利⽤率<br>举例来说，在⼀个 TCP 连接⾥，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程⾮常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。</li>
<li>服务器推送<br>HTTP&#x2F;2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以主动向客户端发送消息。<br>举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、CSS ⽂件等静态资源主动发给客户端，减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。</li>
</ol>
<h4 id="HTTP-2存在的问题"><a href="#HTTP-2存在的问题" class="headerlink" title="HTTP&#x2F;2存在的问题"></a>HTTP&#x2F;2存在的问题</h4><ul>
<li>HTTP&#x2F;2 主要的问题在于，多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以⼀旦发⽣了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。</li>
<li>HTTP&#x2F;1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了</li>
<li>HTTP&#x2F;2 多个请求复⽤⼀个TCP连接，⼀旦发⽣丢包，就会阻塞住所有的 HTTP 请求。</li>
</ul>
<h3 id="HTTP3"><a href="#HTTP3" class="headerlink" title="HTTP3"></a>HTTP3</h3><p>HTTP&#x2F;3 把 HTTP 下层的 TCP 协议改成了 UDP,基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。</p>
<ul>
<li>QUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，<mark>只会阻塞这个流，其他流不会受到影响。</mark></li>
<li>TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。</li>
<li>HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS&#x2F;1.3 的三次握⼿。QUIC 直接把以往的 TCP 和 TLS&#x2F;1.3 的 6 次交互合并成了 3 次，减少了交互次数。</li>
</ul>
<p><img data-src="/mybook.github.io/3227683816513.png"></p>
<h1 id="HTTPS"><a href="#HTTPS" class="headerlink" title="HTTPS"></a>HTTPS</h1><p>HTTPS 在 HTTP 与 TCP 层之间加⼊了 SSL&#x2F;TLS 协议，很好的解决了窃听⻛险，篡改⻛险，冒充⻛险。</p>
<ol>
<li>混合加密的⽅式实现信息的机密性，解决了窃听的⻛险。</li>
<li>摘要算法的⽅式来实现完整性，它能够为数据⽣成独⼀⽆⼆的「指纹」，指纹⽤于校验数据的完整性，解决了篡改的⻛险。</li>
<li>将服务器公钥放⼊到数字证书中，解决了冒充的⻛险。</li>
</ol>
<h2 id="混合加密"><a href="#混合加密" class="headerlink" title="混合加密"></a>混合加密</h2><p>HTTPS 采⽤的是对称加密和⾮对称加密结合的「混合加密」⽅式：</p>
<ul>
<li>在通信建⽴前采⽤⾮对称加密的⽅式交换「会话秘钥」，后续就不再使⽤⾮对称加密。</li>
<li>在通信过程中全部使⽤对称加密的「会话秘钥」的⽅式加密明⽂数据。</li>
</ul>
<p><mark>采⽤「混合加密」的⽅式的原因：</mark></p>
<ul>
<li>对称加密只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换。</li>
<li>⾮对称加密使⽤两个密钥：公钥和私钥，公钥可以任意分发⽽私钥保密，解决了密钥交换问题但速度慢。</li>
</ul>
<h2 id="摘要算法"><a href="#摘要算法" class="headerlink" title="摘要算法"></a>摘要算法</h2><p>客户端在发送明⽂之前会通过摘要算法算出明⽂的「指纹」，发送的时候把「指纹 + 明⽂」⼀同加密成密⽂后，发送给服务器，服务器解密后，⽤相同的摘要算法算出发送过来的明⽂，通过⽐较客户端携带的「指纹」和当前算出的「指纹」做⽐较，若「指纹」相同，说明数据是完整的。<br><img data-src="/mybook.github.io/25951248990.png"></p>
<h2 id="数字证书"><a href="#数字证书" class="headerlink" title="数字证书"></a>数字证书</h2><p>需要借助第三⽅权威机构 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。</p>
<h2 id="SSL-TLS-协议基本流程"><a href="#SSL-TLS-协议基本流程" class="headerlink" title="SSL&#x2F;TLS 协议基本流程"></a>SSL&#x2F;TLS 协议基本流程</h2><ol>
<li>客户端向服务器索要并验证服务器的公钥。</li>
<li>双⽅协商⽣产「会话秘钥」。</li>
<li>双⽅采⽤「会话秘钥」进⾏加密通信</li>
</ol>
<h2 id="密匙交换算法"><a href="#密匙交换算法" class="headerlink" title="密匙交换算法"></a>密匙交换算法</h2><p>使⽤⾮对称加密的⽅式来保护对称加密密钥的协商，这个⼯作就是密钥交换算法负责的。</p>
<h3 id="RSA-握⼿过程"><a href="#RSA-握⼿过程" class="headerlink" title="RSA 握⼿过程"></a>RSA 握⼿过程</h3><p>传统的 TLS 握⼿基本都是使⽤ RSA 算法来实现密钥交换的，在将 TLS 证书部署服务端时，证书⽂件中包含⼀对公私钥，其中公钥会在 TLS 握⼿阶段传递给客户端，私钥则⼀直留在服务端，⼀定要确保私钥不能被窃取。<br>在 RSA 密钥协商算法中，客户端会⽣成随机密钥，并使⽤服务端的公钥加密后再传给服务端。根据⾮对称加密算法，公钥加密的消息仅能通过私钥解密，这样服务端解密后，双⽅就得到了相同的密钥，再⽤它加密应⽤消息。</p>
<p>RSA 算法的缺陷<br>使⽤ RSA 密钥协商算法的最⼤问题是<mark>不⽀持前向保密</mark>。因为客户端传递随机数（⽤于⽣成对称加密密钥的条件之⼀）给服务端时使⽤的是公钥加密的，服务端收到到后，会⽤私钥解密得到随机数。所以⼀旦服务端的私钥泄漏了，过去被第三⽅截获的所有 TLS 通讯密⽂都会被破解。</p>
<h3 id="ECDHE-算法"><a href="#ECDHE-算法" class="headerlink" title="ECDHE 算法"></a>ECDHE 算法</h3><h4 id="DH-算法"><a href="#DH-算法" class="headerlink" title="DH 算法"></a>DH 算法</h4><p>现假设⼩红和⼩明约定使⽤ DH 算法来交换密钥，那么基于离散对数，⼩红和⼩明需要先确定模数和底数作为算法的参数，这两个参数是公开的，⽤ P 和 G 来代称。<br>然后⼩红和⼩明各⾃⽣成⼀个随机整数作为私钥，双⽅的私钥要各⾃严格保管，不能泄漏，⼩红的私钥⽤ a 代称，⼩明的私钥⽤ b 代称。<br>现在⼩红和⼩明双⽅都有了 P 和 G 以及各⾃的私钥，于是就可以计算出公钥：<br>⼩红的公钥记作 A，A &#x3D; G ^ a ( mod P )；<br>⼩明的公钥记作 B，B &#x3D; G ^ b ( mod P )；<br>A 和 B 也是公开的，因为根据离散对数的原理，从真数（A 和 B）反向计算对数 a 和 b 是⾮常困难的，⾄少在现有计算机的计算能⼒是⽆法破解的。<br>双⽅交换各⾃ DH 公钥后，⼩红⼿上共有 5 个数：P、G、a、A、B，⼩明⼿上也同样共有 5 个数：P、G、b、B、A。<br>然后⼩红执⾏运算： B ^ a ( mod P )，其结果为 K，因为离散对数的幂运算有交换律，所以⼩明执⾏运算： A ^ b (mod P )，得到的结果也是 K。<br><img data-src="/mybook.github.io/3347520485606.png"><br>这个 K 就是⼩红和⼩明之间⽤的<mark>对称加密密钥</mark>，可以作为会话密钥使⽤。<br>可以看到，整个密钥协商过程中，⼩红和⼩明公开了 4 个信息：P、G、A、B，其中 P、G 是算法的参数，A 和 B是公钥，⽽ a、b 是双⽅各⾃保管的私钥，⿊客⽆法获取这 2 个私钥，因此⿊客只能从公开的 P、G、A、B ⼊⼿，计算出离散对数（私钥）。<br>如果 P 是⼀个⼤数，在现有的计算机的计算能⼒是很难破解出 私钥 a、b的，破解不出私钥，也就⽆法计算出会话密钥，因此 DH 密钥交换是安全的。</p>
<h1 id="IP全家桶"><a href="#IP全家桶" class="headerlink" title="IP全家桶"></a>IP全家桶</h1><h2 id="DNS-域名解析"><a href="#DNS-域名解析" class="headerlink" title="DNS 域名解析"></a>DNS 域名解析</h2><p><img data-src="/mybook.github.io/5782137816512.png"></p>
<h2 id="ARP"><a href="#ARP" class="headerlink" title="ARP"></a>ARP</h2><p>ARP ⽤于根据 IP 地址查询相应的以太⽹ MAC 地址。<br>在传输⼀个 IP 数据报的时候，确定了源 IP 地址和⽬标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下⼀跳。然⽽，⽹络层的下⼀层是数据链路层，所以我们还要知道「下⼀跳」的 MAC 地址。由于主机的路由表中可以找到下⼀跳的 IP 地址，所以可以通过 ARP 协议，求得下⼀跳的 MAC 地址。</p>
<p>ARP 是借助 ARP 请求与 ARP 响应两种类型的包确定 MAC 地址的</p>
<ol>
<li>主机会通过⼴播发送 ARP 请求，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。</li>
<li>当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包⾥的内容，如果 ARP 请求包中的⽬标 IP 地址与⾃⼰的 IP 地址⼀致，那么这个设备就将⾃⼰的 MAC 地址塞⼊ ARP 响应包返回给主机。</li>
</ol>
<h2 id="ICMP"><a href="#ICMP" class="headerlink" title="ICMP"></a>ICMP</h2><p>互联⽹控制报⽂协议<br>ICMP 主要的功能包括：确认 IP 包是否成功送达⽬标地址、报告发送过程中 IP 包被废弃的原因和改善⽹络设置等。<br>ICMP ⼤致可以分为两⼤类：<br>⼀类是⽤于诊断的查询消息，也就是「查询报⽂类型」<br>另⼀类是通知出错原因的错误消息，也就是「差错报⽂类型」<br><img data-src="/mybook.github.io/5537494615604.png"></p>
<h3 id="ping的工作原理"><a href="#ping的工作原理" class="headerlink" title="ping的工作原理"></a>ping的工作原理</h3><p>ping 命令执⾏的时候，源主机⾸先会构建⼀个 ICMP<br>ICMP 数据包内包含多个字段，最重要的是两个：</p>
<ul>
<li>第⼀个是类型，对于回送请求消息⽽⾔该字段为 8 ；</li>
<li>另外⼀个是序号，主要⽤于区分连续 ping 的时候发出的多个数据包。<br>每发出⼀个请求数据包，序号会⾃动加 1 。为了能够计算往返时间 RTT ，它会在报⽂的数据部分插⼊发送时间。<br><img data-src="/mybook.github.io/1489291806710.png"><br><img data-src="/mybook.github.io/3501300595802.png"></li>
</ul>
<p><img data-src="/mybook.github.io/1454719219187.png"></p>
<h2 id="输入一个网址到浏览器显示页面经历的过程"><a href="#输入一个网址到浏览器显示页面经历的过程" class="headerlink" title="输入一个网址到浏览器显示页面经历的过程"></a>输入一个网址到浏览器显示页面经历的过程</h2><ol>
<li>DNS域名解析系统对输入的网址进行解析<br>DNS域名解析系统本质就是一个数据服务器，里面就存储了域名和IP的对应关系。最后会得到一个IP地址，通过这个IP地址，就能知道我们要访问哪一台服务器了。</li>
<li>建立TCP连接<br>客户端浏览器与服务器建立TCP安全连接（三次握手），为之后的HTTP响应做准备</li>
<li>客户端（浏览器）发送HTTP请求，<br>客户端根据用户操作，如按下回车键，向服务器发送HTTP请求</li>
<li>服务端（服务器）响应请求<br>服务器接收请求，然后进行处理，整合需要的资源，通过HTTP协议传输响应发送给客户端浏览器</li>
<li>浏览器解析渲染页面<br>浏览器接收服务器资源，解析渲染成Web页面<br><img data-src="/mybook.github.io/4843725941355.png"></li>
</ol>
<h1 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h1><h2 id="请求转发和重定向"><a href="#请求转发和重定向" class="headerlink" title="请求转发和重定向"></a>请求转发和重定向</h2><p>重定向和请求转发的区别</p>
<ol>
<li>重定向是两次请求，转发是一次请求，因此转发的速度要快于重定向</li>
<li>重定向之后地址栏上的地址会发生变化，变化成第二次请求的地址，转发之后地址栏上的地址不会变化，还是第一次请求的地址</li>
<li>请求转发可以共享请求参数 ，重定向之后，就获取不了共享参数了</li>
<li>请求转发不能跨域（不能访问其他服务器链接）req.getRequestDispatcher(“<a target="_blank" rel="noopener" href="http://www.baidu.com" ).forward(req,resp);是不行的.重定向可以resp.sendredirect("http www.baidu.com%22)">http://www.baidu.com&quot;).forward(req,resp);是不行的。重定向可以resp.sendRedirect(&quot;http://www.baidu.com&quot;)</a>;</li>
<li>请求转发能转到WEB-INF目录下的文件req.getRequestDispatcher(“&#x2F;WEB-INF&#x2F;views&#x2F;student.jsp”).forward(req,resp);而重定向不能resp.sendRedirect(“&#x2F;day02_01&#x2F;WEB-INF&#x2F;views&#x2F;student.jsp”);</li>
</ol>
<h2 id="Cookie与Session"><a href="#Cookie与Session" class="headerlink" title="Cookie与Session"></a>Cookie与Session</h2><h3 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h3><p><mark>Cookie通过在客户端记录信息确定用户身份，Session通过在服务器端记录信息确定用户身份。</mark><br>在客户端第⼀次请求后，服务器会下发⼀个装有客户信息的「⼩贴纸」，后续客户端请求服务器的时候，带上「⼩贴纸」，服务器就能认得了,Cookie具有不可跨域名性</p>
<h3 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h3><p><mark>Session机制是通过检查服务器上的“客户明细表”来确认客户身份。Session相当于程序在服务器上建立的一份客户档案，客户来访的时候只需要查询客户档案表。</mark></p>
<ul>
<li>Session机制决定了当前客户只会获取到自己的Session，而不会获取到别人的Session。各客户的Session也彼此独立，互不可见。</li>
<li><mark>Session对象是在客户端第一次请求服务器的时候创建的。</mark>Session也是一种key-value的属性对，通过getAttribute(Stringkey)和setAttribute(String key，Objectvalue)方法读写客户状态信息。Servlet里通过request.getSession()方法获取该客户的Session，</li>
<li>Session生成后，只要用户继续访问，服务器就会更新Session的最后访问时间，并维护该Session。为防止内存溢出，服务器会把长时间内没有活跃的Session从内存删除。这个时间就是Session的超时时间。如果超过了超时时间没访问过服务器，Session就自动失效了。</li>
</ul>
<h3 id="区别"><a href="#区别" class="headerlink" title="区别"></a>区别</h3><ol>
<li>cookie数据存放在客户的浏览器上，session数据放在服务器上</li>
<li>cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗,如果主要考虑到安全应当使用session</li>
<li>session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，如果主要考虑到减轻服务器性能方面，应当使用COOKIE</li>
<li>将登陆信息等重要信息存放为SESSION;其他信息如果需要保留，可以放在COOKIE中</li>
<li>两者最大的区别在于生存周期，一个是IE启动到IE关闭.(浏览器页面一关 ,session就消失了)，一个是预先设置的生存周期，或永久的保存于本地的文件。(cookie)</li>
</ol>
<h1 id="高级网络"><a href="#高级网络" class="headerlink" title="高级网络"></a>高级网络</h1><p>SYN-Flood攻击解决办法</p>
<ol>
<li><p>无效连接监视释放<br>这种方法不停监视系统的半开连接和不活动连接，当达到一定阈值时拆除这些连接，从而释放系统资源。这种方法对于所有的连接一视同仁，而且由于SYN Flood造成的半开连接数量很大，正常连接请求也被淹没在其中被这种方式误释放掉，因此这种方法属于入门级的SYN Flood方法。</p>
</li>
<li><p>延缓任务控制块（TCB）分配方法<br>从前面SYN Flood原理可以看到，消耗服务器资源主要是因为当SYN数据报文一到达，系统立即分配TCB，从而占用了资源。而SYN Flood由于很难建立起正常连接，因此，当正常连接建立起来后再分配TCB则可以有效地减轻服务器资源的消耗。常见的方法是使用Syn Cache和Syn Cookie技术。</p>
</li>
</ol>
<ul>
<li><p>Syn Cache技术：<br>这种技术是在收到SYN数据报文时不急于去分配TCB，而是先回应一个SYN ACK报文，并在一个专用HASH表（Cache）中保存这种半开连接信息，直到收到正确的回应ACK报文再分配TCB。在FreeBSD系统中这种Cache每个半开连接只需使用160字节，远小于TCB所需的736个字节。在发送的SYN ACK中需要使用一个己方的Sequence Number，这个数字不能被对方猜到，否则对于某些稍微智能一点的Syn Flood攻击软件来说，它们在发送Syn报文后会发送一个ACK报文，如果己方的Sequence Number被对方猜测到，则会被其建立起真正的连接。因此一般采用一些加密算法生成难于预测的Sequence Number。</p>
</li>
<li><p>Syn Cookie技术：<br>对于SYN攻击，Syn Cache虽然不分配TCB，但是为了判断后续对方发来的ACK报文中的Sequence Number的正确性，还是需要使用一些空间去保存己方生成的Sequence Number等信息，也造成了一些资源的浪费。<br>Syn Cookie技术则完全不使用任何存储资源，这种方法比较巧妙，它使用一种特殊的算法生成Sequence Number，这种算法考虑到了对方的IP、端口、己方IP、端口的固定信息，以及对方无法知道而己方比较固定的一些信息，如MSS、时间等，在收到对方的ACK报文后，重新计算一遍，看其是否与对方回应报文中的（Sequence Number-1）相同，从而决定是否分配TCB资源。</p>
</li>
</ul>
<ol start="3">
<li>使用SYN Proxy防火墙<br>Syn Cache技术和Syn Cookie技术总的来说是一种主机保护技术，需要系统的TCP&#x2F;IP协议栈的支持，而目前并非所有的操作系统支持这些技术。因此很多防火墙中都提供一种SYN代理的功能，其主要原理是对试图穿越的SYN请求进行验证后才放行。</li>
</ol>
<link rel="stylesheet" href="/mybook.github.io/css/spoiler.css" type="text/css"><script src="/mybook.github.io/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://silence-create.github.io/mybook.github.io/2024/05/17/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/mybook.github.io/images/avatar.gif">
      <meta itemprop="name" content="徐川">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="依只若只的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/mybook.github.io/2024/05/17/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" class="post-title-link" itemprop="url">操作系统</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-05-17 15:44:23" itemprop="dateCreated datePublished" datetime="2024-05-17T15:44:23+08:00">2024-05-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-05-20 11:37:05" itemprop="dateModified" datetime="2024-05-20T11:37:05+08:00">2024-05-20</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="操作系统的能力"><a href="#操作系统的能力" class="headerlink" title="操作系统的能力"></a>操作系统的能力</h1><p>现代操作系统，内核⼀般会提供 4 个基本能⼒：<br>进程调度：决定哪个进程、线程使⽤ CPU，也就是进程调度的能⼒；<br>内存管理：决定内存的分配和回收，也就是内存管理的能⼒；<br>设管理备：为进程与硬件设备之间提供通信能⼒，也就是硬件通信能⼒；<br>系统调⽤：如果应⽤程序要运⾏更⾼权限运⾏的服务，那么就需要有系统调⽤，它是⽤户程序与操作系统之间的接⼝。</p>
<h1 id="伟大的原理：局部性原理"><a href="#伟大的原理：局部性原理" class="headerlink" title="伟大的原理：局部性原理"></a>伟大的原理：局部性原理</h1><p><strong>程序在执行时呈现出局部性规律，即在一较短的时间内，程序的执行仅局限于某个部分；相应的它所访问的空间也局限于某个区域</strong><br>时间局部性：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。<br>空间局部性：在最近的将来将用到的信息很可能与正在使用的信息在空间地址上是临近的。<br>顺序局部性：在典型程序中，除转移类指令外，大部分指令是顺序进行的。</p>
<h1 id="CPU"><a href="#CPU" class="headerlink" title="CPU"></a>CPU</h1><h2 id="CPU三级缓存"><a href="#CPU三级缓存" class="headerlink" title="CPU三级缓存"></a>CPU三级缓存</h2><p>cat &#x2F;sys&#x2F;devices&#x2F;system&#x2F;cpu&#x2F;cpu0&#x2F;cache&#x2F;index3&#x2F;size</p>
<h2 id="CPU性能"><a href="#CPU性能" class="headerlink" title="CPU性能"></a>CPU性能</h2><p><img data-src="/mybook.github.io/63874010246117.png"></p>
<h2 id="CPU读取数据方式"><a href="#CPU读取数据方式" class="headerlink" title="CPU读取数据方式"></a>CPU读取数据方式</h2><p><img data-src="/mybook.github.io/487145910246742.png"></p>
<h2 id="CPU的缓存写入"><a href="#CPU的缓存写入" class="headerlink" title="CPU的缓存写入"></a>CPU的缓存写入</h2><p>在什么时机才把 Cache 中的数据写回到内存？<br><strong>写直达：</strong><br>把数据同时写入内存和 Cache 中</p>
<p><img data-src="/mybook.github.io/519060711266908.png"></p>
<p><strong>写回</strong><br>写错时获取策略 ：当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率</p>
<p><img data-src="/mybook.github.io/475621011259577.png"></p>
<p>内存读取？<br>保持独占机制</p>
<h2 id="CPU缓存一致性"><a href="#CPU缓存一致性" class="headerlink" title="CPU缓存一致性"></a>CPU缓存一致性</h2><p><img data-src="/mybook.github.io/227005311256132.png"></p>
<p>第一点，某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为<strong>写传播</strong>；<br>第二点，某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为<strong>事务的串行化</strong>。</p>
<p><strong>解决方式</strong><br>写失效：当一个CPU修改了数据，如果其他CPU有该数据，则通知其为无效；<br>写更新：当一个CPU修改了数据，如果其他CPU有该数据，则通知其更新新数据，（写更新会导致大量的更新操作）。</p>
<h3 id="总线嗅探"><a href="#总线嗅探" class="headerlink" title="总线嗅探"></a>总线嗅探</h3><p><strong>属于写更新</strong><br>当 A 号 CPU 核心修改了 L1 Cache 中 i 变量的值，通过总线把这个事件广播通知给其他所有的核心，然后每个 CPU 核心都会监听总线上的<strong>广播事件</strong>，并检查是否有相同的数据在自己的 L1 Cache 里面，如果 B 号 CPU 核心的 L1 Cache 中有该数据，那么也需要把该数据更新到自己的 L1 Cache</p>
<h3 id="MESI-协议"><a href="#MESI-协议" class="headerlink" title="MESI 协议"></a>MESI 协议</h3><p><strong>属于写失效，写回</strong></p>
<ul>
<li>Modified，已修改<br>缓存行是脏的（dirty），与内存的值不同。如果别的CPU内核要读内存这块数据，该缓存行必须回写到内存，状态变为共享(S).</li>
<li>Exclusive，独占<br>缓存行只在当前缓存中，但是干净的——缓存数据相同于内存数据。当别的缓存读取它时，状态变为共享；当前写数据时，变为已修改状态。</li>
<li>Shared，共享<br>缓存行也存在于其它缓存中且是未修改的。缓存行可以在任意时刻抛弃。</li>
<li>Invalidated，已失效<br>缓存行是无效的</li>
</ul>
<p>当块标记为M（已修改）时，其他高速缓存中块的副本必须标记为I（无效）。</p>
<p><img data-src="/mybook.github.io/562890211252452.png"></p>
<ol>
<li>当一个处理器需要访问某个内存数据时，它首先会检查自己的缓存中是否有该数据的副本。如果缓存中没有该数据的副本，则会发出一个缓存不命中<strong>（miss）</strong>请求，从主内存中获取该数据的副本，并将该数据的副本存储到自己的缓存中。</li>
<li><strong>当一个处理器发出miss请求时</strong>，如果该数据的副本已经存在于另一个处理器或核心的缓存中（即处于共享状态），则该处理器可以<strong>从另一个处理器的缓存中复制该数据的副本</strong>。这个过程称为缓存到缓存复制（cache-to-cache transfer）。</li>
<li>如果两个缓存都处于修改状态，那么必须先将其中一个缓存的数据写回到主内存，然后才能进行缓存到缓存复制。</li>
</ol>
<h2 id="CPU软中断"><a href="#CPU软中断" class="headerlink" title="CPU软中断"></a>CPU软中断</h2><p>Linux 系统为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」。</p>
<p>上半部用来快速处理中断，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。<br>下半部用来延迟处理上半部未完成的工作，一般以「内核线程」的方式运行。</p>
<h1 id="内核"><a href="#内核" class="headerlink" title="内核"></a>内核</h1><p>对于内核的架构一般有这三种类型：</p>
<ul>
<li>宏内核，包含多个模块，一个完整的可执行程序，且拥有最高的权限；内核的所有代码，包括子系统（如内存管理、文件管理、设备驱动程序）都打包到一个文件中。内核中的每一个函数都可以访问到内核中所有其他部分。目前支持模块的动态装卸(裁剪)。宏内核的特征是系统内核的所有模块，比如进程调度、内存管理、文件系统、设备驱动等，都运行在内核态。</li>
<li>微内核，有一个最小版本的内核，一些模块和服务则由用户态管理；最基本的功能由中央内核（微内核）实现。所有其他的功能都委托给一些独立进程，这些进程通过明确定义的通信接口与中心内核通信</li>
<li>混合内核，是宏内核和微内核的结合体，内核中抽象出了微内核的概念，也就是内核中会有一个小型的内核，其他模块就在这个基础上搭建，整个内核是个完整的程序；</li>
</ul>
<p><strong>Window 的内核设计是混合型内核</strong></p>
<p><strong>Linux 的内核是宏内核</strong></p>
<h2 id="用户态-内核态的方式"><a href="#用户态-内核态的方式" class="headerlink" title="用户态-&gt;内核态的方式"></a><font color="red">用户态-&gt;内核态的方式</font></h2><ol>
<li>系统调用<br>这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如前例中fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现</li>
<li>异常<br>当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。  </li>
<li>外围设备的中断<br>当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。</li>
</ol>
<h1 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h1><h2 id="为什么要有虚拟内存？"><a href="#为什么要有虚拟内存？" class="headerlink" title="为什么要有虚拟内存？"></a>为什么要有虚拟内存？</h2><p>局部性原理<br>单片机的 CPU 是直接操作内存的「物理地址」，要想在内存中同时运行两个程序是不可能的。如果第一个程序在某个位置写入一个新的值，将会擦掉第二个程序存放在相同位置上的所有内容</p>
<p>操作系统会提供一种机制，将不同进程的虚拟地址和不同内存的物理地址映射起来。</p>
<h2 id="虚拟内存"><a href="#虚拟内存" class="headerlink" title="虚拟内存"></a>虚拟内存</h2><h3 id="内存分段"><a href="#内存分段" class="headerlink" title="内存分段"></a>内存分段</h3><p>分段机制下的虚拟地址由两部分组成，<strong>段选择因子</strong>和<strong>段内偏移量</strong>。</p>
<p><img data-src="/mybook.github.io/5213036139083.png"></p>
<p><img data-src="/mybook.github.io/1622019696606.png"></p>
<h4 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h4><ol>
<li>存在内存碎⽚的问题<br>如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开⼀个200MB 的程序。</li>
</ol>
<p><img data-src="/mybook.github.io/701232485698.png"></p>
<p>解决外部内存碎⽚的问题就是内存交换。这个内存交换空间，在 Linux 系统⾥，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，⽤于内存与硬盘的空间交换。<br>2. 可能内存交换的效率低的问题<br>如果内存交换的时候，交换的是⼀个占内存空间很⼤的程序，这样整个机器都会显得卡顿。</p>
<h3 id="内存分页"><a href="#内存分页" class="headerlink" title="内存分页"></a>内存分页</h3><p>分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，叫页。在 Linux 下，每一页的大小为 4KB。</p>
<p>虚拟地址与物理地址之间通过页表来映射，如下图：</p>
<p><img data-src="/mybook.github.io/592690815251886.png"></p>
<p><img data-src="/mybook.github.io/7861115269766.png"></p>
<p><strong>页号</strong>和<strong>页内偏移</strong>。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址</p>
<p><img data-src="/mybook.github.io/4368924759853.png"></p>
<p>详细转换如下图：</p>
<p><img data-src="/mybook.github.io/2931454446495.png"></p>
<h4 id="缺点：-1"><a href="#缺点：-1" class="headerlink" title="缺点："></a>缺点：</h4><p>内存碎片：<br>当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个<strong>缺⻚异常</strong>，进⼊系统内核空间分配物理内存、更新进程⻚表，最后再返回⽤户空间，恢复进程的运⾏采⽤了分⻚，那么释放的内存都是以⻚为单位释放的，也就不会产⽣⽆法给进程使⽤的⼩内存。<br>但是，因为内存分页机制分配内存的最小单位是一页，即使程序不足一页大小，我们最少只能分配一个页，所以页内会出现内存浪费，所以针对内存分页机制会有<strong>内部内存碎片</strong>的现象。</p>
<p>空间上的缺陷：<br>在 32 位的环境下，虚拟地址空间共有 4GB，假设一个页的大小是 4KB（2^12），一个进程的页表需要装下 100 多万个「页表项」（2^20） ，每个「页表项」需要 4 个字节大小来存储，那么整个 4GB 空间的映射就需要有 4MB 的内存来存储页表。</p>
<p>这 4MB 大小的页表，看起来也不是很大。但是要知道每个进程都是有自己的虚拟地址空间的，也就说都有自己的页表。那么，100 个进程的话，就需要 400MB 的内存来存储页表</p>
<h3 id="多级分页"><a href="#多级分页" class="headerlink" title="多级分页"></a>多级分页</h3><p>将页表（一级页表）分为 1024 个页表（二级页表），每个表（二级页表）中包含 1024 个「页表项」，形成二级分页。如下图所示：</p>
<p><img data-src="/mybook.github.io/40059992973.png"></p>
<p><strong>映射 4GB 地址空间需要 4KB（一级页表）+ 4MB（二级页表）的内存，更大的空间？（局部性原理的充分应用）</strong><br><strong>局部性原理：</strong><br>每个进程都有 4GB 的虚拟地址空间，对于大多数程序来说，其使用到的空间远未达到 4GB，因为会存在部分对应的页表项都是空的，根本没有分配，<br>对于已分配的页表项，如果存在最近一定时间未访问的页表，在物理内存紧张的情况下，操作系统会将页面换出到硬盘，也就是说不会占用物理内存。</p>
<p><strong>用时分配：</strong><br>如果使用了二级分页，一级页表就可以覆盖整个 4GB 虚拟地址空间，但<strong>如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表。</strong><br>例如：假设只有 20% 的一级页表项被用到了，那么页表占用的内存空间就只有 4KB（一级页表） + 20% * 4MB（二级页表）&#x3D; 0.804MB &lt; 4MB</p>
<p>总结：<br>页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。</p>
<h4 id="TLB技术"><a href="#TLB技术" class="headerlink" title="TLB技术"></a>TLB技术</h4><p><strong>局部性原理的充分应用</strong><br>所以，把最常访问的几个页表项存储到访问速度更快的硬件，在CPU 芯片中，加入了一个专门存放程序最常访问的页表项的 Cache，这个 Cache 就是 TLB ，通常称为页表缓存、转址旁路缓存、快表等</p>
<p><img data-src="/mybook.github.io/576865409267371.png"></p>
<p>在CPU 中，封装了内存管理单元芯片，它用来完成地址转换和 TLB 的访问与交互。有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。<strong>TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。</strong></p>
<h3 id="段页式存储"><a href="#段页式存储" class="headerlink" title="段页式存储"></a>段页式存储</h3><p><strong>Linux内核的内存管理方式</strong></p>
<p>Linux 系统中的每个段都是从 0 地址开始的整个 4GB 虚拟空间（32 位环境下），也就是所有的段的起始地址都是一样的。这意味着，Linux 系统中的代码，包括操作系统本身的代码和应用程序代码，所面对的地址空间都是线性地址空间（虚拟地址），这种做法相当于屏蔽了处理器中的逻辑地址概念，段只被用于访问控制和内存保护</p>
<p><img data-src="/mybook.github.io/5586609807317.png"></p>
<p>在 Linux 操作系统中，虚拟地址空间的内部又被分为<strong>内核空间和用户空间</strong>两部分</p>
<p>每个进程都各自有独立的虚拟内存，但是每个虚拟内存中的内核地址，其实关联的都是相同的物理内存。这样，进程切换到内核态后，就可以很方便地访问内核空间内存。</p>
<h3 id="伙伴算法"><a href="#伙伴算法" class="headerlink" title="伙伴算法"></a><font color="red">伙伴算法</font></h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">unsigned</span> <span class="type">long</span> __init <span class="title">free_all_bootmem</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">unsigned</span> <span class="type">long</span> __init <span class="title">free_all_bootmem_core</span><span class="params">(<span class="type">bootmem_data_t</span> *bdata)</span></span></span><br></pre></td></tr></table></figure>

<ul>
<li>内部碎片是已经被分配出去的（能明确指出属于哪个进程）内存空间大于请求所需的内存空间，不能被利用的空间就是内部碎片。</li>
<li>外部碎片是指还没分配出去（不属于任何进程），但是由于大小无法分配给申请内存空间的新进程的内存空闲块。</li>
</ul>
<p>伙伴系统算法来解决<mark>内存外部碎片</mark>的问题。<mark>swap分区也为一种方法</mark>，把所有的空闲页框分组为 11 块链表，每一块链表分别包含大小为1，2，4，8，16，32，64，128，256，512 和 1024 个连续的页框。<br>假设系统中有 1MB 大小的内存需要动态管理，按照伙伴算法的要求：需要将这1M大小的内存进行划分。这里，我们将这1M的内存分为 64K、64K、128K、256K、和512K 共五个部分，如下图a所示</p>
<p><img data-src="/mybook.github.io/270111911240561.png"></p>
<ol>
<li>此时，如果有一个程序A想要申请一块45K大小的内存，则系统会将第一块64K的内存块分配给该程序（产生内部碎片为代价），如图b所示；</li>
<li>然后程序B向系统申请一块68K大小的内存，系统会将128K内存分配给该程序，如图c所示；</li>
<li>接下来，程序C要申请一块大小为35K的内存。系统将空闲的64K内存分配给该程序，如图d所示；</li>
<li>之后程序D需要一块大小为90K的内存。当程序提出申请时，系统本该分配给程序D一块128K大小的内存，但此时内存中已经没有空闲的128K内存块了，于是根据伙伴算法的原理，系统会将256K大小的内存块平分，将其中一块分配给程序D，另一块作为空闲内存块保留，等待以后使用，如图e所示；</li>
<li>紧接着，程序C释放了它申请的64K内存。在内存释放的同时，系统还负责检查与之相邻并且同样大小的内存是否也空闲，由于此时程序A并没有释放它的内存，所以系统只会将程序C的64K内存回收，如图f所示；</li>
<li>然后程序A也释放掉由它申请的64K内存，系统随机发现与之相邻且大小相同的一段内存块恰好也处于空闲状态。于是，将两者合并成128K内存，如图g所示；</li>
<li>之后程序B释放掉它的128k，系统也将这块内存与相邻的128K内存合并成256K的空闲内存，如图h所示；</li>
<li>最后程序D也释放掉它的内存，经过三次合并后，系统得到了一块1024K的完整内存，如图i所示。</li>
</ol>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>第一，虚拟内存可以使得进程对运行内存超过物理内存大小，<strong>因为程序运行符合局部性原理，CPU 访问内存会有很明显的重复访问的倾向性</strong>，对于那些没有被经常使用到的内存，我们可以把它换出到物理内存之外，比如硬盘上的 swap 区域。<br>第二，由于每个进程都有自己的页表，所以每个进程的虚拟内存空间就是相互独立的。进程也没有办法访问其他进程的页表，所以这些页表是私有的，这就<strong>解决了多进程之间地址冲突的问题。</strong><br>第三，页表里的页表项中除了物理地址之外，还有一些标记属性的比特，比如控制一个页的读写权限，标记该页是否存在等。在内存访问方面，操作系统提供了更好的安全性。</p>
<h2 id="内存进阶"><a href="#内存进阶" class="headerlink" title="内存进阶"></a>内存进阶</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>Linux的用户空间和内核空间内存大小</p>
<p><img data-src="/mybook.github.io/107475909264873.png"></p>
<p>用户空间内存从低到高分别是 6 种不同的内存段：代表了不同的含义</p>
<p><img data-src="/mybook.github.io/416540910246114.png"></p>
<ul>
<li>代码段，包括<strong>二进制可执行代码</strong>；</li>
<li>数据段，包括<strong>已初始化的静态常量和全局变量</strong>；</li>
<li>BSS 段，包括<strong>未初始化的静态变量和全局变量</strong>；</li>
<li>堆段，包括动态分配的内存，<strong>从低地址开始向上增长</strong>；</li>
<li>文件映射段，包括动态库、共享内存等，<strong>从低地址开始向上增长</strong>（跟硬件和内核版本有关 (opens new window)）；</li>
<li>栈段，包括局部变量和函数调用的上下文等。<strong>从低地址开始向下增长</strong>，栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；</li>
</ul>
<h3 id="malloc"><a href="#malloc" class="headerlink" title="malloc"></a>malloc</h3><h4 id="malloc-是如何分配内存的？"><a href="#malloc-是如何分配内存的？" class="headerlink" title="malloc 是如何分配内存的？"></a>malloc 是如何分配内存的？</h4><ul>
<li>方式一：通过 brk() 系统调用从堆分配内存</li>
</ul>
<p><img data-src="/mybook.github.io/510461310268554.png"></p>
<ul>
<li>方式二：通过 mmap() 系统调用在文件映射区域分配内存；也就是从文件映射区“偷”了一块内存</li>
</ul>
<p><img data-src="/mybook.github.io/598501410263690.png"></p>
<p>malloc() 源码里默认定义了一个阈值：</p>
<p>如果用户分配的内存小于 128 KB，则通过 brk() 申请内存；<br>如果用户分配的内存大于 128 KB，则通过 mmap() 申请内存；</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -i &quot;DEFAULT_MMAP_THRESHOLD_MIN&quot; malloc/malloc.c</span><br></pre></td></tr></table></figure>


<h4 id="malloc-1-会分配多大的虚拟内存？"><a href="#malloc-1-会分配多大的虚拟内存？" class="headerlink" title="malloc(1) 会分配多大的虚拟内存？"></a>malloc(1) 会分配多大的虚拟内存？</h4><p>132K</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;malloc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;使用cat /proc/%d/maps查看内存分配\n&quot;</span>, <span class="built_in">getpid</span>());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 申请1字节的内存</span></span><br><span class="line">    <span class="type">void</span> *addr = <span class="built_in">malloc</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;此1字节的内存起始地址：%x\n&quot;</span>, addr);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;使用cat /proc/%d/maps查看内存分配\n&quot;</span>, <span class="built_in">getpid</span>());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将程序阻塞，当输入任意字符时才往下执行</span></span><br><span class="line">    <span class="built_in">getchar</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放内存</span></span><br><span class="line">    <span class="built_in">free</span>(addr);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;释放了1字节的内存，但heap堆并不会释放\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">getchar</span>();</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<p>malloc 通过 brk() 方式申请的内存，free 释放内存的时候，并不会把内存归还给操作系统，而是缓存在 malloc 的内存池中，待下次使用；<br>malloc 通过 mmap() 方式申请的内存，free 释放内存的时候，会把内存归还给操作系统，内存得到真正的释放。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;malloc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">//申请1字节的内存</span></span><br><span class="line">  <span class="type">void</span> *addr = <span class="built_in">malloc</span>(<span class="number">128</span>*<span class="number">1024</span>);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;此128KB字节的内存起始地址：%x\n&quot;</span>, addr);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;使用cat /proc/%d/maps查看内存分配\n&quot;</span>,<span class="built_in">getpid</span>());</span><br><span class="line"></span><br><span class="line">  <span class="comment">//将程序阻塞，当输入任意字符时才往下执行</span></span><br><span class="line">  <span class="built_in">getchar</span>();</span><br><span class="line"></span><br><span class="line">  <span class="comment">//释放内存</span></span><br><span class="line">  <span class="built_in">free</span>(addr);</span><br><span class="line">  <span class="built_in">printf</span>(<span class="string">&quot;释放了128KB字节的内存，内存也归还给了操作系统\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">getchar</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="为什么不全部使用-mmap-来分配内存？"><a href="#为什么不全部使用-mmap-来分配内存？" class="headerlink" title="为什么不全部使用 mmap 来分配内存？"></a>为什么不全部使用 mmap 来分配内存？</h4><p>申请内存的操作应该避免频繁的系统调用，如果都用 mmap 来分配内存，等于每次都要执行系统调用。<br>另外，因为 mmap 分配的内存每次释放的时候，都会归还给操作系统，于是每次 mmap 分配的虚拟地址都是缺页状态的，然后在第一次访问该虚拟地址的时候，就会触发缺页中断。</p>
<h4 id="为什么不全部使用-brk-来分配？"><a href="#为什么不全部使用-brk-来分配？" class="headerlink" title="为什么不全部使用 brk 来分配？"></a>为什么不全部使用 brk 来分配？</h4><p>随着系统频繁地 malloc 和 free ，尤其对于小块内存，堆内将产生越来越多不可用的碎片,<strong>导致“内存泄露”</strong></p>
<h4 id="free-函数只传入一个内存地址，为什么能知道要释放多大的内存？"><a href="#free-函数只传入一个内存地址，为什么能知道要释放多大的内存？" class="headerlink" title="free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？"></a>free() 函数只传入一个内存地址，为什么能知道要释放多大的内存？</h4><p>运行上述脚本代码可发现：打印的地址比实际程序地址多出来 0x10 （16字节）<br>多出来的 16 字节就是保存了该内存块的描述信息，比如有该内存块的大小。</p>
<p><img data-src="/mybook.github.io/354790711257236.png"></p>
<h3 id="内存对齐"><a href="#内存对齐" class="headerlink" title="内存对齐"></a>内存对齐</h3><h4 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h4><ul>
<li>操作系统在数据读取的时候，其实并不是一字节一字节进行读取的，而是一段一段进行读取</li>
<li>我们假如是4bytes。假如我们要读取一个int，如果不对齐，这个int占用第1块的后3位和第2块的第1位，需要两次读取，将两次的数据组合起来。这样CPU将做出“多余操作”，严重影响处理速度。</li>
<li>因此需要进行内存对齐，从而提高CPU处理速率，而这项任务就交给编译器进行相应的地址分配和优化，编译器会根据提供参数或者目标环境进行相应的内存对齐。</li>
</ul>
<h4 id="结构体内存对齐的规则（未指定-pragma-pack时）"><a href="#结构体内存对齐的规则（未指定-pragma-pack时）" class="headerlink" title="结构体内存对齐的规则（未指定#pragma pack时）"></a>结构体内存对齐的规则（未指定#pragma pack时）</h4><ol>
<li>第一个成员起始于0偏移处；</li>
<li>每个成员按其类型大小和指定对齐参数n中较小的一个进行对齐；</li>
<li>结构体总长度必须为所有对齐参数的整数倍；</li>
<li>对于数组，可以拆开看做n个数组元素<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">A</span> &#123;</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">char</span> b;</span><br><span class="line">    <span class="type">short</span> c;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">B</span> &#123;</span><br><span class="line">    <span class="type">char</span> b;</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">short</span> c;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
sizeof(A) &#x3D; 8;sizeof(B) &#x3D; 12。</li>
</ol>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">a</th>
<th align="center">b</th>
<th align="center">c</th>
</tr>
</thead>
<tbody><tr>
<td align="center">A的内存布局：</td>
<td align="center">1111</td>
<td align="center">1*</td>
<td align="center">11</td>
</tr>
<tr>
<td align="center">B的内存布局：</td>
<td align="center">1***</td>
<td align="center">1111</td>
<td align="center">11**</td>
</tr>
<tr>
<td align="center">其中星号*表示填充的字节。A中，b后面为何要补充一个字节？因为c为short，其起始位置要为2的倍数，就是原则1。c的后面没有补充，因为b和c正好占用4个字节，整个A占用空间为4的倍数，也就是最大成员int类型的倍数，所以不用补充。B中，b是char为1，b后面补充了3个字节，因为a是int为4，根据原则1，起始位置要为4的倍数，所以b后面要补充3个字节。c后面补充两个字节，根据原则3，整个B占用空间要为4的倍数，c后面不补充，整个B的空间为10，不符，所以要补充2个字节。</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">A</span> &#123;</span><br><span class="line">    <span class="type">int</span> a;</span><br><span class="line">    <span class="type">double</span> b;</span><br><span class="line">    <span class="type">float</span> c;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">B</span> &#123;</span><br><span class="line">    <span class="type">char</span> e[<span class="number">2</span>];</span><br><span class="line">    <span class="type">int</span> f;</span><br><span class="line">    <span class="type">double</span> g;</span><br><span class="line">    <span class="type">short</span> h;</span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">A</span> i;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>sizeof(A) &#x3D; 24; 这个比较好理解，int为4，double为8，float为4，总长为8的倍数，补齐，所以整个A为24。<br>sizeof(B) &#x3D; 48; 看看B的内存布局。</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">e</th>
<th align="center">f</th>
<th align="center">g</th>
<th align="center">h</th>
<th align="center">i</th>
</tr>
</thead>
<tbody><tr>
<td align="center">B的内存布局</td>
<td align="center">11**</td>
<td align="center">1111</td>
<td align="center">11111111</td>
<td align="center">11 * * * * * *</td>
<td align="center">1111****, 11111111, 1111****</td>
</tr>
<tr>
<td align="center">i其实就是A的内存布局。i的起始位置要为24的倍数，所以h后面要补齐。</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<h3 id="大小端模式"><a href="#大小端模式" class="headerlink" title="大小端模式"></a>大小端模式</h3><ul>
<li>大端存储是指低字节存储在高地址</li>
<li>小端存储是指低字节存储在低地址<br>根据联合体来判断该系统是大端还是小端。<mark>因为联合体变量总是从低地址存储</mark><br>判断大小端的代码：<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">union</span> <span class="title class_">test</span> &#123;</span><br><span class="line">        <span class="type">int</span> i;</span><br><span class="line">        <span class="type">char</span> c;</span><br><span class="line">    &#125;;</span><br><span class="line">    test t;</span><br><span class="line">    t.i = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (t.c == <span class="number">1</span>) &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;big&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;little&quot;</span> &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="内存回收"><a href="#内存回收" class="headerlink" title="内存回收"></a>内存回收</h2><ol>
<li>后台内存回收：在物理内存紧张的时候，会唤醒 kswapd 内核线程来回收内存，这个回收内存的过程<strong>异步</strong>的，不会阻塞进程的执行。</li>
<li>直接内存回收：如果后台异步回收跟不上进程内存申请的速度，就会开始直接回收，这个回收内存的过程是<strong>同步</strong>的，会阻塞进程的执行。</li>
<li>如果直接内存回收后，空闲的物理内存仍然无法满足此次物理内存的申请，那么内核就会放最后的大招了 ——触发 OOM （Out of Memory）机制。</li>
</ol>
<p>OOM Killer 机制：<br>会根据算法选择一个占用物理内存较高的进程，然后将其杀死，以便释放内存资源，如果物理内存依然不足，OOM Killer 会继续杀死占用物理内存较高的进程，直到释放足够的内存位置。</p>
<h3 id="哪些内存可以被回收？"><a href="#哪些内存可以被回收？" class="headerlink" title="哪些内存可以被回收？"></a>哪些内存可以被回收？</h3><ul>
<li><p>文件页：<strong>内核缓存的磁盘数据</strong>（Buffer）和<strong>内核缓存的文件数据</strong>（Cache）都叫作文件页。大部分文件页，都可以直接释放内存，以后有需要时，再从磁盘重新读取就可以了。而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放。<strong>回收干净页的方式是直接释放内存，回收脏页的方式是先写回磁盘后再释放内存</strong>。</p>
</li>
<li><p>匿名页：这部分内存没有实际载体，不像文件缓存有硬盘文件这样一个载体，比如堆、栈数据等。这部分内存很可能还要再次被访问，所以不能直接释放内存，它们回收的方式是通过 Linux 的<strong>Swap 机制</strong>，Swap 会把不常访问的内存先写到磁盘中，然后”释放”这些内存，给其他更需要的进程使用。再次访问这些内存时，重新从磁盘读入内存就可以了。</p>
</li>
</ul>
<p>Linux 提供了一个 &#x2F;proc&#x2F;sys&#x2F;vm&#x2F;swappiness 选项，用来调整文件页和匿名页的回收倾向。数值越大，越积极使用 Swap</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/sys/vm/swappiness</span><br></pre></td></tr></table></figure>


<h3 id="基于LRU算法"><a href="#基于LRU算法" class="headerlink" title="基于LRU算法"></a>基于LRU算法</h3><p>维护着 active 和 inactive 两个双向链表，其中：<br>active_list 活跃内存页链表，这里存放的是最近被访问过（活跃）的内存页；<br>inactive_list 不活跃内存页链表，这里存放的是很少被访问（非活跃）的内存页；</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/meminfo | grep -i active | sort</span><br></pre></td></tr></table></figure>


<h3 id="如何保护一个进程不被-OOM-杀掉呢？"><a href="#如何保护一个进程不被-OOM-杀掉呢？" class="headerlink" title="如何保护一个进程不被 OOM 杀掉呢？"></a>如何保护一个进程不被 OOM 杀掉呢？</h3><p>Linux 内核里有一个 oom_badness() 函数</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// points 代表打分的结果</span></span><br><span class="line"><span class="comment">// process_pages 代表进程已经使用的物理内存页面数</span></span><br><span class="line"><span class="comment">// oom_score_adj 代表 OOM 校准值</span></span><br><span class="line"><span class="comment">// totalpages 代表系统总的可用页面数</span></span><br><span class="line">points = process_pages + oom_score_adj*totalpages/<span class="number">1000</span></span><br></pre></td></tr></table></figure>

<p> oom_score_adj。它是可以通过 &#x2F;proc&#x2F;[pid]&#x2F;oom_score_adj 来配置的，设置 -1000 到 1000 之间的任意一个数值，-1000不会被杀死</p>
<h3 id="swap机制的作用"><a href="#swap机制的作用" class="headerlink" title="swap机制的作用"></a>swap机制的作用</h3><p><img data-src="/mybook.github.io/107475909264873.png"></p>
<p>在 32 位&#x2F;64 位操作系统环境下，申请的虚拟内存超过物理内存后会怎么样？</p>
<p>在 32 位操作系统，因为进程最大只能申请 3 GB 大小的虚拟内存，所以直接申请 8G 内存，会申请失败。<br>在 64 位操作系统，因为进程最大只能申请 128 TB 大小的虚拟内存，即使物理内存只有 4GB，申请 8G 内存也是没问题，因为申请的内存是虚拟内存。<br>程序申请的虚拟内存，如果没有被使用，它是不会占用物理空间的。<strong>当访问这块虚拟内存后，操作系统才会进行物理内存分配。</strong></p>
<p>如果申请物理内存大小超过了空闲物理内存大小，就要看操作系统有没有开启 Swap 机制：<br>如果没有开启 Swap 机制，程序就会直接 OOM；<br>如果有开启 Swap 机制，程序可以正常运行。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">free -m    #linux</span><br><span class="line">dir /A     #windows</span><br></pre></td></tr></table></figure>

<h2 id="内存的预读失效和缓存污染"><a href="#内存的预读失效和缓存污染" class="headerlink" title="内存的预读失效和缓存污染"></a>内存的预读失效和缓存污染</h2><p>预读失效：读磁盘多读了一些，但是没有用到<strong>（局部性原理的充分应用）</strong><br>缓存污染：批量读，把热点数据挤出去</p>
<p><strong>以上问题十分常见，包括操作系统，redis，mysql等</strong><br>Redis实现 LFU 算法，MySQL 和 Linux 操作系统是改进 LRU 算法<br>LRU算法是基于最近使用时间，其核心思想是<strong>淘汰最长时间未被使用的数据</strong>，这适用于访问模式具有时间局部性的场景；<br>LFU算法是基于访问频率，其核心思想是<strong>淘汰访问频率最低的数据</strong>，这适用于访问模式具有频率局部性的场景。</p>
<h3 id="Linux-的-Page-Cache-和-MySQL-的-Buffer-Pool"><a href="#Linux-的-Page-Cache-和-MySQL-的-Buffer-Pool" class="headerlink" title="Linux 的 Page Cache 和 MySQL 的 Buffer Pool"></a>Linux 的 Page Cache 和 MySQL 的 Buffer Pool</h3><p><img data-src="/mybook.github.io/321104711250370.png">                                    <img data-src="/mybook.github.io/439454711240900.png"></p>
<h3 id="解决预读失效"><a href="#解决预读失效" class="headerlink" title=" 解决预读失效"></a><font color="red"> 解决预读失效</font></h3><p>Linux 操作系统实现两个了 LRU 链表：活跃 LRU 链表（active_list）和非活跃 LRU 链表（inactive_list）；<br>预读页就只需要加入到 inactive list 区域的头部，当页被真正访问的时候，才将页插入 active list 的头部。</p>
<p><img data-src="/mybook.github.io/200245111243404.png"></p>
<p>MySQL 的 Innodb 存储引擎是在一个 LRU 链表上划分来 2 个区域：young 区域 和 old 区域。<br>预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部。</p>
<p><img data-src="/mybook.github.io/26395211252351.png"></p>
<h3 id="解决缓存污染"><a href="#解决缓存污染" class="headerlink" title="解决缓存污染"></a><font color="red">解决缓存污染</font></h3><p>Linux 操作系统：在内存页<strong>被访问第二次</strong>的时候，才将页从 inactive list 升级到 active list 里。<br>MySQL Innodb：在内存页被访问第二次的时候，并不会马上将该页从 old 区域升级到 young 区域，因为还要<strong>进行停留在 old 区域的时间判断</strong></p>
<p>如果第二次的访问时间与第一次访问的时间在 1 秒内（默认值），那么该页就不会被从 old 区域升级到 young 区域；<br>如果第二次的访问时间与第一次访问的时间超过 1 秒，那么该页就会从 old 区域升级到 young 区域；</p>
<h2 id="深入内存"><a href="#深入内存" class="headerlink" title="深入内存"></a>深入内存</h2><p>32位系统，用户态空间划分为3g大小：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/arch/x86/include/<span class="keyword">asm</span>/page_32_types.h        PAGE_OFFSET</span><br></pre></td></tr></table></figure>


<p><img data-src="/mybook.github.io/223035114245236.png"><img data-src="/mybook.github.io/507125114245845.png"></p>
<p>进程在内核中的描述符task_struct 结构</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">task_struct</span> &#123;</span><br><span class="line">        <span class="comment">// 进程id</span></span><br><span class="line">	    <span class="type">pid_t</span>				pid;</span><br><span class="line">        <span class="comment">// 用于标识线程所属的进程 pid</span></span><br><span class="line">	    <span class="type">pid_t</span>				tgid;</span><br><span class="line">        <span class="comment">// 进程打开的文件信息</span></span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">files_struct</span>		*files;</span><br><span class="line">        <span class="comment">// 内存描述符表示进程虚拟地址空间</span></span><br><span class="line">        <span class="keyword">struct</span> <span class="title class_">mm_struct</span>		*mm;</span><br><span class="line"></span><br><span class="line">        .......... 省略 .......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在进程描述符 task_struct 结构中，有一个专门描述进程虚拟地址空间的内存描述符 mm_struct 结构，这个结构体中包含了进程虚拟内存空间的全部信息。</p>
<p>当我们调用 fork() 函数创建进程的时候，表示进程地址空间的 mm_struct 结构会随着进程描述符 task_struct 的创建而创建</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="function"><span class="type">long</span> <span class="title">do_fork</span><span class="params">(<span class="type">unsigned</span> <span class="type">long</span> clone_flags,</span></span></span><br><span class="line"><span class="params"><span class="function">	      <span class="type">unsigned</span> <span class="type">long</span> stack_start,</span></span></span><br><span class="line"><span class="params"><span class="function">	      <span class="type">unsigned</span> <span class="type">long</span> stack_size,</span></span></span><br><span class="line"><span class="params"><span class="function">	      <span class="type">int</span> __user *parent_tidptr,</span></span></span><br><span class="line"><span class="params"><span class="function">	      <span class="type">int</span> __user *child_tidptr)</span></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">struct</span> task_struct *<span class="title">copy_process</span><span class="params">(<span class="type">unsigned</span> <span class="type">long</span> clone_flags,</span></span></span><br><span class="line"><span class="params"><span class="function">					<span class="type">unsigned</span> <span class="type">long</span> stack_start,</span></span></span><br><span class="line"><span class="params"><span class="function">					<span class="type">unsigned</span> <span class="type">long</span> stack_size,</span></span></span><br><span class="line"><span class="params"><span class="function">					<span class="type">int</span> __user *child_tidptr,</span></span></span><br><span class="line"><span class="params"><span class="function">					<span class="keyword">struct</span> pid *pid,</span></span></span><br><span class="line"><span class="params"><span class="function">					<span class="type">int</span> trace)</span></span></span><br><span class="line"><span class="function">					</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="type">int</span> <span class="title">copy_mm</span><span class="params">(<span class="type">unsigned</span> <span class="type">long</span> clone_flags, <span class="keyword">struct</span> task_struct *tsk)</span></span></span><br></pre></td></tr></table></figure>

<p>通过 fork() 函数创建出的子进程，它的虚拟内存空间以及相关页表相当于父进程虚拟内存空间的一份拷贝，直接从父进程中拷贝到子进程中。<br>通过 vfork() 函数创建出的子进程，首先会设置 CLONE_VM 标识，这样来到 copy_mm 函数中就会进入 if (clone_flags &amp; CLONE_VM) 条件中，在这个分支中会将父进程的虚拟内存空间以及相关页表直接赋值给子进程。这样一来父进程和子进程的虚拟内存空间就变成共享的了。也就是说父子进程之间使用的虚拟内存空间是一样的，并不是一份拷贝。<br>vfork() ：进程-&gt;线程，Linux 内核并不区别对待</p>
<h3 id="内核如何布局进程虚拟内存空间"><a href="#内核如何布局进程虚拟内存空间" class="headerlink" title="内核如何布局进程虚拟内存空间"></a>内核如何布局进程虚拟内存空间</h3><p>在mm_struct中，定义了各个数据域的长度</p>
<p><img data-src="/mybook.github.io/431122815272800.png"></p>
<h3 id="内核如何管理虚拟内存区域"><a href="#内核如何管理虚拟内存区域" class="headerlink" title="内核如何管理虚拟内存区域"></a>内核如何管理虚拟内存区域</h3><p>新的结构体 vm_area_struct，正是这个结构体<strong>描述了</strong>这些虚拟内存区域</p>
<p><img data-src="/mybook.github.io/424744115244311.png"></p>
<p>include&#x2F;linux&#x2F;mm.h：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vm_flags	访问权限</span><br><span class="line">VM_READ	可读</span><br><span class="line">VM_WRITE	可写</span><br><span class="line">VM_EXEC	可执行</span><br><span class="line">VM_SHARD	可多进程之间共享</span><br><span class="line">VM_IO	可映射至设备 IO 空间</span><br><span class="line">VM_RESERVED	内存区域不可被换出</span><br><span class="line">VM_SEQ_READ	内存区域可能被顺序访问</span><br><span class="line">VM_RAND_READ	内存区域可能被随机访问</span><br></pre></td></tr></table></figure>

<h3 id="虚拟内存区域在内核中是如何被组织的"><a href="#虚拟内存区域在内核中是如何被组织的" class="headerlink" title="虚拟内存区域在内核中是如何被组织的"></a>虚拟内存区域在内核中是如何被组织的</h3><p><img data-src="/mybook.github.io/295374815240562.png"></p>
<p>在进程虚拟内存空间中包含的内存区域 VMA 比较多的情况下，使用红黑树查找特定虚拟内存区域的时间复杂度是 O( logN ) ，可以显著减少查找所需的时间。<br>所以在内核中，同样的内存区域 vm_area_struct 会有两种组织形式，<strong>一种是双向链表用于高效的遍历，另一种就是红黑树用于高效的查找</strong>，每个 VMA 区域都是红黑树中的一个节点，通过 struct vm_area_struct 结构中的 vm_rb 将自己连接到红黑树中。</p>
<p>总结：mm_struct中的mmap为vm_area_struct类型，指向了每个域的开始和结束，并且同时以双向链表和红黑树存在，而mm_struct定义的start和end，标示了每个域的结束位置</p>
<h1 id="进程调度"><a href="#进程调度" class="headerlink" title="进程调度"></a>进程调度</h1><h2 id="Linux的进程"><a href="#Linux的进程" class="headerlink" title="Linux的进程"></a>Linux的进程</h2><h3 id="0号进程"><a href="#0号进程" class="headerlink" title="0号进程"></a>0号进程</h3><p>0号进程称为 idle 进程，其 pid 等于0。</p>
<p>每个进程都有struct task_struct。idle进程对应的PCB是 struct task_struct init_task。<br>idle进程是唯一一个没有通过fork或者kernel_thread产生的进程，因为 init_task 是静态变量（初始化了的全局变量），其他进程的PCB都是fork或者kernel_thread动态申请内存创建的。<br>每个进程都有对应的一个函数，idle进程的函数是 start_kernel()，start_kernel() 最后会调用 cpu_startup_entry() ，其内部是 while(1) {}</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">asmlinkage __visible <span class="type">void</span> __init <span class="title">start_kernel</span><span class="params">(<span class="type">void</span>)</span></span></span><br></pre></td></tr></table></figure>

<h3 id="1号进程"><a href="#1号进程" class="headerlink" title="1号进程"></a>1号进程</h3><p>1号进程称为 init 进程，其 pid 等于1。</p>
<p>1号进程是0号进程通过调用 kernel_thread() 创建的，在运行 schedule_preempt_disabled() 内的 schedule() 后，就启动调度器进行进程切换，kernel_init() 也就得以运行。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kernel_thread</span>(kernel_init, <span class="literal">NULL</span>, CLONE_FS);</span><br></pre></td></tr></table></figure>
<p>kernel_init() 最后会启动用户态的处于根文件系统存储的 init 进程，从而实现 init 内核态到 init 用户态的转化。<br>init进程完成系统的初始化，是系统中所有其它用户进程的祖先进程。</p>
<h3 id="2号进程"><a href="#2号进程" class="headerlink" title="2号进程"></a>2号进程</h3><p>2号进程称为 kthreadd 进程，其 pid 等于2。<br>kthreadd进程由idle进程通过kernel_thread创建，并始终运行在内核空间, 负责所有内核线程的创建。</p>
<p>kthreadd利用for(;;)一直驻留在内存中运行：主要过程如下：<br>检查kthread_create_list为空时，kthreadd让出cpu的执行权<br>kthread_create_list不为空时，利用while循环遍历kthread_create_list链表<br>每取下一个链表节点后调用create_kthread，创建内核线程</p>
<p><img data-src="/mybook.github.io/547263518240701.png"></p>
<p>kernel_thread()函数<strong>是通过调用do_fork()函数创建的线程，而do_fork()则是在应用层fork(), vfork()和clone()函数的系统调用</strong>；此外还需要在其执行函数里调用daemonize()进行资源的释放；该线程挂接在init进程下。<br>kthread_create()函数是通过工作队列workqueue创建的线程，此线程挂在kthreadd线程下。<br>kthread_run()函数本质上是调用了kthread_create()和wake_up_process(), 就是除了挂在工作队列上后，便唤醒进行工作。<br>kthread_create()是比较推崇的创建内核线程的方式。</p>
<h3 id="写时复制"><a href="#写时复制" class="headerlink" title="写时复制"></a><font color="red">写时复制</font></h3><p>在Linux程序中，fork()会产生一个和父进程完全相同的子进程，但子进程在此后多会exec系统调用，出于效率考虑，linux中引入了“写时复制“技术，也就是<strong>只有进程空间的各段的内容要发生变化时，才会将父进程的内容复制一份给子进程</strong><br>该技术是依赖硬件MMU的，没有MMU，就不支持 fork，只支持vfork。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __ARCH_WANT_SYS_FORK</span></span><br><span class="line"><span class="built_in">SYSCALL_DEFINE0</span>(fork)</span><br><span class="line">&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> CONFIG_MMU</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">do_fork</span>(SIGCHLD, <span class="number">0</span>, <span class="number">0</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">	<span class="comment">/* can not support in nommu mode */</span></span><br><span class="line">	<span class="keyword">return</span> -EINVAL;                    <span class="comment">//返回这个错误码需要被上层捕捉</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>


<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __ARCH_WANT_SYS_VFORK</span></span><br><span class="line"><span class="built_in">SYSCALL_DEFINE0</span>(vfork)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">do_fork</span>(CLONE_VFORK | CLONE_VM | SIGCHLD, <span class="number">0</span>,</span><br><span class="line">			<span class="number">0</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//写时复制COW体现在这个函数中: copy_mm-&gt;dup_mm-&gt;dup_mmap-&gt;.......-&gt;copy_one_pte</span></span><br><span class="line"><span class="function"><span class="type">static</span> <span class="keyword">inline</span> <span class="type">unsigned</span> <span class="type">long</span></span></span><br><span class="line"><span class="function"><span class="title">copy_one_pte</span><span class="params">(<span class="keyword">struct</span> mm_struct *dst_mm, <span class="keyword">struct</span> mm_struct *src_mm,</span></span></span><br><span class="line"><span class="params"><span class="function">		<span class="type">pte_t</span> *dst_pte, <span class="type">pte_t</span> *src_pte, <span class="keyword">struct</span> vm_area_struct *vma,</span></span></span><br><span class="line"><span class="params"><span class="function">		<span class="type">unsigned</span> <span class="type">long</span> addr, <span class="type">int</span> *rss)</span></span></span><br></pre></td></tr></table></figure>

<p><img data-src="/mybook.github.io/95371510264876.png"></p>
<p><strong>exec函数(#include &lt;unistd.h&gt;)：</strong><br>装载一个新的程序（可执行映像）覆盖当前进程内存空间中的映像，从而执行不同的任务。exec系列函数在执行时会直接替换掉当前进程的地址空间。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">execl</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *path, <span class="type">const</span> <span class="type">char</span> *arg,...<span class="comment">/* (char*)NULL*/</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execlp</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *file, <span class="type">const</span> <span class="type">char</span> *arg,...<span class="comment">/* (char*)NULL*/</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execle</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *path, <span class="type">const</span> <span class="type">char</span> *arg,...<span class="comment">/* (char*)NULL, char *const envp[]*/</span>)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execv</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *path, <span class="type">char</span> *<span class="type">const</span> argv[])</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execvp</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *file, <span class="type">char</span> *<span class="type">const</span> argv[])</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execvpe</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *file, <span class="type">char</span> *<span class="type">const</span> argv[], <span class="type">char</span> *<span class="type">const</span> envp[])</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">execve</span><span class="params">(<span class="type">const</span> <span class="type">char</span> *path, <span class="type">char</span> *<span class="type">const</span> argv[], <span class="type">char</span> *<span class="type">const</span> envp[])</span></span>;</span><br></pre></td></tr></table></figure>

<ul>
<li>在fork之后exec之前两个进程用的是相同的物理空间（内存区），子进程的代码段、数据段、堆栈都是指向父进程的物理空间，也就是说，两者的虚拟空间不同，但其对应的物理空间是同一个。当父子进程中有更改相应段的行为发生时，再为子进程相应的段分配物理空间</li>
<li>如果是因为exec，由于两者执行的代码不同，子进程的代码段也会分配单独的物理空间。</li>
<li>如果不是因为exec，内核会给子进程的数据段、堆栈段分配相应的物理空间（至此两者有各自的进程空间，互不影响），而代码段继续共享父进程的物理空间（两者的代码完全相同）。</li>
</ul>
<p><strong>写时复制的应用</strong></p>
<ol>
<li><p>虚拟内存管理中的写时复制<br>一般把这种被共享访问的页面标记为只读。当一个task试图向内存中写入数据时，内存管理单元（MMU）抛出一个异常，内核处理该异常时为该task分配一份物理内存并复制数据到此内存，重新向MMU发出执行该task的写操作。</p>
</li>
<li><p>Linux的文件管理系统使用了写时复制策略。</p>
</li>
<li><p>[数据库]服务器也一般采用了写时复制策略，为用户提供一份snapshot。</p>
</li>
<li><p>软件应用中的写时复制<br>[C++标准程序库]中的[std::string]类，在C++98&#x2F;C++03标准中是允许写时复制策略。但在[C++11]标准中为了提高并行性取消了这一策略。 GCC从版本5开始，std::string不再采用COW策略。</p>
</li>
</ol>
<h3 id="孤儿进程与僵尸进程"><a href="#孤儿进程与僵尸进程" class="headerlink" title="孤儿进程与僵尸进程"></a>孤儿进程与僵尸进程</h3><p>孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作，所以孤儿进程并不会有什么危害。</p>
<p>僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。</p>
<ul>
<li>父进程只管生成新的子进程，对子进程退出之后的事情，则一概不闻不问，系统运行一段时间后，系统中就会存在很多的僵死进程，用ps命令查看的话，就会看到很多状态为Z的进程。</li>
<li>僵死进程并不是问题的根源，罪魁祸首是产生出大量僵死进程的父进程。答案就是把产生大量僵死进程的那个元凶枪毙掉<mark>（通过kill发送SIGTERM或者SIGKILL信号）</mark></li>
<li>枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进程，这些孤儿进程会被init进程接管，init进程会wait()这些孤儿进程，释放它们占用的系统进程表中的资源。</li>
</ul>
<h3 id="守护进程"><a href="#守护进程" class="headerlink" title="守护进程"></a>守护进程</h3><p>守护进程（daemon）是后台运行的、系统启动是就存在的、不与任何终端关联的，用于处理一些系统级别任务的特殊进程。</p>
<h4 id="创建守护进程"><a href="#创建守护进程" class="headerlink" title="创建守护进程"></a>创建守护进程</h4><ol>
<li>fork()创建子进程，父进程exit()退出；</li>
</ol>
<ul>
<li>由于守护进程是脱离控制终端的，完成这一步后就会在Shell终端里造成程序已经运行完毕的假象。之后的所有工作都在子进程中完成，而用户在Shell终端里则可以执行其他命令，从而在形式上做到了与控制终端的脱离，在后台工作。</li>
<li>由于父进程先于子进程退出，子进程就变为孤儿进程，并由 init 进程作为其父进程收养。</li>
</ul>
<ol start="2">
<li>在子进程调用setsid()创建新会话；<br>在调用了 fork() 函数后，子进程全盘拷贝了父进程的会话期、进程组、控制终端等，虽然父进程退出了，但会话期、进程组、控制终端等并没有改变。这还不是真正意义上的独立开来，而 setsid() 函数能够使进程完全独立出来，摆脱其他进程的控制。</li>
</ol>
<p>setsid()创建一个新会话，调用进程担任新会话的首进程，其作用有：</p>
<ul>
<li>使当前进程脱离原会话的控制</li>
<li>使当前进程脱离原进程组的控制</li>
<li>使当前进程脱离原控制终端的控制</li>
</ul>
<ol start="3">
<li><p>在子进程中调用chdir()改变当前目录为根目录；<br>使用fork创建的子进程继承了父进程的当前工作目录。由于守护进程在后台运行，开始于系统开启，终止于系统关闭，所以要将其目录改为系统的根目录下。进程在执行时，其文件系统不能被卸下。</p>
</li>
<li><p>在子进程中调用umask()重设文件权限掩码为0；</p>
</li>
</ol>
<ul>
<li>文件权限掩码是指屏蔽掉文件权限中的对应位。比如，有个文件权限掩码是050，它就屏蔽了文件组拥有者的可读与可执行权限</li>
<li>由于使用fork函数新建的子进程继承了父进程的文件权限掩码，这就给该子进程使用文件带来了诸多的麻烦。因此把文件权限掩码重设为0即清除掩码（权限为777），这样可以大大增强该守护进程的灵活性。通常的使用方法为umask(0)。</li>
</ul>
<ol start="5">
<li>在子进程中close()不需要的文件描述符；</li>
</ol>
<ul>
<li>子进程从父进程那里继承了打开文件描述符。这些被打开的文件可能永远不会被守护进程读写，但它们一样消耗系统资源，而且可能导致所在的文件系统无法卸下。</li>
<li>在第二步之后，守护进程已经与控制终端失去了联系，终端输入的字符不可能达到守护进程，守护进程中用常规方法输出的字符也不可能在终端显示出来。所以，文件描述符为0、1和2 的3个文件（输入、输出和报错）已经失去了存在的价值，也应被关闭。</li>
</ul>
<ol start="6">
<li>守护进程退出处理<br>当用户需要外部停止守护进程运行时，往往会使用 kill 命令停止该守护进程。守护进程中需要编码来实现 kill 发出的signal信号处理，达到进程的正常退出。</li>
</ol>
<h2 id="进程和线程"><a href="#进程和线程" class="headerlink" title="进程和线程"></a>进程和线程</h2><h3 id="进程："><a href="#进程：" class="headerlink" title="进程："></a>进程：</h3><p><strong>程序段：</strong> 存放程序代码；<br><strong>数据段：</strong> 存放程序运行时使用、产生的运算数据，如全局变量、局部变量、宏定义的常量；<br><strong>PCB（task_struct）：</strong> 存放操作系统对程序进行管理所需的各种信息，如进程描述信息、进程控制和管理信息、资源分配清单、处理机相关信息。</p>
<h4 id="进程的组成"><a href="#进程的组成" class="headerlink" title="进程的组成"></a>进程的组成</h4><p>详细信息如下图：</p>
<p><img data-src="/mybook.github.io/416540910246114.png"></p>
<ul>
<li>代码段，包括<strong>二进制可执行代码</strong>；</li>
<li>数据段，包括<strong>已初始化的静态常量和全局变量</strong>；</li>
<li>BSS 段，包括<strong>未初始化的静态变量和全局变量</strong>；</li>
<li>堆段，包括动态分配的内存，<strong>从低地址开始向上增长</strong>；</li>
<li>文件映射段，包括动态库、共享内存等，<strong>从低地址开始向上增长</strong>（跟硬件和内核版本有关 (opens new window)）；</li>
<li>栈段，包括局部变量和函数调用的上下文等。<strong>从低地址开始向下增长</strong>，栈的大小是固定的，一般是 8 MB。当然系统也提供了参数，以便我们自定义大小；</li>
</ul>
<h4 id="并行和并发"><a href="#并行和并发" class="headerlink" title="并行和并发"></a>并行和并发</h4><p><img data-src="/mybook.github.io/468791310252792.png"></p>
<p>虽然单核的 CPU 在某一个瞬间，只能运行一个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生并行的错觉，实际上这是并发。</p>
<h4 id="进程的状态"><a href="#进程的状态" class="headerlink" title="进程的状态"></a>进程的状态</h4><p><img data-src="/mybook.github.io/114001410257831.png"></p>
<ul>
<li>创建状态（new）：进程正在被创建时的状态；</li>
<li>结束状态（Exit）：进程正在从系统中消失时的状态；</li>
<li>运行状态（Running）：该时刻进程占用 CPU；</li>
<li>就绪状态（Ready）：可运行，由于其他进程处于运行状态而暂时停止运行；</li>
<li>阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入&#x2F;输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；</li>
</ul>
<h3 id="线程："><a href="#线程：" class="headerlink" title="线程："></a>线程：</h3><p><strong>线程是进程当中的一条执行流程</strong>****</p>
<p><img data-src="/mybook.github.io/254071810259126.png"></p>
<ul>
<li>同⼀个进程内多个线程之间可以共享代码段、数据段、打开的⽂件等资源，</li>
<li>但每个线程各自都有⼀套独⽴的寄存器和栈，这样可以确保线程的控制流是相对独⽴的</li>
</ul>
<h4 id="线程共享的环境"><a href="#线程共享的环境" class="headerlink" title="线程共享的环境"></a>线程共享的环境</h4><p>包括：进程代码段、进程的公有数据(利用这些共享的数据，线程很容易的实现相互之间的通讯)、进程打开的文件描述符、信号的处理器、进程的当前目录和进程用户ID与进程组ID。</p>
<h4 id="线程的优点"><a href="#线程的优点" class="headerlink" title="线程的优点"></a>线程的优点</h4><ul>
<li>一个进程中可以同时存在多个线程；</li>
<li>各个线程之间可以并发执行；</li>
<li>各个线程之间可以共享地址空间和文件等资源；</li>
</ul>
<h4 id="线程的缺点"><a href="#线程的缺点" class="headerlink" title="线程的缺点"></a>线程的缺点</h4><p>当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（这里是针对 C&#x2F;C++ 语言，Java语言中的线程奔溃不会造成进程崩溃）。<br>举个例子，对于游戏的用户设计，则不应该使用多线程的方式，否则一个用户挂了，会影响其他同个进程的线程。</p>
<h4 id="线程上下文切换"><a href="#线程上下文切换" class="headerlink" title="线程上下文切换"></a>线程上下文切换</h4><p>当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；<br>当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；</p>
<h4 id="三种线程的实现⽅式"><a href="#三种线程的实现⽅式" class="headerlink" title="三种线程的实现⽅式"></a>三种线程的实现⽅式</h4><ul>
<li>⽤户线程（User Thread）：在⽤户空间实现的线程，不是由内核管理的线程，是由⽤户态的线程库来完成线程的管理；</li>
<li>内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程；</li>
<li>轻量级进程（LightWeight Process）：在内核中来⽀持⽤户线程；</li>
</ul>
<h5 id="用户线程"><a href="#用户线程" class="headerlink" title="用户线程"></a>用户线程</h5><p>用户线程的整个线程管理和调度，操作系统是不直接参与的，⽽是由⽤户级线程库函数来完成线程的管理，包括线程的创建、终⽌、同步和调度等。</p>
<p>⽤户线程的优点：</p>
<ul>
<li>每个进程都需要有它私有的线程控制块（TCB）列表，⽤来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由⽤户级线程库函数来维护，可⽤于不⽀持线程技术的操作系统</li>
<li>⽤户线程的切换也是由线程库函数来完成的，⽆需⽤户态与内核态的切换，所以速度特别快；</li>
</ul>
<p>⽤户线程的缺点：</p>
<ul>
<li>由于操作系统不参与线程的调度，如果⼀个线程发起了系统调⽤⽽阻塞，那进程所包含的⽤户线程都不能执⾏了。</li>
<li>当⼀个线程开始运⾏后，除⾮它主动地交出 CPU 的使⽤权，否则它所在的进程当中的其他线程⽆法运⾏，因为⽤户态的线程没法打断当前运⾏中的线程，它没有这个特权，只有操作系统才有，但是⽤户线程不是由操作系统管理的。</li>
<li>由于时间⽚分配给进程，故与其他进程⽐，在多线程执⾏时，每个线程得到的时间⽚较少，执⾏会⽐较慢；</li>
</ul>
<h5 id="内核线程"><a href="#内核线程" class="headerlink" title="内核线程"></a>内核线程</h5><p>内核线程是由操作系统管理的，线程对应的 TCB ⾃然是放在操作系统⾥的，这样线程的创建、终⽌和管理都是由操作系统负责。</p>
<p>内核线程的优点：</p>
<ul>
<li>在⼀个进程当中，如果某个内核线程发起系统调⽤⽽被阻塞，并不会影响其他内核线程的运⾏；</li>
<li>分配给线程，多线程的进程获得更多的 CPU 运⾏时间；</li>
</ul>
<p>内核线程的缺点：</p>
<ul>
<li>在⽀持内核线程的操作系统中，由内核来维护进程和线程的上下⽂信息，如 PCB 和TCB；</li>
<li>线程的创建、终⽌和切换都是通过系统调⽤的⽅式来进⾏，因此对于系统来说，系统开销⽐较⼤；</li>
</ul>
<h5 id="轻量级进程"><a href="#轻量级进程" class="headerlink" title="轻量级进程"></a>轻量级进程</h5><p>轻量级进程（LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。<br>轻量级进程通常共享相同的地址空间，但具有独立的堆栈和寄存器状态，从而实现了类似进程的隔离和并发执行。<br>LWP与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息</p>
<h3 id="线程与进程的⽐较"><a href="#线程与进程的⽐较" class="headerlink" title="线程与进程的⽐较"></a>线程与进程的⽐较</h3><ol>
<li>进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位；</li>
<li>进程拥有⼀个完整的资源平台，⽽线程只独享必不可少的资源，如寄存器和栈；</li>
<li>线程同样具有就绪、阻塞、执⾏三种基本状态，同样具有状态之间的转换关系；</li>
<li>线程能减少并发执⾏的时间和空间开销；</li>
</ol>
<h3 id="线程相⽐进程能减少开销"><a href="#线程相⽐进程能减少开销" class="headerlink" title="线程相⽐进程能减少开销"></a>线程相⽐进程能减少开销</h3><ul>
<li>线程的创建时间⽐进程快，因为进程在创建的过程中，还需要资源管理信息，⽐如内存管理信息、⽂件管理信息，⽽线程在创建的过程中，不会涉及这些资源管理信息，⽽是共享它们；</li>
<li>线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多；</li>
<li>同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同⼀个进程的线程都具有同⼀个⻚表，在切换的时候不需要切换⻚表。⽽进程之间切换的时候要把⻚表给切换掉，⻚表的切换过程开销是⽐较⼤的；</li>
<li>由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更⾼了；</li>
</ul>
<h3 id="多线程和多进程的比较"><a href="#多线程和多进程的比较" class="headerlink" title="多线程和多进程的比较"></a>多线程和多进程的比较</h3><p><img data-src="/mybook.github.io/2429254083522.png"></p>
<ol>
<li>需要频繁创建销毁的优先用线程。<br>实例：web服务器。来一个建立一个线程，断了就销毁线程。要是用进程，创建和销毁的代价是很难承受的。</li>
<li>需要进行大量计算的优先使用线程。<br>所谓大量计算，当然就是要消耗很多cpu，切换频繁了，这种情况先线程是最合适的。实例：图像处理、算法处理</li>
<li>强相关的处理用线程，若相关的处理用进程。<br>一般的server需要完成如下任务：消息收发和消息处理。消息收发和消息处理就是弱相关的任务，而消息处理里面可能又分为消息解码、业务处理，这两个任务相对来说相关性就要强多了。因此消息收发和消息处理可以分进程设计，消息解码和业务处理可以分线程设计。</li>
<li>可能扩展到多机分布的用进程，多核分布的用线程。</li>
</ol>
<h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><p>协程可以理解为用户态的轻量级的非抢占式的线程。可以在程序的某个点挂起，并在稍后恢复执行</p>
<p><strong>原理：</strong></p>
<ul>
<li>我们知道操作系统在线程等待IO的时候，会阻塞当前线程，切换到其它线程，这样在当前线程等待IO的过程中，其它线程可以继续执行。</li>
<li>当线程数量非常多的时候，却产生了问题。一是系统线程会占用非常多的内存空间，二是过多的线程切换会占用大量的系统时间。</li>
<li>协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。<mark>协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程</mark>，</li>
</ul>
<p><strong>特点：</strong><br>用户态:协程是在用户态实现调度。<br>轻量级:协程不用内核调度，不被被操作系统内核所管理，不需要内核态与用户态之间切换。<br>非抢占:协程是由用户自己实现调度，并且同一时间只能有一个协程在执行，协程自己主动交出CPU的。</p>
<p><strong>优点：</strong><br>协程切换的时候开销小，用户态且轻量<br>非抢占式，不用加很多锁，减小复杂度，不用很复杂的处理线程同步问题。</p>
<p><strong>缺点：</strong><br>协程可以在单线程内处理高并发,但是协程不能同时使用单个CPU的多个核心，不能利用多核，只能使用单核。<br>假设协程运行在线程之上，并且协程调用了一个阻塞IO操作，操作系统会让线程进入阻塞状态，<mark>当前的协程和其它绑定在该线程之上的协程都会陷入阻塞而得不到调度</mark>，这往往是不能接受的。因此，<strong>协程只有和异步IO结合起来才能发挥出最大的威力。</strong></p>
<h2 id="进程的通信"><a href="#进程的通信" class="headerlink" title="进程的通信"></a>进程的通信</h2><h3 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h3><p>所谓的管道，就是内核里面的一串缓存，所谓的管道，就是内核里面的一串缓存</p>
<h4 id="无名管道"><a href="#无名管道" class="headerlink" title="无名管道"></a>无名管道</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">pipe</span><span class="params">(<span class="type">int</span> fd[<span class="number">2</span>])</span></span>;</span><br></pre></td></tr></table></figure>
<p>fd[0]为读而打开，fd[1]为写而打开</p>
<p><img data-src="/mybook.github.io/312724210260128.png"></p>
<p>使用 fork 创建子进程，创建的子进程会复制父进程的文件描述符，但是管道只能一端写入，另一端读出，所以这种模式容易造成混乱，需要：<br>父进程关闭读取的 fd[0]，只保留写入的 fd[1]；<br>子进程关闭写入的 fd[1]，只保留读取的 fd[0]；</p>
<p><img data-src="/mybook.github.io/206554310260305.png">                   <strong>关闭后变为-&gt;</strong>        <img data-src="/mybook.github.io/345674310245857.png"></p>
<p><strong>执行A | B发生了什么</strong><br>A进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间不存在父子关系，它俩的父进程都是 shell。<br><img data-src="/mybook.github.io/291044710262136.png"></p>
<h4 id="命名管道"><a href="#命名管道" class="headerlink" title="命名管道"></a>命名管道</h4><p>也被叫做 FIFO ，因为数据是先进先出的传输⽅式。在使⽤命名管道前，先需要通过 mkfifo 命令来创建，并且指定管道名字：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">mkfifo</span> myPipe</span><br></pre></td></tr></table></figure>
<p>myPipe 就是这个管道的名称，基于 Linux ⼀切皆⽂件的理念，所以管道也是以⽂件的⽅式存在，我们可以⽤ ls 看⼀下，这个⽂件的类型是 p，也就是 pipe（管道） 的意思：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">ls</span> -l</span><br><span class="line">prw-r--r--. 1 root root 0 Jul 17 02:45 myPipe</span><br></pre></td></tr></table></figure>

<p>管道传输数据是单向的，如果想相互通信，我们需要创建两个管道才⾏。管道这种通信⽅式效率低，不适合进程间频繁地交换数据。    </p>
<ul>
<li>对于匿名管道，<strong>它的通信范围是存在⽗⼦关系的进程</strong>。因为管道没有实体，也就是没有管道⽂件，只能通过 fork 来复制⽗进程 fd ⽂件描述符，来达到通信的⽬的。</li>
<li>对于命名管道，<strong>它可以在不相关的进程间也能相互通信</strong>。因为命令管道，提前创建了⼀个类型为管道的设备⽂件，在进程⾥只要使⽤这个设备⽂件，就可以相互通信。</li>
</ul>
<h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">msgget</span>();</span><br></pre></td></tr></table></figure>
<p><mark>消息队列是保存在内核中的消息链表，</mark>消息队列不适合⽐较⼤数据的传输，<br><mark>消息队列通信过程中，存在⽤户态与内核态之间的数据拷⻉开销</mark>，因为进程写⼊数据到内核中的消息队列时，会发⽣从⽤户态拷⻉数据到内核态的过程，同理另⼀进程读取内核中的消息数据时，会发⽣从内核态拷⻉数据到⽤户态的过程。</p>
<h3 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">shmget</span>();</span><br></pre></td></tr></table></figure>
<p>多个进程将同一个文件（内存的匿名段）映射到它们的地址空间<br>共享内存的机制，就是拿出⼀块虚拟地址空间来，映射到相同的物理内存中。<br><img data-src="/mybook.github.io/98108102469.png"></p>
<h4 id="存储映射I-O（mmap）"><a href="#存储映射I-O（mmap）" class="headerlink" title="存储映射I&#x2F;O（mmap）"></a><font color="red">存储映射I&#x2F;O（mmap）</font></h4><p>mmap将一个文件或者其它对象映射进内存上<br>mmap操作提供了一种机制，让用户程序直接访问设备内存，这种机制，相比较在用户空间和内核空间互相拷贝数据，效率更高。在要求高性能的应用中比较常用。mmap映射内存必须是页面大小的整数倍，面向流的设备不能进行mmap，mmap的实现和硬件有关。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/mman.h&gt;</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> *<span class="title">mmap</span><span class="params">(<span class="type">void</span> *addr,<span class="type">size_t</span> len,<span class="type">int</span> prot,<span class="type">int</span> flags,<span class="type">int</span> fd,<span class="type">off_t</span> off)</span></span>;</span><br></pre></td></tr></table></figure>
<p><img data-src="/mybook.github.io/4064114819868.png"></p>
<ul>
<li>两个进程中通信<br>两个程序映射同一个文件到自己的地址空间, 进程A先运行, 每隔两秒读取映射区域, 看是否发生变化. 进程B后运行, 它修改映射区域, 然后推出, 此时进程A能够观察到存储映射区的变化。</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/mman.h&gt;</span>  </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BUF_SIZE 100  </span></span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc, <span class="type">char</span> **argv)</span>  </span></span><br><span class="line"><span class="function"></span>&#123;  </span><br><span class="line">    <span class="type">int</span> fd, nread, i;  </span><br><span class="line">    <span class="keyword">struct</span> <span class="title class_">stat</span> sb;  </span><br><span class="line">    <span class="type">char</span> *mapped, buf[BUF_SIZE];  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; BUF_SIZE; i++) &#123;  </span><br><span class="line">        buf[i] = <span class="string">&#x27;#&#x27;</span>;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/* 打开文件 */</span>  </span><br><span class="line">    <span class="keyword">if</span> ((fd = <span class="built_in">open</span>(argv[<span class="number">1</span>], O_RDWR)) &lt; <span class="number">0</span>) &#123;  </span><br><span class="line">        <span class="built_in">perror</span>(<span class="string">&quot;open&quot;</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/* 获取文件的属性 */</span>  </span><br><span class="line">    <span class="keyword">if</span> ((<span class="built_in">fstat</span>(fd, &amp;sb)) == <span class="number">-1</span>) &#123;  </span><br><span class="line">        <span class="built_in">perror</span>(<span class="string">&quot;fstat&quot;</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/* 将文件映射至进程的地址空间 */</span>  </span><br><span class="line">    <span class="keyword">if</span> ((mapped = (<span class="type">char</span> *)<span class="built_in">mmap</span>(<span class="literal">NULL</span>, sb.st_size, PROT_READ |   </span><br><span class="line">                    PROT_WRITE, MAP_SHARED, fd, <span class="number">0</span>)) == (<span class="type">void</span> *)<span class="number">-1</span>) &#123;  </span><br><span class="line">        <span class="built_in">perror</span>(<span class="string">&quot;mmap&quot;</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/* 文件已在内存, 关闭文件也可以操纵内存 */</span>  </span><br><span class="line">    <span class="built_in">close</span>(fd);  </span><br><span class="line">      </span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 进程A：每隔两秒查看存储映射区是否被修改 */</span>  </span><br><span class="line">    <span class="keyword">while</span> (<span class="number">1</span>) &#123;  </span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%s\n&quot;</span>, mapped);  </span><br><span class="line">        <span class="built_in">sleep</span>(<span class="number">2</span>);  </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* 进程B：修改一个字符 */</span>  </span><br><span class="line">    mapped[<span class="number">20</span>] = <span class="string">&#x27;9&#x27;</span>;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;  </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>



<h3 id="信号量"><a href="#信号量" class="headerlink" title="信号量"></a>信号量</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">semget</span>();</span><br></pre></td></tr></table></figure>
<p>信号量其实是⼀个整型的计数器，主要⽤于实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据。</p>
<p>信号量表示资源的数量，控制信号量的⽅式有两种原⼦操作：</p>
<ul>
<li>⼀个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占⽤，进程需阻塞等待；相减后如果信号量 &gt;&#x3D; 0，则表明还有资源可使⽤，进程可正常继续执⾏。</li>
<li>⼀个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 &lt;&#x3D; 0，则表明当前有阻塞中的进程，于是会将阻塞的进程唤醒运⾏；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；</li>
</ul>
<p><img data-src="/mybook.github.io/595705014240451.png"></p>
<ul>
<li><strong>信号初始化为 1 ，就代表着是互斥信号量</strong>，它可以保证共享内存在任何时刻只有⼀个进程在访问，这就很好的保护了共享内存<br>进程 A 在访问共享内存前，先执⾏了 P 操作，由于信号量的初始值为 1，故在进程 A 执 ⾏ P 操作后信号量变为 0，表示共享资源可⽤，于是进程 A 就可以访问共享内存。<br>若此时，进程 B 也想访问共享内存，执⾏了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占⽤，因此进程 B 被阻塞。<br>直到进程 A 访问完共享内存，才会执⾏ V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执⾏ V 操作，使信号量恢复到初始值 1。</li>
</ul>
<p><img data-src="/mybook.github.io/290185114258877.png"></p>
<ul>
<li><strong>信号初始化为 0 ，就代表着是同步信号量</strong>，它可以保证进程 A 应在进程 B 之前执⾏。<br>如果进程 B ⽐进程 A 先执⾏了，那么执⾏到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没⽣产数据，于是进程 B 就阻塞等待；<br>接着，当进程 A ⽣产完数据后，执⾏了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；<br>最后，进程 B 被唤醒后，意味着进程 A 已经⽣产了数据，于是进程 B 就可以正常读取数据了。</li>
</ul>
<h3 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h3><p>对于异常情况下的⼯作模式，就需要⽤「信号」的⽅式来通知进程。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">kill</span> -l</span><br><span class="line"> 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5)SIGTRAP</span><br><span class="line"> 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10)SIGUSR1</span><br><span class="line">11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15)SIGTERM</span><br><span class="line">16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20)SIGTSTP</span><br><span class="line">21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25)SIGXFSZ</span><br><span class="line">26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30)SIGPWR</span><br><span class="line">31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37)SIGRTMIN+3</span><br><span class="line">38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42)SIGRTMIN+8</span><br><span class="line">43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47)SIGRTMIN+13</span><br><span class="line">48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52)SIGRTMAX-12</span><br><span class="line">53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57)SIGRTMAX-7</span><br><span class="line">58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62)SIGRTMAX-2</span><br></pre></td></tr></table></figure>
<p>Ctrl+C 产⽣ SIGINT（2） （可被忽略）信号，表示终⽌该进程；<br>Ctrl+Z 产⽣ SIGTSTOP（19） 信号，表示挂起该进程，但还未结束；</p>
<p><strong>唯⼀的异步通信机制</strong>。进程有三种⽅式响应信号 1. 执⾏默认操作、2. 捕捉信号、3. 忽略信号。有两个信号是应⽤进程<mark>⽆法捕捉和忽略</mark>的，即<mark>SIGKILL（9） 和 SEGSTOP（19） </mark>，这是为了⽅便我们能在任何时候结束或停⽌某个进程</p>
<h3 id="Socket"><a href="#Socket" class="headerlink" title="Socket"></a>Socket</h3><p>TCP网络编程<br><img data-src="/mybook.github.io/4171516095354.png"></p>
<ul>
<li>服务端和客户端初始化 socket ，得到⽂件描述符；</li>
<li>服务端调⽤ bind ，将绑定在 IP 地址和端⼝;</li>
<li>服务端调⽤ listen ，进⾏监听；</li>
<li>服务端调⽤ accept ，等待客户端连接；</li>
<li>客户端调⽤ connect ，向服务器端的地址和端⼝发起连接请求；</li>
<li>服务端 accept 返回⽤于传输的 socket 的⽂件描述符；</li>
<li>客户端调⽤ write 写⼊数据；服务端调⽤ read 读取数据；</li>
<li>客户端断开连接时，会调⽤ close ，那么服务端 read 读取数据的时候，就会读取到了EOF ，待处理完数据后，服务端调⽤ close ，表示连接关闭</li>
</ul>
<h2 id="线程的同步与互斥"><a href="#线程的同步与互斥" class="headerlink" title="线程的同步与互斥"></a>线程的同步与互斥</h2><p><strong>如果要访问共享资源（内存，变量等），必须考虑互斥</strong>，保证一个线程在临界区执行时，其他线程应该被阻止进入</p>
<h3 id="互斥量（互斥锁）"><a href="#互斥量（互斥锁）" class="headerlink" title="互斥量（互斥锁）"></a>互斥量（互斥锁）</h3><p>pthread_mutex_******<br>确保同一时间只有一个线程访问数据</p>
<h3 id="读写锁（共享互斥锁）"><a href="#读写锁（共享互斥锁）" class="headerlink" title="读写锁（共享互斥锁）"></a>读写锁（共享互斥锁）</h3><p>pthread_rwlock_******<br>一次只有一个线程可以占有写模式的读写锁，多个线程可以同时占有读模式的读写锁</p>
<ul>
<li>写加锁状态时，所有试图对这个锁加锁的线程都会被阻塞</li>
<li>读加锁状态时，所有试图以读模式对它加锁的线程都可以得到访问权，所有试图以写模式对它加锁的线程都会阻塞</li>
</ul>
<h3 id="条件变量"><a href="#条件变量" class="headerlink" title="条件变量"></a>条件变量</h3><p>pthread_cond_******</p>
<ul>
<li>条件变量与互斥量一起使用时，允许线程以无竞争的方式等待特定的条件发生。</li>
<li>条件本身是由互斥量保护的。线程在改变条件状态之前必须首先锁住互斥量。其他线程在获得互斥量之前不会察觉到这种改变，因为互斥量必须在锁定以后才能计算条件。</li>
<li>传递给pthread_cond_wait的<mark>互斥量对条件变量进行保护</mark>。调用者把锁住的互斥量传给函数，函数然后自动把调用线程放到等待条件的线程列表上，对互斥量解锁。</li>
</ul>
<h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><p>pthread_spin_******</p>
<ul>
<li>互斥锁加锁失败后，线程会释放 CPU ，给其他线程；</li>
<li>⾃旋锁加锁失败后，线程会忙等待，直到它拿到锁；</li>
<li>当加锁失败时，互斥锁⽤「线程切换」来应对，⾃旋锁则⽤「忙等待」来应对</li>
<li>在单核CPU 上，需要抢占式的调度器（即不断通过时钟中断⼀个线程，运⾏其他线程）。否则，⾃旋锁在单 CPU 上⽆法使⽤，因为⼀个⾃旋的线程永远不会放弃 CPU。</li>
</ul>
<h3 id="屏障"><a href="#屏障" class="headerlink" title="屏障"></a>屏障</h3><p>pthread_barrier_******<br>是用户协调多个线程并行工作的同步机制。屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。pthread_join函数就是一种屏障，允许一个线程等待，直到另一个线程退出。<br>但是屏障对象的概念更广，它们允许任意数量的线程等待，直到所有的线程完成处理工作，而线程不需要退出。所有线程达到屏障后可以接着工作。</p>
<h3 id="信号量-1"><a href="#信号量-1" class="headerlink" title="信号量"></a>信号量</h3><p>P、V 操作，见上文信号量</p>
<h3 id="信号-1"><a href="#信号-1" class="headerlink" title="信号"></a>信号</h3><h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><h3 id="死锁的四个条件"><a href="#死锁的四个条件" class="headerlink" title="死锁的四个条件"></a>死锁的四个条件</h3><p>互斥条件；互斥条件是指多个线程不能同时使⽤同⼀个资源。<br>持有并等待条件； 一个进程本身占有资源（一种或多种），同时还有资源未得到满足，等待其他进程释放该资源。<br>不可剥夺条件；当线程已经持有了资源 ，在⾃⼰使⽤完之前不能被其他线程获取，<br>环路等待条件；在死锁发⽣的时候，两个线程获取资源的顺序构成了环形链。</p>
<h3 id="死锁预防"><a href="#死锁预防" class="headerlink" title="死锁预防"></a>死锁预防</h3><p>确保系统永远不会进入死锁状态<br><mark>a、破坏“占有且等待”条件</mark></p>
<ol>
<li>所有的进程在开始运行之前，必须一次性地申请其在整个运行过程中所需要的全部资源。</li>
<li>允许进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到的已经使用完毕的资源，然后再去请求新的资源。</li>
</ol>
<p><mark>b、破坏“不可抢占”条件</mark><br>当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。</p>
<p><mark>c、破坏“循环等待”条件</mark><br> 可以通过定义资源类型的线性顺序来预防，可将每个资源编号，当一个进程占有编号为i的资源时，那么它下一次申请资源只能申请编号大于i的资源。</p>
<h3 id="避免死锁"><a href="#避免死锁" class="headerlink" title="避免死锁"></a>避免死锁</h3><p>在分配资源时判断是否会出现死锁，只在不会出现死锁的情况下才分配资源。<br>两种避免办法：<br>    1、如果一个进程的请求会导致死锁，则不启动该进程<br>    2、如果一个进程的增加资源请求会导致死锁 ，则拒绝该申请。</p>
<p>避免死锁的具体实现通常利用<strong>银行家算法</strong><br>可利用资源向量Available：用于表示系统里边各种资源剩余的数目。<br>最大需求矩阵Max：用于表示各个进程对各种资源的额最大需求量。<br>分配矩阵Allocation：就是用于表示已经分配给各个进程的各种资源的数目。也是一个nxm的矩阵。<br>需求矩阵Need：用于表示进程仍然需要的资源数目，用一个nxm的矩阵表示。</p>
<h3 id="哲学家就餐问题"><a href="#哲学家就餐问题" class="headerlink" title="哲学家就餐问题"></a>哲学家就餐问题</h3><p>方案一：<br>让偶数编号的哲学家「先拿左边的叉⼦后拿右边的叉⼦」，奇数编号的哲学家「先拿右边的叉⼦后拿左边的叉⼦」。</p>
<p><img data-src="/mybook.github.io/2239037095963.png"></p>
<p>方案二：<br>用一个数组 state 来记录每一位哲学家的三个状态，分别是在进餐状态、思考状态、饥饿状态（正在试图拿叉子）。那么，一个哲学家只有在两个邻居都没有进餐时，才可以进入进餐状态。第 i 个哲学家的左邻右舍，则由宏 LEFT 和 RIGHT 定义：<br>LEFT : ( i + 5 - 1 ) % 5<br>RIGHT : ( i + 1 ) % 5<br>比如 i 为 2，则 LEFT 为 1，RIGHT 为 3。</p>
<p><img data-src="/mybook.github.io/283411416246744.png"></p>
<h3 id="悲观锁与乐观锁"><a href="#悲观锁与乐观锁" class="headerlink" title="悲观锁与乐观锁"></a>悲观锁与乐观锁</h3><ol>
<li>悲观锁做事⽐较悲观，它认为多线程同时修改共享资源的概率⽐较⾼，于是很容易出现冲突，所以访问共享资源前，先要上锁。</li>
<li>乐观锁做事⽐较乐观，它假定冲突的概率很低，先修改完共享资源，再验证这段时间内有没有发⽣冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。<br>应用：在线文档多人编辑</li>
</ol>
<h1 id="调度算法"><a href="#调度算法" class="headerlink" title="调度算法"></a>调度算法</h1><h2 id="调度的原则"><a href="#调度的原则" class="headerlink" title="调度的原则"></a>调度的原则</h2><ul>
<li>CPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；</li>
<li>系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；</li>
<li>周转时间：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；</li>
<li>等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；</li>
<li>响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。</li>
</ul>
<h2 id="进程调度算法"><a href="#进程调度算法" class="headerlink" title="进程调度算法"></a>进程调度算法</h2><h3 id="先来先服务调度算法"><a href="#先来先服务调度算法" class="headerlink" title="先来先服务调度算法"></a>先来先服务调度算法</h3><h3 id="最短作业优先调度算法"><a href="#最短作业优先调度算法" class="headerlink" title="最短作业优先调度算法"></a>最短作业优先调度算法</h3><h3 id="高响应比优先调度算法"><a href="#高响应比优先调度算法" class="headerlink" title="高响应比优先调度算法"></a>高响应比优先调度算法</h3><p><img data-src="/mybook.github.io/4947119118995.png"></p>
<p>如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应⽐」就越⾼，这样短作业的进程容易被选中运⾏；<br>如果两个进程「要求的服务时间」相同时，「等待时间」越⻓，「响应⽐」就越⾼，这就兼顾到了⻓作业进程，因为进程的响应⽐可以随时间等待的增加⽽提⾼，当其等待时间⾜够⻓时，其响应⽐便可以升到很⾼，从⽽获得运⾏的机会；</p>
<h3 id="时间⽚轮转调度算法"><a href="#时间⽚轮转调度算法" class="headerlink" title="时间⽚轮转调度算法"></a>时间⽚轮转调度算法</h3><p>如果时间⽚设得太短会导致过多的进程上下⽂切换，降低了 CPU 效率；如果设得太⻓⼜可能引起对短作业进程的响应时间变⻓。</p>
<h3 id="最⾼优先级调度算法"><a href="#最⾼优先级调度算法" class="headerlink" title="最⾼优先级调度算法"></a>最⾼优先级调度算法</h3><p>静态优先级：创建进程时候，就已经确定了优先级了，然后整个运⾏时间优先级都不会变化；<br>动态优先级：根据进程的动态变化调整优先级，如果进程运⾏时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升⾼其优先级，也就是随着时间的推移增加等待进程的优先级。<br>⾮抢占式：当就绪队列中出现优先级⾼的进程，运⾏完当前进程，再选择优先级⾼的进程。<br>抢占式：当就绪队列中出现优先级⾼的进程，当前进程挂起，调度优先级⾼的进程运⾏。<br>但是依然有缺点，可能会导致低优先级的进程永远不会运⾏。</p>
<h3 id="多级反馈队列调度算法"><a href="#多级反馈队列调度算法" class="headerlink" title="多级反馈队列调度算法"></a>多级反馈队列调度算法</h3><p><img data-src="/mybook.github.io/5290937106862.png"></p>
<p>设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短；新的进程会被放⼊到第⼀级队列的末尾，按先来先服务的原则排队等待被调度，如果在第⼀级队列规定的时间⽚没运⾏完成，则将其转⼊到第⼆级队列的末尾，以此类推，直⾄完成；<br>当较⾼优先级的队列为空，才调度较低优先级的队列中的进程运⾏。如果进程运⾏时，有新进程进⼊较⾼优先级的队列，则停⽌当前运⾏的进程并将其移⼊到原队列末尾，接着让较⾼优先级的进程运⾏；</p>
<h2 id="内存页面置换算法"><a href="#内存页面置换算法" class="headerlink" title="内存页面置换算法"></a>内存页面置换算法</h2><h3 id="最佳⻚⾯置换算法"><a href="#最佳⻚⾯置换算法" class="headerlink" title="最佳⻚⾯置换算法"></a>最佳⻚⾯置换算法</h3><p>最佳⻚⾯置换算法基本思路是，置换在「未来」最⻓时间不访问的⻚⾯。</p>
<h3 id="先进先出置换算法"><a href="#先进先出置换算法" class="headerlink" title="先进先出置换算法"></a>先进先出置换算法</h3><p>既然我们⽆法预知⻚⾯在下⼀次访问前所需的等待时间，那我们可以选择在内存驻留时间很⻓的⻚⾯进⾏中置换，这个就是「先进先出置换」算法的思想</p>
<h3 id="最近最久未使⽤的置换算法"><a href="#最近最久未使⽤的置换算法" class="headerlink" title="最近最久未使⽤的置换算法"></a>最近最久未使⽤的置换算法</h3><p>最近最久未使⽤（LRU）的置换算法的基本思路是，发⽣缺⻚时，选择最⻓时间没有被访问的⻚⾯进⾏置换，</p>
<h4 id="LRU缓存"><a href="#LRU缓存" class="headerlink" title="LRU缓存"></a>LRU缓存</h4><p>像浏览器的缓存策略、memcached的缓存策略都是使用LRU这个算法，LRU算法会将近期最不会访问的数据淘汰掉。<br><img data-src="/mybook.github.io/1128100686625.png"></p>
<ul>
<li>新数据插入到链表头部</li>
<li>每当缓存命中（即缓存数据被访问），则将数据移到链表头部</li>
<li>当链表满的时候，将链表尾部的数据丢弃</li>
</ul>
<p>LRU Cache具备的操作：<br>set(key,value)：如果key在hashmap中存在，则先重置对应的value值，然后获取对应的节点cur，将cur节点从链表删除，并移动到链表的头部；若果key在hashmap不存在，则新建一个节点，并将节点放到链表的头部。当Cache存满的时候，将链表最后一个节点删除即可。<br>get(key)：如果key在hashmap中存在，则把对应的节点放到链表头部，并返回对应的value值；如果不存在，则返回-1。</p>
<p>LRU的c++实现：<br>LRU实现采用双向链表 + Map 来进行实现。这里采用双向链表的原因是：如果采用普通的单链表，则删除节点的时候需要从表头开始遍历查找，效率为O(n)，采用双向链表可以直接改变节点的前驱的指针指向进行删除达到O(1)的效率。使用Map来保存节点的key、value值便于能在O(logN)的时间查找元素,对应get操作。</p>
<p>双链表节点的定义：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> <span class="title class_">CacheNode</span> &#123;</span><br><span class="line"> <span class="type">int</span> key;  <span class="comment">// 键</span></span><br><span class="line"> <span class="type">int</span> value; <span class="comment">// 值</span></span><br><span class="line"> CacheNode *pre, *next; <span class="comment">// 节点的前驱、后继指针</span></span><br><span class="line"> <span class="built_in">CacheNode</span>(<span class="type">int</span> k, <span class="type">int</span> v) : <span class="built_in">key</span>(k), <span class="built_in">value</span>(v), <span class="built_in">pre</span>(<span class="literal">NULL</span>), <span class="built_in">next</span>(<span class="literal">NULL</span>) &#123;&#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>对于LRUCache这个类而言，构造函数需要指定容量大小</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">LRUCache</span>(<span class="type">int</span> capacity)</span><br><span class="line">&#123;</span><br><span class="line"> size = capacity;  <span class="comment">// 容量</span></span><br><span class="line"> head = <span class="literal">NULL</span>;   <span class="comment">// 链表头指针</span></span><br><span class="line"> tail = <span class="literal">NULL</span>;   <span class="comment">// 链表尾指针</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>双链表的节点删除操作：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">remove</span><span class="params">(CacheNode *node)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> <span class="keyword">if</span> (node -&gt; pre != <span class="literal">NULL</span>)</span><br><span class="line"> &#123;</span><br><span class="line"> node -&gt; pre -&gt; next = node -&gt; next;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> &#123;</span><br><span class="line"> head = node -&gt; next;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">if</span> (node -&gt; next != <span class="literal">NULL</span>)</span><br><span class="line"> &#123;</span><br><span class="line"> node -&gt; next -&gt; pre = node -&gt; pre;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> &#123;</span><br><span class="line"> tail = node -&gt; pre;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>将节点插入到头部的操作：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">setHead</span><span class="params">(CacheNode *node)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> node -&gt; next = head;</span><br><span class="line"> node -&gt; pre = <span class="literal">NULL</span>;</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">if</span> (head != <span class="literal">NULL</span>)</span><br><span class="line"> &#123;</span><br><span class="line"> head -&gt; pre = node;</span><br><span class="line"> &#125;</span><br><span class="line"> head = node;</span><br><span class="line"> <span class="keyword">if</span> (tail == <span class="literal">NULL</span>)</span><br><span class="line"> &#123;</span><br><span class="line"> tail = head;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>get(key)操作的实现比较简单，直接通过判断Map是否含有key值即可，如果查找到key，则返回对应的value，否则返回-1;</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">get</span><span class="params">(<span class="type">int</span> key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> map&lt;<span class="type">int</span>, CacheNode *&gt;::iterator it = mp.<span class="built_in">find</span>(key);</span><br><span class="line"> <span class="keyword">if</span> (it != mp.<span class="built_in">end</span>())</span><br><span class="line"> &#123;</span><br><span class="line"> CacheNode *node = it -&gt; second;</span><br><span class="line"> <span class="built_in">remove</span>(node);</span><br><span class="line"> <span class="built_in">setHead</span>(node);</span><br><span class="line"> <span class="keyword">return</span> node -&gt; value;</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> &#123;</span><br><span class="line"> <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>set(key, value)操作需要分情况判断。如果当前的key值对应的节点已经存在，则将这个节点取出来，并且删除节点所处的原有的位置，并在头部插入该节点；如果节点不存在节点中，这个时候需要在链表的头部插入新节点，插入新节点可能导致容量溢出，如果出现溢出的情况，则需要删除链表尾部的节点。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">set</span><span class="params">(<span class="type">int</span> key, <span class="type">int</span> value)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"> map&lt;<span class="type">int</span>, CacheNode *&gt;::iterator it = mp.<span class="built_in">find</span>(key);</span><br><span class="line"> <span class="keyword">if</span> (it != mp.<span class="built_in">end</span>())</span><br><span class="line"> &#123;</span><br><span class="line"> CacheNode *node = it -&gt; second;</span><br><span class="line"> node -&gt; value = value;</span><br><span class="line"> <span class="built_in">remove</span>(node);</span><br><span class="line"> <span class="built_in">setHead</span>(node);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line"> &#123;</span><br><span class="line"> CacheNode *newNode = <span class="keyword">new</span> <span class="built_in">CacheNode</span>(key, value);</span><br><span class="line"> <span class="keyword">if</span> (mp.<span class="built_in">size</span>() &gt;= size)</span><br><span class="line"> &#123;</span><br><span class="line">  map&lt;<span class="type">int</span>, CacheNode *&gt;::iterator iter = mp.<span class="built_in">find</span>(tail -&gt; key);</span><br><span class="line">  <span class="built_in">remove</span>(tail);</span><br><span class="line">  mp.<span class="built_in">erase</span>(iter);</span><br><span class="line"> &#125;</span><br><span class="line"> <span class="built_in">setHead</span>(newNode);</span><br><span class="line"> mp[key] = newNode;</span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="时钟⻚⾯置换算法"><a href="#时钟⻚⾯置换算法" class="headerlink" title="时钟⻚⾯置换算法"></a>时钟⻚⾯置换算法</h3><p><img data-src="/mybook.github.io/5742525189098.png"></p>
<p><img data-src="/mybook.github.io/1333708746621.png"></p>
<h3 id="最不常⽤算法"><a href="#最不常⽤算法" class="headerlink" title="最不常⽤算法"></a>最不常⽤算法</h3><p>当发⽣缺⻚中断时，选择「访问次数」最少的那个⻚⾯，并将其淘汰。</p>
<h2 id="磁盘调度算法"><a href="#磁盘调度算法" class="headerlink" title="磁盘调度算法"></a>磁盘调度算法</h2><h3 id="先来先服务算法"><a href="#先来先服务算法" class="headerlink" title="先来先服务算法"></a>先来先服务算法</h3><h3 id="最短寻道时间优先算法"><a href="#最短寻道时间优先算法" class="headerlink" title="最短寻道时间优先算法"></a>最短寻道时间优先算法</h3><p>根据距离磁头最近的请求的算法</p>
<h3 id="扫描算法（电梯算法）"><a href="#扫描算法（电梯算法）" class="headerlink" title="扫描算法（电梯算法）"></a>扫描算法（电梯算法）</h3><p>磁头在⼀个⽅向上移动，访问所有未完成的请求，直到磁头到达该⽅向上的最后的磁道，才调换⽅向，这就是扫描（Scan）算法。<br><img data-src="/mybook.github.io/5363799515717.png"></p>
<h3 id="循环扫描算法"><a href="#循环扫描算法" class="headerlink" title="循环扫描算法"></a>循环扫描算法</h3><p>只有磁头朝某个特定⽅向移动时，才处理磁道访问请求，⽽返回时直接快速移动⾄最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应⼀个⽅向上的请求。<br><img data-src="/mybook.github.io/3568121535713.png"><br>循环扫描算法相⽐于扫描算法，对于各个位置磁道响应频率相对⽐较平均。</p>
<h1 id="文件系统"><a href="#文件系统" class="headerlink" title="文件系统"></a>文件系统</h1><p>一切皆文件</p>
<h2 id="Linux的文件类型"><a href="#Linux的文件类型" class="headerlink" title="Linux的文件类型"></a>Linux的文件类型</h2><ol>
<li>普通文件<br>普通文件根据存放的内容的不同，又分为如下两种：</li>
</ol>
<ul>
<li><p>文本文件<br>存放的都是文字编码，文本编辑器打开后，会将这些文字编码翻译为文字图形，以供人识别。</p>
</li>
<li><p>纯二进制文件（机器码）</p>
</li>
<li><p><input disabled type="checkbox"> 
比如经过编译后得到的可执行文件，里面放的是cpu执行的纯二进制机器码，由于文编编辑器只认识文字编码，所以用文本编辑器打开后，显示的内容无法是错乱的，无法辨识。命令cat就是一个二进制文件</p>
</li>
<li><p><input disabled type="checkbox"> 
其实不管存放的是文字编码，还是机器码，在计算机中存储时，其实都是以二进制形式存放的，只不过我们这里可刻意的把机器码这类非文字编码的数据，特意强调为了二进制数据。</p>
</li>
<li><p><input disabled type="checkbox"> 
对linux内核而言，这两种文件并无区别，至于文件中的数据如何解释，则由处理这些数据的应用程序（比如文本编辑器）来决定。</p>
</li>
<li><p><input disabled type="checkbox"> 
不管是文字编码数据，还是纯二进制数据，应用程序调用read、write读写文件时，没有任何区别。</p>
</li>
</ul>
<ol start="2">
<li>目录文件<br>目录是一种特殊的文件，专门用于管理其它文件。第一个属性为 [d]，例如 [drwxrwxrwx]。</li>
<li>字符设备文件<br>字符设备文件，就是字符设备驱动程序，在上层的表现形式。<br>当应用程序调用底层字符设备驱动程序，实现对某个字符设备进行读写时，上层就需要对接底层的字符驱动程序，字符设备驱动在上层，会以“字符设备文件”的形式表现出来，我们通过open、read、write去读写字符设备文件，就实现了和底层字符设备驱动程序的交互。</li>
<li>块设备文件<br>对应块设备（如磁盘等）。<br>块设备文件，是块设备驱动程序在上层的表现形式。</li>
</ol>
<ul>
<li><mark>字符设备与块设备有什么区别？</mark><br>（a）字符设备<br>以字节为单位来操作数据。<br>比如：键盘、鼠标、显示器都等是字符设备。<br>（b）块设备<br>块设备存储的数据量往往非常大，为了提高读写效率，都是以块（1024字节）为单位来操作数据。<br>比如：电脑硬盘、移动硬盘、u盘等，凡是涉及大量数据存储的，都是以块为单位来操作数据的，都是块设备。</li>
</ul>
<ol start="5">
<li>FIFO（fifo：p）<br>管道文件，用于实现不同进程（程序）之间的通信，管道是OS提供的一种纯代码层面的通信机制。<br>A进程 ————————&gt; 管道文件 ————————&gt;B进程</li>
<li>套接字文件（socket：s）<br>专门用于网络通信的文件。</li>
</ol>
<h2 id="文件的管理"><a href="#文件的管理" class="headerlink" title="文件的管理"></a>文件的管理</h2><p>索引节点，也就是 inode，用来记录文件的元信息，比如 inode 编号、文件大小、访问权限、创建时间、修改时间、数据在磁盘的位置等等。索引节点是文件的唯一标识，它们之间一一对应，也同样都会被存储在硬盘中，所以索引节点同样占用磁盘空间。<br>目录项，也就是 dentry，用来记录文件的名字、索引节点指针以及与其他目录项的层级关联关系。多个目录项关联起来，就会形成目录结构，但它与索引节点不同的是，<strong>目录项是由内核维护的一个数据结构，不存放于磁盘，而是缓存在内存。</strong></p>
<p>磁盘读写的最小单位是扇区，扇区的大小只有 512B 大小，Linux 读写逻辑块，逻辑块大小为 4KB，也就是一次性读写 8 个扇区。</p>
<p><img data-src="/mybook.github.io/503013809240452.png"></p>
<p>磁盘进行格式化的时候，会被分成三个存储区域，分别是超级块、索引节点区和数据块区。</p>
<ul>
<li>超级块：用来存储文件系统的详细信息，比如块个数、块大小、空闲块等等。当文件系统挂载时进入内存。</li>
<li>索引节点区：用来存储索引节点；当文件被访问时进入内存</li>
<li>数据块区：用来存储文件或目录数据；</li>
</ul>
<h2 id="文件的存放方式"><a href="#文件的存放方式" class="headerlink" title="文件的存放方式"></a>文件的存放方式</h2><p>连续空间存放方式<br>缺陷：「磁盘空间碎片」和「文件长度不易扩展」</p>
<p>非连续空间存放方式：「链表方式」和「索引方式」</p>
<p>「隐式链表」的方式存放<br>实现的方式是文件头要包含「第一块」和「最后一块」的位置，并且每个数据块里面留出一个指针空间，用来存放下一个数据块的位置，</p>
<p><img data-src="/mybook.github.io/104654809258878.png"></p>
<p>缺点在于无法直接访问数据块，只能通过指针顺序访问文件，以及数据块指针消耗了一定的存储空间。隐式链接分配的稳定性较差，系统在运行过程中由于软件或者硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失</p>
<p>「显式链接」的方式存放<br>它指把用于链接文件各数据块的指针，显式地存放在内存的一张链接表中，该表在整个磁盘仅设置一张，每个表项中存放链接指针，指向下一个数据块号。</p>
<p><img data-src="/mybook.github.io/280175009246745.png"></p>
<p>缺点是不适用于大磁盘</p>
<p>「索引方式」</p>
<p>单索引</p>
<p><img data-src="/mybook.github.io/552165409256135.png"></p>
<p>链表 + 索引</p>
<p><img data-src="/mybook.github.io/437125409259580.png"></p>
<p>多级索引块</p>
<p><img data-src="/mybook.github.io/60975509251889.png"></p>
<h2 id="Unix和Linux-Ext-2-3"><a href="#Unix和Linux-Ext-2-3" class="headerlink" title="Unix和Linux Ext 2&#x2F;3"></a>Unix和Linux Ext 2&#x2F;3</h2><p><img data-src="/mybook.github.io/144745809269769.png"></p>
<h2 id="空闲空间管理"><a href="#空闲空间管理" class="headerlink" title="空闲空间管理"></a>空闲空间管理</h2><h3 id="空闲表法"><a href="#空闲表法" class="headerlink" title="空闲表法"></a>空闲表法</h3><p>适用于建立连续文件</p>
<p><img data-src="/mybook.github.io/527295909267373.png"></p>
<h3 id="空闲链表法"><a href="#空闲链表法" class="headerlink" title="空闲链表法"></a>空闲链表法</h3><p><img data-src="/mybook.github.io/145370110264875.png"></p>
<h3 id="位图法"><a href="#位图法" class="headerlink" title="位图法"></a>位图法</h3><p>在 Linux 文件系统就采用了位图的方式来管理空闲空间，不仅用于数据空闲块的管理，还用于 inode 空闲块的管理，</p>
<p>「位图 + 数据」<br>每位表示一个数据块，共可以表示 4 * 1024 * 8 &#x3D; 2^15 个空闲块，由于 1 个数据块是 4K 大小，那么最大可以表示的空间为 2^15 * 4 * 1024 &#x3D; 2^27 个 byte，也就是 128M。表示的大小过少，Linux使用块组结构</p>
<p><img data-src="/mybook.github.io/594342710246116.png"></p>
<ul>
<li>超级块，包含的是文件系统的重要信息，比如 inode 总个数、块总个数、每个块组的 inode 个数、每个块组的块个数等等。</li>
<li>块组描述符，包含文件系统中各个块组的状态，比如块组中空闲块和 inode 的数目等，每个块组都包含了文件系统中「所有块组的组描述符信息」。</li>
<li>数据位图和 inode 位图， 用于表示对应的数据块或 inode 是空闲的，还是被使用中。</li>
<li>inode 列表，包含了块组中所有的 inode，inode 用于保存文件系统中与各个文件和目录相关的所有元数据。</li>
<li>数据块，包含文件的有用数据。</li>
</ul>
<p>超级块和块组描述符表，这两个都是全局信息，而且非常的重要，这么做是有两个原因：<br>如果系统崩溃破坏了超级块或块组描述符，有关文件系统结构和内容的所有信息都会丢失。如果有冗余的副本，该信息是可能恢复的。<br>通过使文件和管理数据尽可能接近，减少了磁头寻道和旋转，这可以提高文件系统的性能。</p>
<h2 id="目录的管理"><a href="#目录的管理" class="headerlink" title="目录的管理"></a>目录的管理</h2><p>目录文件的块里面保存的是目录里面一项一项的文件信息。</p>
<p><img data-src="/mybook.github.io/301453410268556.png"></p>
<h2 id="软链接-ln-s-和硬链接-ln-d）"><a href="#软链接-ln-s-和硬链接-ln-d）" class="headerlink" title="软链接(ln -s)和硬链接(ln -d）"></a>软链接(ln -s)和硬链接(ln -d）</h2><h3 id="硬链接"><a href="#硬链接" class="headerlink" title="硬链接"></a>硬链接</h3><p> 多个目录项中的「索引节点」指向一个文件，也就是指向同一个 inode。<strong>每个文件系统都有各自的 inode 数据结构和列表，所以硬链接是不可用于跨文件系统的</strong>。由于多个目录项都是指向一个 inode，那么只有删除文件的所有硬链接以及源文件时，系统才会彻底删除该文件。</p>
<p><img data-src="/mybook.github.io/366183610263692.png"></p>
<h3 id="软链接"><a href="#软链接" class="headerlink" title="软链接"></a>软链接</h3><p>相当于重新创建一个文件，这个文件有独立的 inode，但是这个文件的内容是另外一个文件的路径，所以访问软链接的时候，实际上相当于访问到了另外一个文件，所以软链接是可以跨文件系统的，甚至目标文件被删除了，链接文件还是在的，只不过指向的文件找不到了而已。</p>
<p><img data-src="/mybook.github.io/234184310240902.png" alt="软链接"></p>
<h2 id="文件I-O"><a href="#文件I-O" class="headerlink" title="文件I&#x2F;O"></a><font color="red">文件I&#x2F;O</font></h2><h3 id="缓冲与非缓冲-I-O"><a href="#缓冲与非缓冲-I-O" class="headerlink" title="缓冲与非缓冲 I&#x2F;O"></a>缓冲与非缓冲 I&#x2F;O</h3><p>文件操作的标准库是可以实现数据的缓存，那么根据「是否利用标准库缓冲」，可以把文件 I&#x2F;O 分为缓冲 I&#x2F;O 和非缓冲 I&#x2F;O：</p>
<ul>
<li>缓冲 I&#x2F;O，利用的是标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件。</li>
<li>非缓冲 I&#x2F;O，直接通过系统调用访问文件，不经过标准库缓存。<br>这里所说的「缓冲」特指标准库内部实现的缓冲。</li>
</ul>
<p>例如，很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存了起来，这样做的目的是，减少系统调用的次数，毕竟系统调用是有 CPU 上下文切换的开销的。</p>
<h3 id="直接与非直接-I-O"><a href="#直接与非直接-I-O" class="headerlink" title="直接与非直接 I&#x2F;O"></a>直接与非直接 I&#x2F;O</h3><p>我们都知道磁盘 I&#x2F;O 是非常慢的，所以 Linux 内核为了减少磁盘 I&#x2F;O 次数，在系统调用后，会把用户数据拷贝到内核中缓存起来，<strong>这个内核缓存空间也就是「页缓存」（page cache），只有当缓存满足某些条件的时候，才发起磁盘 I&#x2F;O 的请求。</strong></p>
<p>那么，根据是「否利用操作系统的缓存」，可以把文件 I&#x2F;O 分为直接 I&#x2F;O 与非直接 I&#x2F;O：</p>
<p>直接 I&#x2F;O，不会发生内核缓存和用户程序之间数据复制，而是直接经过文件系统访问磁盘。<br>非直接 I&#x2F;O，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给内核缓存，再由内核决定什么时候写入数据到磁盘。</p>
<p><strong>非直接I&#x2F;O下，什么时候刷盘？</strong></p>
<ol>
<li>在调用 write 的最后，当发现内核缓存的数据太多的时候，内核会把数据写到磁盘上；</li>
<li>用户主动调用 sync，内核缓存会刷到磁盘上；</li>
<li>当内存十分紧张，无法再分配页面时，也会把内核缓存的数据刷到磁盘上；</li>
<li>内核缓存的数据的缓存时间超过某个时间时，也会把数据刷到磁盘上；</li>
</ol>
<h3 id="阻塞与非阻塞I-O"><a href="#阻塞与非阻塞I-O" class="headerlink" title="阻塞与非阻塞I&#x2F;O"></a>阻塞与非阻塞I&#x2F;O</h3><p>阻塞等待的是<strong>内核数据准备好</strong> 和 <strong>数据从内核态拷贝到用户态</strong>这两个过程</p>
<p><img data-src="/mybook.github.io/422510511240452.png"></p>
<p>非阻塞 I&#x2F;O，非阻塞的 read 请求在数据未准备好的情况下<strong>立即返回，可以继续往下执行</strong>，此时应用程序不断<strong>轮询内核</strong>，直到数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果。<br>最后一次 read 调用，获取数据的过程，<strong>是一个同步的过程，是需要等待的过程</strong>。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。</p>
<p><img data-src="/mybook.github.io/253940811258878.png"></p>
<h3 id="同步与异步-I-O"><a href="#同步与异步-I-O" class="headerlink" title="同步与异步 I&#x2F;O"></a>同步与异步 I&#x2F;O</h3><p>使用 select I&#x2F;O 多路复用过程。注意，read 获取数据的过程（数据从内核态拷贝到用户态的过程），也是<strong>一个同步的过程</strong>，需要等待</p>
<p><img data-src="/mybook.github.io/375061511246745.png"></p>
<p>是否阻塞一般指的是进程、线程状态，是否异步一般指的是是否依赖其它任务已经完成</p>
<ul>
<li>如果这个进程、线程在等待当前函数返回时，仍在执行其他消息处理，那这种情况就叫做同步非阻塞；</li>
<li>如果这个进程、线程在等待当前函数返回时，没有执行其他消息处理，而是处于挂起等待状态，那这种情况就叫做同步阻塞；</li>
</ul>
<p>所以，<strong>阻塞 I&#x2F;O、非阻塞 I&#x2F;O，还是基于非阻塞 I&#x2F;O 的多路复用都是同步调用</strong>。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。</p>
<p>异步I&#x2F;O：</p>
<p><img data-src="/mybook.github.io/421221711266911.png"></p>
<h3 id="信号驱动式IO"><a href="#信号驱动式IO" class="headerlink" title="信号驱动式IO"></a>信号驱动式IO</h3><p>信号驱动式I&#x2F;O是指进程预先告知内核，使得当某个描述符上发生某事时，内核使用信号通知相关进程。当数据报到达时触发SIGIO信号，该信号通知数据已经到来，并没有将数据都入到应用程序的buffer中。因此，还需要我们在SIGIO信号处理函数中，手动的读取到来的数据，将其存放在buffer中。</p>
<p><img data-src="/mybook.github.io/551232711258987.png"></p>
<p><strong>总结</strong></p>
<p><img data-src="/mybook.github.io/206442911246854.png"></p>
<h2 id="Page-Cache"><a href="#Page-Cache" class="headerlink" title="Page Cache"></a>Page Cache</h2><p>非直接I&#x2F;O中，内核会找个合适的时机，将 page cache 中的数据持久化到磁盘。但是如果 page cache 里的文件数据，在持久化到磁盘化到磁盘之前，系统发生了崩溃，那这部分数据就会丢失了。</p>
<p>当然， 我们也可以在程序里调用 fsync 函数，在写文文件的时候，立刻将文件数据持久化到磁盘，这样就可以解决系统崩溃导致的文件数据丢失的问题。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/meminfo</span><br><span class="line"></span><br><span class="line">Buffers + Cached + SwapCached = Active(file) + Inactive(file) + Shmem + SwapCached</span><br></pre></td></tr></table></figure>
<p>Page Cache 用于缓存文件的页数据，buffer cache 用于缓存块设备（如磁盘）的块数据。</p>
<h3 id="文件持久化的一致性-可靠性"><a href="#文件持久化的一致性-可靠性" class="headerlink" title="文件持久化的一致性&amp;可靠性"></a>文件持久化的一致性&amp;可靠性</h3><p>当前 Linux 下以两种方式实现文件一致性：</p>
<p>Write Through（写穿）：向用户层提供特定接口，应用程序可主动调用接口来保证文件一致性；<br>Write back（写回）：系统中存在定期任务（表现形式为内核线程），周期性地同步文件系统中文件脏数据块，这是默认的 Linux 一致性方案；</p>
<table>
<thead>
<tr>
<th align="center">方法</th>
<th align="center">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="center">fsync(intfd)</td>
<td align="center">fsync(fd)：将 fd 代表的文件的脏数据和脏元数据全部刷新至磁盘中。</td>
</tr>
<tr>
<td align="center">fdatasync(int fd)</td>
<td align="center">fdatasync(fd)：将 fd 代表的文件的脏数据刷新至磁盘，同时对必要的元数据刷新至磁盘中，这里所说的必要的概念是指：对接下来访问文件有关键作用的信息，如文件大小，而文件修改时间等不属于必要信息</td>
</tr>
<tr>
<td align="center">sync()</td>
<td align="center">sync()：则是对系统中所有的脏的文件数据元数据刷新至磁盘中</td>
</tr>
</tbody></table>
<ul>
<li>关于多线程的架构问题，Linux 内核采取了 Lighthttp 的做法，即系统中存在一个管理线程和多个刷新线程（每个持久存储设备对应一个刷新线程）。</li>
<li>管理线程监控设备上的脏页面情况，若设备一段时间内没有产生脏页面，就销毁设备上的刷新线程；若监测到设备上有脏页面需要回写且尚未为该设备创建刷新线程，那么创建刷新线程处理脏页面回写。</li>
<li>而刷新线程的任务较为单调，只负责将设备中的脏页面回写至持久存储设备中。</li>
</ul>
<p>刷新线程刷新设备上脏页面大致设计如下：<br>每个设备保存脏文件链表，保存的是该设备上存储的脏文件的 inode 节点。所谓的回写文件脏页面即回写该 inode 链表上的某些文件的脏页面；</p>
<p>系统中存在多个回写时机:</p>
<ol>
<li>第一是应用程序主动调用回写接口（fsync，fdatasync 以及 sync 等）</li>
<li>第二管理线程周期性地唤醒设备上的回写线程进行回写</li>
<li>第三是某些应用程序&#x2F;内核任务发现内存不足时要回收部分缓存页面而事先进行脏页面回写，设计一个统一的框架来管理这些回写任务非常有必要。</li>
</ol>
<h2 id="Swap详解"><a href="#Swap详解" class="headerlink" title="Swap详解"></a>Swap详解</h2><p>操作系统以 page 为单位管理内存，当进程发现需要访问的数据不在内存时，操作系统可能会将数据以页的方式加载到内存中。上述过程被称为<strong>缺页中断</strong>，当操作系统发生缺页中断时，就会通过系统调用将 page 再次读到内存中。</p>
<h1 id="设备管理"><a href="#设备管理" class="headerlink" title="设备管理"></a>设备管理</h1><p><img data-src="/mybook.github.io/106675315259580.png"></p>
<h2 id="I-O-控制⽅式"><a href="#I-O-控制⽅式" class="headerlink" title="I&#x2F;O 控制⽅式"></a>I&#x2F;O 控制⽅式</h2><ol>
<li>轮询等待<br>让 CPU ⼀直查寄存器的状态，直到状态标记为完成，很明显，这种⽅式⾮常的傻⽠，它会占⽤ CPU 的全部时间。</li>
<li>中断<br>通知操作系统数据已经准备好了。我们⼀般会有⼀个硬件的中断控制器，当设备完成任务后触发中断到中断控制器，中断控制器就通知 CPU，⼀个中断产⽣了，CPU 需要停下当前⼿⾥的事情来处理中断。<br>另外，中断有两种，⼀种软中断，例如代码调⽤ INT 指令触发，⼀种是硬件中断，就是硬件通过中断控制器触发的。<br>但中断的⽅式对于频繁读写数据的磁盘，并不友好，这样 CPU 容易经常被打断，会占⽤CPU ⼤量的时间。对于这⼀类设备的问题的解决⽅法是使⽤ DMA功能，它可以使得设备在 CPU 不参与的情况下，能够⾃⾏完成把设备 I&#x2F;O 数据放⼊到内存。那要实现 DMA 功能要有 「DMA 控制器」硬件的⽀持。</li>
</ol>
<h2 id="DMA技术"><a href="#DMA技术" class="headerlink" title="DMA技术"></a><font color="red">DMA技术</font></h2><p>实现了文件I&#x2F;O的第一道流程</p>
<p>在进⾏ I&#x2F;O 设备和内存的数据传输的时候，数据搬运的⼯作全部交给 DMA 控制器，⽽ CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。</p>
<p><img data-src="/mybook.github.io/3320624841468.png"></p>
<ol>
<li>⽤户进程调⽤ read ⽅法，向操作系统发出 I&#x2F;O 请求，请求读取数据到⾃⼰的内存缓冲区中，进程进⼊阻塞状态；</li>
<li>操作系统收到请求后，进⼀步将 I&#x2F;O 请求发送 DMA，然后让 CPU 执⾏其他任务；</li>
<li>DMA 进⼀步将 I&#x2F;O 请求发送给磁盘；</li>
<li>磁盘收到 DMA 的 I&#x2F;O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知⾃⼰缓冲区已满；</li>
<li>DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷⻉到内核缓冲区中，此时不占⽤CPU，CPU 可以执⾏其他任务；</li>
<li>当 DMA 读取了⾜够多的数据，就会发送中断信号给 CPU；</li>
<li>CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷⻉到⽤户空间，系统调⽤返回；</li>
</ol>
<h2 id="传统文件传输"><a href="#传统文件传输" class="headerlink" title="传统文件传输"></a>传统文件传输</h2><p>两个系统调用：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">read</span>(file, tmp_buf, len);</span><br><span class="line"><span class="built_in">write</span>(socket, tmp_buf, len);</span><br></pre></td></tr></table></figure>

<p>4 次用户态与内核态的上下文切换， 4 次数据拷贝</p>
<p><img data-src="/mybook.github.io/324970016256135.png"></p>
<h2 id="零拷贝技术"><a href="#零拷贝技术" class="headerlink" title="零拷贝技术"></a><font color="red">零拷贝技术</font></h2><ul>
<li>要想提⾼⽂件传输的性能，就需要<strong>减少⽤户态与内核态的上下⽂切换</strong>和<strong>内存拷贝</strong>的次数。</li>
</ul>
<ol>
<li>方案一：<br>mmap（见上文共享内存） + write</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">buf = <span class="built_in">mmap</span>(file, len);</span><br><span class="line"><span class="built_in">write</span>(sockfd, buf, len);</span><br></pre></td></tr></table></figure>
<p>mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，可以减少一次数据拷贝，但是需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次，3次数据拷贝</p>
<p><img data-src="/mybook.github.io/165871416251889.png"></p>
<ol start="2">
<li>方案二：<br>sendfile();</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">ssize_t</span> <span class="title">sendfile</span><span class="params">(<span class="type">int</span> out_fd, <span class="type">int</span> in_fd, <span class="type">off_t</span> *offset, <span class="type">size_t</span> count)</span></span>;</span><br><span class="line"><span class="comment">//前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。</span></span><br></pre></td></tr></table></figure>
<p>只有 2 次上下文切换，和 3 次数据拷贝</p>
<p><img data-src="/mybook.github.io/515381916269769.png"></p>
<ol start="3">
<li>方案三（真正的零拷贝）：<br>网卡需支持SG-DMA技术<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">ethtool -k eth0 | grep scatter-gather</span></span><br><span class="line">scatter-gather: on</span><br></pre></td></tr></table></figure></li>
</ol>
<p><img data-src="/mybook.github.io/3305717821354.png"></p>
<ol>
<li>通过 DMA 将磁盘上的数据拷⻉到内核缓冲区⾥；</li>
<li>缓冲区描述符和数据⻓度传到 socket 缓冲区，这样⽹卡的 SG-DMA 控制器就可以<strong>直接将内核缓存中的数据拷⻉到⽹卡的缓冲区⾥</strong>，此过程不需要将数据从操作系统内核缓冲区拷⻉到 socket 缓冲区中，这样就减少了⼀次数据拷⻉；</li>
</ol>
<p><strong>零拷⻉技术的⽂件传输⽅式相⽐传统⽂件传输的⽅式，减少了 2 次上下⽂切换和数据拷⻉次数，只需要 2 次上下⽂切换和数据拷⻉次数，就可以完成⽂件的传输，⽽且 2 次的数据拷⻉过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。</strong></p>
<p><strong>零拷贝技术的应用：Kafka、Nginx、Java NIO 库里的 transferTo方法</strong></p>
<h2 id="理想的文件传输方式"><a href="#理想的文件传输方式" class="headerlink" title="理想的文件传输方式"></a>理想的文件传输方式</h2><p>传输⽂件的时候，我们要根据⽂件的⼤⼩来使⽤不同的⽅式：<br>传输⼤⽂件的时候，使⽤「异步 I&#x2F;O + 直接 I&#x2F;O」；<br>传输⼩⽂件的时候，则使⽤「零拷⻉技术」；</p>
<h2 id="I-O多路复用"><a href="#I-O多路复用" class="headerlink" title="I&#x2F;O多路复用"></a>I&#x2F;O多路复用</h2><h3 id="select"><a href="#select" class="headerlink" title="select"></a>select</h3><p>select 实现多路复⽤的⽅式是，将已连接的 Socket 都放到⼀个⽂件描述符集合，然后调⽤select 函数<mark>将⽂件描述符集合拷⻉到内核⾥</mark>，让内核来检查是否有⽹络事件产⽣，检查的⽅式很粗暴，就是<mark>通过遍历</mark>⽂件描述符集合的⽅式，当检查到有事件产⽣后，将此 Socket 标记为可读或可写， 接着<mark>再把整个⽂件描述符集合拷⻉回⽤户态⾥</mark>，然后⽤户态还需要<mark>再通过遍历</mark>的⽅法找到可读或可写的 Socket，然后再对其处理。</p>
<p>所以，对于 select 这种⽅式，需要进行2 次「遍历」⽂件描述符集合，⼀次是在内核态⾥，⼀个次是在⽤户态⾥ ，⽽且还会发⽣ 2 次「拷⻉」⽂件描述符集合，先从⽤户空间传⼊内核空间，由内核修改后，再传出到⽤户空间中。<br>select 使⽤固定⻓度的 BitsMap，表示⽂件描述符集合，⽽且所⽀持的⽂件描述符的个数是有限制的。</p>
<h3 id="poll"><a href="#poll" class="headerlink" title="poll"></a>poll</h3><p>poll 不再⽤ BitsMap 来存储所关注的⽂件描述符，取⽽代之⽤<mark>动态数组，以链表形式来组织</mark>，突破了 select 的⽂件描述符个数限制，当然还会受到系统⽂件描述符限制。<br>但是 poll 和 select 并没有太⼤的本质区别，都是使⽤<strong>线性结构</strong>存储进程关注的 Socket集合，因此都需要遍历⽂件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，⽽且也需要在⽤户态与内核态之间拷⻉⽂件描述符集合，这种⽅式随着并发数上来，性能的损耗会呈指数级增⻓。</p>
<h3 id="epoll"><a href="#epoll" class="headerlink" title="epoll"></a>epoll</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> s = <span class="built_in">socket</span>(AF_INET, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line"><span class="built_in">bind</span>(s, ...);</span><br><span class="line"><span class="built_in">listen</span>(s, ...)</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> epfd = <span class="built_in">epoll_create</span>(...);</span><br><span class="line"><span class="built_in">epoll_ctl</span>(epfd, ...); <span class="comment">//将所有需要监听的socket添加到epfd中</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="type">int</span> n = <span class="built_in">epoll_wait</span>(...);</span><br><span class="line">    <span class="keyword">for</span>(接收到数据的socket)&#123;</span><br><span class="line">        <span class="comment">//处理</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先创建一个epoll对象，然后使用epoll_ctl对这个对象进行操作，把需要监控的描述添加进去，这些描述如将会以epoll_event结构体的形式组成一颗红黑树，接着阻塞在epoll_wait，进入大循环，当某个fd上有事件发生时，内核将会把其对应的结构体放入到一个链表中，返回有事件发生的链表。</p>
<ul>
<li>第⼀点，<mark>epoll 在内核⾥使⽤红⿊树来跟踪进程所有待检测的⽂件描述字</mark>，把需要监控的socket 通过 epoll_ctl() 函数加⼊内核中的红⿊树⾥，红⿊树是个⾼效的数据结构，<mark>增删查⼀般时间复杂度是 O(logn)</mark> ，通过对这棵⿊红树进⾏操作，这样就不需要像 select&#x2F;poll 每次操作时都传⼊整个 socket 集合，只需要传⼊⼀个待检测的 socket，<mark>减少了内核和⽤户空间⼤量的数据拷贝和内存分配</mark></li>
<li>第⼆点， epoll 使⽤事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件，当某个socket 有事件发⽣时，通过回调函数内核会将其加⼊到这个就绪事件列表中，当⽤户调⽤epoll_wait() 函数时，只会返回有事件发⽣的⽂件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，⼤⼤提⾼了检测的效率。</li>
<li>第三点，使用__put_user 函数，将数据从内核拷贝到用户空间，而非共享内存</li>
</ul>
<p><img data-src="/mybook.github.io/118080312240551.png"></p>
<h4 id="两种事件触发模式"><a href="#两种事件触发模式" class="headerlink" title="两种事件触发模式"></a>两种事件触发模式</h4><ul>
<li>边缘触发模式(ET)，当被监控的 Socket 描述符上有可读事件发⽣时，<mark>服务器端只会从epoll_wait 中苏醒⼀次</mark>，即使进程没有调⽤ read 函数从内核读取数据，也依然只苏醒⼀次，因此我们程序要保证⼀次性将内核缓冲区的数据读取完；</li>
<li>⽔平触发模式(LT)，当被监控的 Socket 上有可读事件发⽣时，<mark>服务器端不断地从epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束</mark>，⽬的是告诉我们有数据需要读取；</li>
</ul>
<p>如果使⽤边缘触发模式，在收到通知后应尽可能地读写数据，以免错失读写的机会。如果是阻塞的，没有数据可读写时，进程会<mark>阻塞</mark>在读写函数那⾥，程序就没办法继续往下执⾏。<mark>所以，边缘触发模式⼀般和⾮阻塞 I&#x2F;O 搭配使⽤，</mark>程序会⼀直执⾏ I&#x2F;O 操作，直到系统调⽤（如 read 和 write ）返回错误，错误类型为EAGAIN 或 EWOULDBLOCK 。</p>
<p>⼀般来说，边缘触发的效率⽐⽔平触发的效率要⾼,因为边缘触发可以减少 epoll_wait 的系统调⽤次数，系统调⽤也是有⼀定的开销的的，毕竟也存在上下⽂的切换。</p>
<h4 id="ET和LT模式各自应用场景是什么？为什么有了高效的ET还需要LT？"><a href="#ET和LT模式各自应用场景是什么？为什么有了高效的ET还需要LT？" class="headerlink" title="ET和LT模式各自应用场景是什么？为什么有了高效的ET还需要LT？"></a>ET和LT模式各自应用场景是什么？为什么有了高效的ET还需要LT？</h4><ol>
<li>LT的编程更符合用户直觉，业务层逻辑更简单，不易出错，但效率较低；</li>
<li>ET的编程可以做到更加简洁，某些场景下更加高效，但另一方面容易遗漏事件，容易产生bug；</li>
<li>对于nginx这种高性能服务器，ET模式是很好的，Redis使用的是LT，避免使用的过程中出现bug；</li>
<li>当并发量比较小时，比较推荐LT，因为LT模式下应用的读写逻辑比较简单，不容易遗漏事件，代码不易出错好维护，而且性能损失不大。当并发量非常大时，推荐使用ET模式，可以有效提升EPOLL效率。</li>
</ol>
<h1 id="操作系统其它知识"><a href="#操作系统其它知识" class="headerlink" title="操作系统其它知识"></a>操作系统其它知识</h1><h2 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h2><ol>
<li>什么是shell？</li>
</ol>
<ul>
<li>shell是linux的一个外壳，它包在linux内核的外面，为用户和内核之间的交互提供了一个接口。</li>
<li>当用户下达指令给该操作系统的时候，实际上是把指令告诉shell，经过shell解释，处理后让内核做出相应的动作。</li>
<li>系统的回应和输出的信息也由shell处理，然后显示在用户的屏幕上</li>
</ul>
<ol start="2">
<li>为什么使用shell脚本？</li>
</ol>
<ul>
<li>适合处理操作系统底层的业务，有众多系统命令为其做支撑（还有文本处理三兄弟：grep，sed，awk）</li>
<li>适合处理纯文本文件，linux中许多服务配置文件，启动脚本，都是纯文本文件（如：httpd，nfs，mysql，nginx，lvs）</li>
<li>linux系统脚本用shell开发更简单，简言之，shell脚本操作更加方便，快捷，高效。</li>
</ul>
<ol start="3">
<li>shell脚本与编程语言的区别？</li>
</ol>
<ul>
<li>shell脚本是能运行的文本，它包含命令和运行逻辑关系 。与C语言、C++、C#等编程语言不同。</li>
<li>shell脚本不需要编译、连接及生成可执行文件，直接由相应的解释器（最常用的解释器为bash） 解释执行即可。</li>
<li>它的优点是可批量，多次执行（使用）。简言之，shell脚本是解释性语言，而c语言则是编译性语言。</li>
</ul>
<h2 id="句柄（windows）"><a href="#句柄（windows）" class="headerlink" title="句柄（windows）"></a>句柄（windows）</h2><p><img data-src="/mybook.github.io/2535111169068.png">       <img data-src="/mybook.github.io/3580711156935.png"></p>
<p>Windows是一个以虚拟内存为基础的操作系统，进程的代码和数据并不全部装入内存，进程的某一段装入内存后，还可能被换出到外存，当再次需要时，再装入内存。两次装入的地址绝大多数情况下是不一样的。</p>
<p>系统为每个进程在内存中分配一定的区域，用来存放各个句柄，即一个个无符号整型。每个无符号整型值相当于一个指针，指向内存中的另一个区域A。而区域A中存放的正是对象在内存中的地址。<mark>当对象在内存中的位置发生变化时，区域A的值被更新，变为当前时刻对象在内存中的地址，而在这个过程中，区域A的位置以及对应句柄的值是不发生变化的。</mark></p>
<ol>
<li>所谓“唯一”、“不变”是指在程序的一次运行中。如果本次运行完，关闭程序，再次启动程序运行，那么这次运行中，同一对象的句柄的值和上次运行时比较，一般是不一样的。</li>
<li>句柄是对象生成时系统指定的，属性是只读的，程序员不能修改句柄。</li>
<li>不同的系统中，句柄的大小（字节数）是不同的，可以使用sizeof()来计算句柄的大小。</li>
<li>通过句柄，程序员只能调用系统提供的服务（即API调用），不能像使用指针那样，做其它的事。</li>
</ol>
<h2 id="Linux网络传输"><a href="#Linux网络传输" class="headerlink" title="Linux网络传输"></a>Linux网络传输</h2><h3 id="Linux-接收⽹络包的流程"><a href="#Linux-接收⽹络包的流程" class="headerlink" title="Linux 接收⽹络包的流程"></a>Linux 接收⽹络包的流程</h3><ul>
<li>⽹卡是计算机⾥的⼀个硬件，专⻔负责接收和发送⽹络包，当⽹卡接收到⼀个⽹络包后，会通过 DMA 技术，将⽹络包放⼊到 Ring Buffer，这个是⼀个环形缓冲区。</li>
<li>Linux 内核在 2.6 版本中引⼊了 NAPI 机制，它是混合「中断和轮询」的⽅式来接收⽹络包，它的核⼼概念就是<mark>不采⽤中断的⽅式读取数据</mark>，⽽是⾸先<mark>采⽤中断唤醒数据接收的服务程序</mark>，然后 poll 的⽅法来轮询数据</li>
<li>⽐如，当有⽹络包到达时，⽹卡发起硬件中断，于是会执⾏⽹卡硬件中断处理函数，中断处理函数处理完需要「暂时屏蔽中断」，然后唤醒「软中断」来轮询处理数据，直到没有新数据时才恢复中断，这样⼀次中断处理多个⽹络包，于是就可以降低⽹卡中断带来的性能开销。</li>
</ul>
<h3 id="高性能网络模式：Reactor-和-Proactor"><a href="#高性能网络模式：Reactor-和-Proactor" class="headerlink" title="高性能网络模式：Reactor 和 Proactor"></a>高性能网络模式：Reactor 和 Proactor</h3><p><strong>1. 单 Reactor 单进程 &#x2F; 线程</strong></p>
<ul>
<li>Reactor 对象通过 select （IO 多路复⽤接⼝） 监听事件，收到事件后通过 dispatch 进⾏分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li>
<li>如果是连接建⽴的事件，则交由 Acceptor 对象进⾏处理，Acceptor 对象会通过 accept⽅法 获取连接，并创建⼀个 Handler 对象来处理后续的响应事件；</li>
<li>如果不是连接建⽴事件， 则交由当前连接对应的 Handler 对象来进⾏响应；Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li>
</ul>
<p><strong>2. 单 Reactor 多线程 &#x2F; 多进程</strong></p>
<ul>
<li>Reactor 对象通过 select （IO 多路复⽤接⼝） 监听事件，收到事件后通过 dispatch 进⾏分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li>
<li>如果是连接建⽴的事件，则交由 Acceptor 对象进⾏处理，Acceptor 对象会通过 accept⽅法 获取连接，并创建⼀个 Handler 对象来处理后续的响应事件；</li>
<li>如果不是连接建⽴事件， 则交由当前连接对应的 Handler 对象来进⾏响应；</li>
<li>Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给⼦线程⾥的 Processor 对象进⾏业务处理；</li>
<li>⼦线程⾥的 Processor 对象就进⾏业务处理，处理完后，将结果发给主线程中的 Handler对象，接着由 Handler 通过 send ⽅法将响应结果发送给 client；</li>
</ul>
<p>「单 Reactor」的模式还有个问题，因为⼀个 Reactor 对象承担所有事件的监听和响应，⽽且只在主线程中运⾏，在⾯对瞬间⾼并发的场景时，容易成为性能的瓶颈的地⽅。</p>
<p><strong>3. 多 Reactor 多进程 &#x2F; 线程</strong></p>
<ul>
<li>主线程中的 MainReactor 对象通过 select 监控连接建⽴事件，收到事件后通过 Acceptor对象中的 accept 获取连接，将新的连接分配给某个⼦线程；</li>
<li>⼦线程中的 SubReactor 对象将 MainReactor 对象分配的连接加⼊ select 继续进⾏监听，并创建⼀个 Handler ⽤于处理连接的响应事件。</li>
<li>如果有新的事件发⽣时，SubReactor 对象会调⽤当前连接对应的 Handler 对象来进⾏响应。</li>
<li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li>
</ul>
<p>主线程和⼦线程分⼯明确，主线程只负责接收新连接，⼦线程负责完成后续的业务处理。<br>主线程和⼦线程的交互很简单，主线程只需要把新连接传给⼦线程，⼦线程⽆须返回数据，直接就可以在⼦线程将处理结果发送给客户端。</p>
<ul>
<li>Reactor 是⾮阻塞同步网络模式，感知的是就绪可读写事件。在每次感知到有事件发⽣（⽐如可读就绪事件）后，就需要应⽤进程主动调⽤ read ⽅法来完成数据的读取，也就是要应⽤进程主动将 socket 接收缓存中的数据读到应⽤进程内存中，这个过程是同步的，读取完数据后应⽤进程才能处理数据。</li>
<li>Proactor 是异步⽹络模式， 感知的是已完成的读写事件。在发起异步读写请求时，需要传⼊数据缓冲区的地址（⽤来存放结果数据）等信息，这样系统内核才可以⾃动帮我们把数据的读写⼯作完成，这⾥的读写⼯作全程由操作系统来做，并不需要像 Reactor 那样还需要应⽤进程主动发起 read&#x2F;write 来读写数据，操作系统完成读写⼯作后，就会通知应⽤进程直接处理数据。</li>
</ul>
<h2 id="一致性哈希"><a href="#一致性哈希" class="headerlink" title="一致性哈希"></a>一致性哈希</h2><p>一致性哈希算法就很好地解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。</p>
<p>一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对 2^32 进行取模运算，是一个固定的值。</p>
<p>我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，就像钟表一样，钟表的圆可以理解成由 60 个点组成的圆，而此处我们把这个圆想象成由 2^32 个点组成的圆，这个圆环被称为哈希环，如下图：</p>
<p><img data-src="/mybook.github.io/84610117267373.png"></p>
<p>一致性哈希要进行两步哈希：</p>
<p>第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；<br>第二步：当对数据进行存储或访问时，对数据进行哈希映射；<br>所以，一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上。</p>
<h2 id="Linux内核体系结构"><a href="#Linux内核体系结构" class="headerlink" title="Linux内核体系结构"></a>Linux内核体系结构</h2><p>系统调用接口、进程管理、内存管理、虚拟文件系统、网络堆栈、设备驱动程序、硬件架构的相关代码。</p>
<h3 id="系统调用接口"><a href="#系统调用接口" class="headerlink" title="系统调用接口"></a>系统调用接口</h3><p>SCI 层提供了某些机制执行从用户空间到内核的函数调用。正如前面讨论的一样，这个接口依赖于体系结构，甚至在相同的处理器家族内也是如此。SCI 实际上是一个非常有用的函数调用多路复用和多路分解服务。在 .&#x2F;linux&#x2F;kernel 中您可以找到 SCI 的实现，并在 .&#x2F;linux&#x2F;arch 中找到依赖于体系结构的部分。</p>
<h3 id="进程管理"><a href="#进程管理" class="headerlink" title="进程管理"></a>进程管理</h3><p>进程管理的重点是进程的执行。在内核中，这些进程称为线程，代表了单独的处理器虚拟化（线程代码、数据、堆栈和 CPU 寄存器）。在用户空间，通常使用进程 这个术语，不过 Linux 实现并没有区分这两个概念（进程和线程）。内核通过 SCI 提供了一个应用程序编程接口（API）来创建一个新进程（fork、exec 或 Portable Operating System Interface [POSIX] 函数），停止进程（kill、exit），并在它们之间进行通信和同步（signal 或者 POSIX 机制）。</p>
<p>进程管理还包括处理活动进程之间共享 CPU 的需求。内核实现了一种新型的调度算法，不管有多少个线程在竞争 CPU，这种算法都可以在固定时间内进行操作。这种算法就称为 O(1) 调度程序，这个名字就表示它调度多个线程所使用的时间和调度一个线程所使用的时间是相同的。O(1) 调度程序也可以支持多处理器（称为对称多处理器或 SMP）。您可以在 .&#x2F;linux&#x2F;kernel 中找到进程管理的源代码，在 .&#x2F;linux&#x2F;arch 中可以找到依赖于体系结构的源代码。</p>
<h3 id="内存管理-1"><a href="#内存管理-1" class="headerlink" title="内存管理"></a>内存管理</h3><p>内核所管理的另外一个重要资源是内存。为了提高效率，如果由硬件管理虚拟内存，内存是按照所谓的内存页 方式进行管理的（对于大部分体系结构来说都是 4KB）。Linux 包括了管理可用内存的方式，以及物理和虚拟映射所使用的硬件机制。不过内存管理要管理的可不止 4KB 缓冲区。Linux 提供了对 4KB 缓冲区的抽象，例如 slab 分配器。这种内存管理模式使用 4KB 缓冲区为基数，然后从中分配结构，并跟踪内存页使用情况，比如哪些内存页是满的，哪些页面没有完全使用，哪些页面为空。这样就允许该模式根据系统需要来动态调整内存使用。为了支持多个用户使用内存，有时会出现可用内存被消耗光的情况。由于这个原因，页面可以移出内存并放入磁盘中。这个过程称为交换，因为页面会被从内存交换到硬盘上。内存管理的源代码可以在 .&#x2F;linux&#x2F;mm 中找到。</p>
<h3 id="虚拟文件系统"><a href="#虚拟文件系统" class="headerlink" title="虚拟文件系统"></a>虚拟文件系统</h3><p>虚拟文件系统（VFS）是 Linux 内核中非常有用的一个方面，因为它为文件系统提供了一个通用的接口抽象。VFS 在 SCI 和内核所支持的文件系统之间提供了一个交换层（请参看图4）。</p>
<h2 id="Linux文件系统层次结构"><a href="#Linux文件系统层次结构" class="headerlink" title="Linux文件系统层次结构"></a>Linux文件系统层次结构</h2><p>在 VFS 上面，是对诸如 open、close、read 和 write 之类的函数的一个通用 API 抽象。在 VFS 下面是文件系统抽象，它定义了上层函数的实现方式。它们是给定文件系统（超过 50 个）的插件。文件系统的源代码可以在 .&#x2F;linux&#x2F;fs 中找到。文件系统层之下是缓冲区缓存，它为文件系统层提供了一个通用函数集（与具体文件系统无关）。这个缓存层通过将数据保留一段时间（或者随即预先读取数据以便在需要是就可用）优化了对物理设备的访问。缓冲区缓存之下是设备驱动程序，它实现了特定物理设备的接口。</p>
<h3 id="网络堆栈"><a href="#网络堆栈" class="headerlink" title="网络堆栈"></a>网络堆栈</h3><p>网络堆栈在设计上遵循模拟协议本身的分层体系结构。回想一下，Internet Protocol (IP) 是传输协议（通常称为传输控制协议或 TCP）下面的核心网络层协议。TCP 上面是 socket 层，它是通过 SCI 进行调用的。socket 层是网络子系统的标准 API，它为各种网络协议提供了一个用户接口。从原始帧访问到 IP 协议数据单元（PDU），再到 TCP 和 User Datagram Protocol (UDP)，socket 层提供了一种标准化的方法来管理连接，并在各个终点之间移动数据。内核中网络源代码可以在 .&#x2F;linux&#x2F;net 中找到。</p>
<h3 id="设备驱动程序"><a href="#设备驱动程序" class="headerlink" title="设备驱动程序"></a>设备驱动程序</h3><p>Linux 内核中有大量代码都在设备驱动程序中，它们能够运转特定的硬件设备。Linux 源码树提供了一个驱动程序子目录，这个目录又进一步划分为各种支持设备，例如 Bluetooth、I2C、serial 等。设备驱动程序的代码可以在 .&#x2F;linux&#x2F;drivers 中找到。</p>
<h3 id="依赖体系结构的代码"><a href="#依赖体系结构的代码" class="headerlink" title="依赖体系结构的代码"></a>依赖体系结构的代码</h3><p>尽管 Linux 很大程度上独立于所运行的体系结构，但是有些元素则必须考虑体系结构才能正常操作并实现更高效率。.&#x2F;linux&#x2F;arch 子目录定义了内核源代码中依赖于体系结构的部分，其中包含了各种特定于体系结构的子目录（共同组成了 BSP）。对于一个典型的桌面系统来说，使用的是 x86 目录。每个体系结构子目录都包含了很多其他子目录，每个子目录都关注内核中的一个特定方面，例如引导、内核、内存管理等。这些依赖体系结构的代码可以在 .&#x2F;linux&#x2F;arch 中找到。</p>
<p>如果 Linux 内核的可移植性和效率还不够好，Linux 还提供了其他一些特性，它们无法划分到上面的分类中。作为一个生产操作系统和开源软件，Linux 是测试新协议及其增强的良好平台。Linux 支持大量网络协议，包括典型的 TCP&#x2F;IP，以及高速网络的扩展（大于 1 Gigabit Ethernet [GbE] 和 10 GbE）。Linux 也可以支持诸如流控制传输协议（SCTP）之类的协议，它提供了很多比 TCP 更高级的特性（是传输层协议的接替者）。</p>
<p>Linux 还是一个动态内核，支持动态添加或删除软件组件。被称为动态可加载内核模块，它们可以在引导时根据需要（当前特定设备需要这个模块）或在任何时候由用户插入。</p>
<p>Linux 最新的一个增强是可以用作其他操作系统的操作系统（称为系统管理程序）。最近，对内核进行了修改，称为基于内核的虚拟机（KVM）。这个修改为用户空间启用了一个新的接口，它可以允许其他操作系统在启用了 KVM 的内核之上运行。除了运行 Linux 的其他实例之外， Microsoft Windows也可以进行虚拟化。惟一的限制是底层处理器必须支持新的虚拟化指令。</p>
<link rel="stylesheet" href="/mybook.github.io/css/spoiler.css" type="text/css"><script src="/mybook.github.io/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://silence-create.github.io/mybook.github.io/2024/05/17/Redis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/mybook.github.io/images/avatar.gif">
      <meta itemprop="name" content="徐川">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="依只若只的博客">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/mybook.github.io/2024/05/17/Redis/" class="post-title-link" itemprop="url">Redis</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-05-17 15:44:23" itemprop="dateCreated datePublished" datetime="2024-05-17T15:44:23+08:00">2024-05-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2024-05-20 11:39:47" itemprop="dateModified" datetime="2024-05-20T11:39:47+08:00">2024-05-20</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Redis数据结构"><a href="#Redis数据结构" class="headerlink" title="Redis数据结构"></a>Redis数据结构</h1><p>常见的有五种：String（字符串），Hash（哈希），List（列表），Set（集合）、Zset（有序集合）。</p>
<p>随着 Redis 版本的更新，后面又支持了四种数据类型： BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、GEO（3.2 版新增）、Stream（5.0 版新增）。</p>
<h2 id="String类型"><a href="#String类型" class="headerlink" title="String类型"></a>String类型</h2><p>是redis中最基本的数据类型，一个key对应一个value。</p>
<ul>
<li>String类型是二进制安全的，底层的数据结构实现主要是 int 和 SDS（简单动态字符串）。</li>
<li>SDS 不仅可以保存文本数据，还可以保存二进制数据， SDS 的所有 API 都会以处理二进制的方式处理存放在 buf[] 数组里的数据。所以 SDS 不光能存放文本数据，而且能保存图片、音频、视频、压缩文件这样的二进制数据。</li>
<li>C 语言的字符串并不记录自身长度，所以获取长度的复杂度为 O(n)；而 SDS 结构里用 len 属性记录了字符串长度，所以复杂度为 O(1)。</li>
<li>Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出。因为 SDS 在拼接字符串之前会检查 SDS 空间是否满足要求，如果空间不够会自动扩容，所以不会导致缓冲区溢出的问题。</li>
</ul>
<p><img data-src="/mybook.github.io/542052117263693.png"></p>
<ul>
<li>如果一个字符串对象保存的是整数值，并且这个整数值可以用long类型来表示，那么字符串对象会将整数值保存在字符串对象结构的ptr属性里面（将void*转换成 long），并将字符串对象的编码设置为int</li>
<li>如果字符串对象保存的是一个字符串，并且这个字符申的长度小于等于 32 字节（redis 2.+版本），那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串，并将对象的编码设置为embstr， embstr编码是专门用于保存短字符串的一种优化编码方式</li>
<li>如果字符串对象保存的是一个字符串，并且这个字符串的长度大于 32 字节（redis 2.+版本），那么字符串对象将使用一个简单动态字符串（SDS）来保存这个字符串，并将对象的编码设置为raw</li>
</ul>
<p><strong>embstr优点：</strong><br>embstr会通过一次内存分配函数来分配一块连续的内存空间来保存redisObject和SDS，raw编码会通过调用两次内存分配函数来分别分配两块空间来保存redisObject和SDS<br>因为embstr编码的字符串对象的所有数据都保存在一块连续的内存里面可以更好的利用 CPU 缓存提升性能。</p>
<p><strong>embstr缺点：</strong></p>
<p>embstr编码的字符串对象实际上是只读的，redis没有为embstr编码的字符串对象编写任何相应的修改程序。当我们对embstr编码的字符串对象执行任何修改命令（例如append）时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令。<br>如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; <span class="built_in">set</span> hello world</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get hello</span><br><span class="line"><span class="string">&quot;world&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>使用场景:</strong></p>
<ul>
<li>缓存对象</li>
<li>常规计数</li>
<li>分布式锁</li>
</ul>
<h2 id="List"><a href="#List" class="headerlink" title="List"></a>List</h2><p>双向链表或压缩列表<br>如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用压缩列表作为 List 类型的底层数据结构；</p>
<p>“使用列表的技巧:”<br>lpush+lpop&#x3D;Stack(栈)<br>lpush+rpop&#x3D;Queue（队列）<br>lpush+ltrim&#x3D;Capped Collection（有限集合）<br>lpush+brpop&#x3D;Message Queue（消息队列）</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; lpush mylist 1 2 ll <span class="built_in">ls</span> mem</span><br><span class="line">(<span class="built_in">integer</span>) 5</span><br><span class="line">127.0.0.1:6379&gt; lrange mylist 0 -1</span><br><span class="line">1) <span class="string">&quot;mem&quot;</span></span><br><span class="line">2) <span class="string">&quot;ls&quot;</span></span><br><span class="line">3) <span class="string">&quot;ll&quot;</span></span><br><span class="line">4) <span class="string">&quot;2&quot;</span></span><br><span class="line">5) <span class="string">&quot;1&quot;</span></span><br><span class="line">127.0.0.1:6379&gt;</span><br></pre></td></tr></table></figure>

<p><strong>应用场景：</strong><br>消息队列<br>消息保序：使用 LPUSH + RPOP；<br>阻塞读取：使用 BRPOP；<br>重复消息处理：生产者自行实现全局唯一 ID；<br>消息的可靠性：使用 BRPOPLPUSH</p>
<h2 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h2><p>是一个Mapmap，指值本身又是一种键值对结构</p>
<p><img data-src="/mybook.github.io/313723511267020.png"></p>
<p>内部实现<br>Hash 类型的底层数据结构是由<strong>压缩列表或哈希表</strong>实现的：</p>
<ul>
<li>如果哈希类型元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），所有值小于 64 字节（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用压缩列表作为 Hash 类型的底层数据结构；</li>
<li>如果哈希类型元素不满足上面条件，Redis 会使用哈希表作为 Hash 类型的 底层数据结构。</li>
</ul>
<p>在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了。</p>
<p>使用：所有hash的命令都是  h   开头的     hget  、hset 、  hdel 等</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; hset user name1 hao</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; hset user email1 hao@163.com</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br><span class="line">127.0.0.1:6379&gt; hgetall user</span><br><span class="line">1) <span class="string">&quot;name1&quot;</span></span><br><span class="line">2) <span class="string">&quot;hao&quot;</span></span><br><span class="line">3) <span class="string">&quot;email1&quot;</span></span><br><span class="line">4) <span class="string">&quot;hao@163.com&quot;</span></span><br></pre></td></tr></table></figure>

<p><strong>应用场景</strong></p>
<ul>
<li>缓存对象</li>
<li>购物车</li>
</ul>
<h2 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h2><p>Set 类型的底层数据结构是由<strong>哈希表</strong>或<strong>整数集合</strong>实现的：</p>
<p>使用：命令都是以s开头的  sset 、srem、scard、smembers、sismember</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sadd myset hao hao1 xiaohao hao</span><br><span class="line">(<span class="built_in">integer</span>) 3</span><br><span class="line">127.0.0.1:6379&gt; SMEMBERS myset</span><br><span class="line">1) <span class="string">&quot;xiaohao&quot;</span></span><br><span class="line">2) <span class="string">&quot;hao1&quot;</span></span><br><span class="line">3) <span class="string">&quot;hao&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; SISMEMBER myset hao</span><br><span class="line">(<span class="built_in">integer</span>) 1</span><br></pre></td></tr></table></figure>


<p>如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用整数集合作为 Set 类型的底层数据结构；<br>如果集合中的元素不满足上面条件，则 Redis 使用哈希表作为 Set 类型的底层数据结构。</p>
<p><img data-src="/mybook.github.io/208841010257242.png"></p>
<p>Set 类型和 List 类型的区别如下：</p>
<p>List 可以存储重复元素，Set 只能存储非重复元素；<br>List 是按照元素的先后顺序存储元素的，而 Set 则是无序方式存储元素的。<br>集合中的元素是无序的，不能通过索引下标获取元素</p>
<p><strong>Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞</strong></p>
<p>应用场景：<br>点赞<br>共同关注<br>抽奖活动</p>
<h2 id="ZSet"><a href="#ZSet" class="headerlink" title="ZSet"></a>ZSet</h2><p>有序集合和集合有着必然的联系，保留了集合不能有重复成员的特性，区别是，有序集合中的元素是可以排序的，它给每个元素设置一个分数，作为排序的依据。<br><img data-src="/mybook.github.io/432203811259689.png"><br>使用： 有序集合的命令都是 以  z  开头    zadd 、 zrange、 zscore</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; zadd myscoreset 100 hao 90 xiaohao</span><br><span class="line">(<span class="built_in">integer</span>) 2</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE myscoreset 0 -1</span><br><span class="line">1) <span class="string">&quot;xiaohao&quot;</span></span><br><span class="line">2) <span class="string">&quot;hao&quot;</span></span><br><span class="line">127.0.0.1:6379&gt; ZSCORE myscoreset hao</span><br><span class="line"><span class="string">&quot;100&quot;</span></span><br></pre></td></tr></table></figure>



<h2 id="BitMap"><a href="#BitMap" class="headerlink" title="BitMap"></a>BitMap</h2><p>Bitmap，即位图，是一串连续的二进制数组（0和1），可以通过偏移量（offset）定位元素。BitMap通过最小的单位bit来进行0|1的设置，表示某个元素的值或者状态，时间复杂度为O(1)。</p>
<p>由于 bit 是计算机中最小的单位，使用它进行储存将非常节省空间，特别<strong>适合一些数据量大且使用二值统计的场景。</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">设置值，其中value只能是 0 和 1</span></span><br><span class="line">SETBIT key offset value</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">获取值</span></span><br><span class="line">GETBIT key offset</span><br></pre></td></tr></table></figure>


<p>内部实现:<br>Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。<br>String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态，你可以把 Bitmap 看作是一个 bit 数组</p>
<p><strong>应用场景</strong><br>签到统计<br>判断用户登陆态<br>连续签到用户总数</p>
<h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><p>HyperLogLog 提供不精确的去重计数, 是统计规则是基于概率完成的，不是非常准确，标准误算率是 0.81%。<br>HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的内存空间总是固定的、并且是很小的。<br>每个 HyperLogLog 键<strong>只需要花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数</strong>，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间:<br><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/HyperLogLog">HyperLogLog数学原理</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">添加指定元素到 HyperLogLog 中</span></span><br><span class="line">PFADD key element [element ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回给定 HyperLogLog 的基数估算值。</span></span><br><span class="line">PFCOUNT key [key ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">将多个 HyperLogLog 合并为一个 HyperLogLog</span></span><br><span class="line">PFMERGE destkey sourcekey [sourcekey ...]</span><br></pre></td></tr></table></figure>
<p><strong>应用场景</strong><br>百万级网页 UV 计数</p>
<h2 id="GEO"><a href="#GEO" class="headerlink" title="GEO"></a>GEO</h2><p><strong>内部实现</strong><br>GEO 本身并没有设计新的底层数据结构，而是直接使用了 Sorted Set 集合类型。</p>
<p>GEO 类型使用 GeoHash 编码方法实现了经纬度到 Sorted Set 中元素权重分数的转换，这其中的两个关键机制就是「对二维地图做区间划分」和「对区间进行编码」。一组经纬度落在某个区间后，就用区间的编码值来表示，并把编码值作为 Sorted Set 元素的权重分数。</p>
<p>这样一来，我们就可以把经纬度保存到 Sorted Set 中，利用 Sorted Set 提供的“按权重进行有序范围查找”的特性，实现 LBS 服务中频繁使用的“搜索附近”的需求。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。</span></span><br><span class="line">GEOADD key longitude latitude member [longitude latitude member ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。</span></span><br><span class="line">GEOPOS key member [member ...]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">返回两个给定位置之间的距离。</span></span><br><span class="line">GEODIST key member1 member2 [m|km|ft|mi]</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。</span></span><br><span class="line">GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]</span><br></pre></td></tr></table></figure>

<p><strong>应用场景</strong><br>滴滴叫车<br>这里以滴滴叫车的场景为例，介绍下具体如何使用 GEO 命令：GEOADD 和 GEORADIUS 这两个命令。</p>
<p>假设车辆 ID 是 33，经纬度位置是（116.034579，39.030452），我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。</p>
<p>执行下面的这个命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">GEOADD cars:locations 116.034579 39.030452 33</span><br></pre></td></tr></table></figure>
<p>当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令。</p>
<p>例如，LBS 应用执行下面的命令时，Redis 会根据输入的用户的经纬度信息（116.054579，39.030452 ），查找以这个经纬度为中心的 5 公里内的车辆信息，并返回给 LBS 应用。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RADIUS cars:locations 116.054579 39.030452 5 km ASC COUNT 10</span><br></pre></td></tr></table></figure>

<h2 id="Stream"><a href="#Stream" class="headerlink" title="Stream"></a>Stream</h2><p>Redis Stream 是 Redis 5.0 版本新增加的数据类型，Redis 专门为消息队列设计的数据类型。它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠。</p>
<p>在 Redis 5.0 Stream 没出来之前，消息队列的实现方式都有着各自的缺陷，例如：</p>
<p>发布订阅模式，不能持久化也就无法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息的缺陷；<br>List 实现消息队列的方式不能重复消费，一个消息消费完就会被删除，而且生产者需要自行实现全局唯一 ID。</p>
<p><strong>常见命令</strong><br>Stream 消息队列操作命令：</p>
<p>XADD：插入消息，保证有序，可以自动生成全局唯一 ID；<br>XLEN ：查询消息长度；<br>XREAD：用于读取消息，可以按 ID 读取数据；<br>XDEL ： 根据消息 ID 删除消息；<br>DEL ：删除整个 Stream；<br>XRANGE ：读取区间消息<br>XREADGROUP：按消费组形式读取消息；<br>XPENDING 和 XACK：<br>XPENDING 命令可以用来查询每个消费组内所有消费者「已读取、但尚未确认」的消息；<br>XACK 命令用于向消息队列确认消息处理已完成；</p>
<p><strong>应用场景</strong></p>
<h3 id="消息队列"><a href="#消息队列" class="headerlink" title="消息队列"></a>消息队列</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">* 表示让 Redis 为插入的数据自动生成一个全局唯一的 ID</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">往名称为 mymq 的消息队列中插入一条消息，消息的键是 name，值是 xiaolin</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XADD mymq * name xiaolin</span></span><br><span class="line">&quot;1654254953808-0&quot;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">从 ID 号为 1654254953807-0 的消息开始，读取后续的所有消息（示例中一共 1 条）。</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XREAD STREAMS mymq 1654254953807-0</span></span><br><span class="line">1) 1) &quot;mymq&quot;</span><br><span class="line">   2) 1) 1) &quot;1654254953808-0&quot;</span><br><span class="line">         2) 1) &quot;name&quot;</span><br><span class="line">            2) &quot;xiaolin&quot;</span><br><span class="line">            </span><br></pre></td></tr></table></figure>
<p>如果想要实现阻塞读（当没有数据时，阻塞住），可以调用 XRAED 时设定 BLOCK 配置项，实现类似于 BRPOP 的阻塞读取操作。</p>
<p><img data-src="/mybook.github.io/332081109240466.png"></p>
<p>Stream 可以以使用 XGROUP 创建消费组，创建消费组之后，Stream 可以使用 XREADGROUP 命令让消费组内的消费者读取消息。</p>
<p>创建两个消费组，这两个消费组消费的消息队列是 mymq，都指定从第一条消息开始读取：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个名为 group1 的消费组，0-0 表示从第一条消息开始读取。</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XGROUP CREATE mymq group1 0-0</span></span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">创建一个名为 group2 的消费组，0-0 表示从第一条消息开始读取。</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XGROUP CREATE mymq group2 0-0</span></span><br><span class="line">OK</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>消费组 group1 内的消费者 consumer1 从 mymq 消息队列中读取所有消息的命令如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">命令最后的参数“&gt;”，表示从第一条尚未被消费的消息开始读取。</span></span><br><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XREADGROUP GROUP group1 consumer1 STREAMS mymq &gt;</span></span><br><span class="line">1) 1) &quot;mymq&quot;</span><br><span class="line">   2) 1) 1) &quot;1654254953808-0&quot;</span><br><span class="line">         2) 1) &quot;name&quot;</span><br><span class="line">            2) &quot;xiaolin&quot;</span><br></pre></td></tr></table></figure>
<p>消息队列中的消息一旦被消费组里的一个消费者读取了，就不能再被该消费组内的其他消费者读取了，即同一个消费组里的消费者不能消费同一条消息。</p>
<p>比如说，我们执行完刚才的 XREADGROUP 命令后，再执行一次同样的命令，此时读到的就是空值了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; XREADGROUP GROUP group1 consumer1 STREAMS mymq &gt;</span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure>

<p>但是，不同消费组的消费者可以消费同一条消息（但是有前提条件，创建消息组的时候，不同消费组指定了相同位置开始读取消息）。<br>比如说，刚才 group1 消费组里的 consumer1 消费者消费了一条 id 为 1654254953808-0 的消息，现在用 group2 消费组里的 consumer1 消费者消费消息：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XREADGROUP GROUP group2 consumer1 STREAMS mymq &gt;</span></span><br><span class="line">1) 1) &quot;mymq&quot;</span><br><span class="line">   2) 1) 1) &quot;1654254953808-0&quot;</span><br><span class="line">         2) 1) &quot;name&quot;</span><br><span class="line">            2) &quot;xiaolin&quot;</span><br></pre></td></tr></table></figure>
<p>因为我创建两组的消费组都是从第一条消息开始读取，所以可以看到第二组的消费者依然可以消费 id 为 1654254953808-0 的这一条消息。因此，不同的消费组的消费者可以消费同一条消息。</p>
<h3 id="基于-Stream-实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？"><a href="#基于-Stream-实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？" class="headerlink" title="基于 Stream 实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？"></a>基于 Stream 实现的消息队列，如何保证消费者在发生故障或宕机再次重启后，仍然可以读取未处理完的消息？</h3><p>Streams 会自动使用内部队列（也称为 PENDING List）留存消费组里每个消费者读取的消息，直到消费者使用 XACK 命令通知 Streams“消息已经处理完成”。</p>
<p>消费确认增加了消息的可靠性，一般在业务处理完成之后，需要执行 XACK 命令确认消息已经被消费完成，整个流程的执行如下图所示：</p>
<p><img data-src="/mybook.github.io/5962009258892.png"></p>
<p>如果消费者没有成功处理消息，它就不会给 Streams 发送 XACK 命令，消息仍然会留存。此时，消费者可以在重启后，用 XPENDING 命令查看已读取、但尚未确认处理完成的消息。</p>
<p>一旦消息 1654256265584-0 被 consumer2 处理了，consumer2 就可以使用 XACK 命令通知 Streams，然后这条消息就会被删除。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XACK mymq group2 1654256265584-0</span></span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure>

<p>当我们再使用 XPENDING 命令查看时，就可以看到，consumer2 已经没有已读取、但尚未确认处理的消息了。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">&gt; </span><span class="language-bash">XPENDING mymq group2 - + 10 consumer2</span></span><br><span class="line">(empty array)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>总结：</p>
<ul>
<li>消息保序：XADD&#x2F;XREAD</li>
<li>阻塞读取：XREAD block</li>
<li>重复消息处理：Stream 在使用 XADD 命令，会自动生成全局唯一 ID；</li>
<li>消息可靠性：内部使用 PENDING List 自动保存消息，使用 XPENDING 命令查看消费组已经读取但是未被确认的消息，消费者使用 XACK 确认消息；</li>
<li>支持消费组形式消费数据</li>
</ul>
<h3 id="Redis-基于-Stream-消息队列与专业的消息队列有哪些差距？"><a href="#Redis-基于-Stream-消息队列与专业的消息队列有哪些差距？" class="headerlink" title="Redis 基于 Stream 消息队列与专业的消息队列有哪些差距？"></a>Redis 基于 Stream 消息队列与专业的消息队列有哪些差距？</h3><ul>
<li>消息不丢?</li>
</ul>
<p>生产者会不会丢消息，消费者不会丢消息,,Redis 消息中间件会丢消息, Redis 在以下 2 个场景下，都会导致数据丢失：</p>
<ol>
<li>AOF 持久化配置为每秒写盘，但这个写盘过程是异步的，Redis 宕机时会存在数据丢失的可能</li>
<li>主从复制也是异步的，主从切换时，也存在丢失数据的可能 。</li>
</ol>
<ul>
<li>消息可堆积?<br>Redis 的数据都存储在内存中，这就意味着一旦发生消息积压，则会导致 Redis 的内存持续增长，如果超过机器内存上限，就会面临被 OOM 的风险。但 Kafka、RabbitMQ 专业的消息队列它们的数据都是存储在磁盘上</li>
</ul>
<p><strong>关键看业务场景：</strong><br><strong>如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。</strong><br><strong>如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。</strong></p>
<h3 id="Redis-发布-订阅机制为什么不可以作为消息队列？"><a href="#Redis-发布-订阅机制为什么不可以作为消息队列？" class="headerlink" title="Redis 发布&#x2F;订阅机制为什么不可以作为消息队列？"></a>Redis 发布&#x2F;订阅机制为什么不可以作为消息队列？</h3><ol>
<li>发布&#x2F;订阅机制没有基于任何数据类型实现，所以不具备「数据持久化」的能力，也就是发布&#x2F;订阅机制的相关操作，不会写入到 RDB 和 AOF 中，当 Redis 宕机重启，发布&#x2F;订阅机制的数据也会全部丢失。</li>
<li>发布订阅模式是“发后既忘”的工作模式，如果有订阅者离线重连之后不能消费之前的历史消息。</li>
<li>当消费端有一定的消息积压时，也就是生产者发送的消息，消费者消费不过来时，如果超过 32M 或者是 60s 内持续保持在 8M 以上，消费端会被强行断开，这个参数是在配置文件中设置的，默认值是<code>client-output-buffer-limit pubsub 32mb 8mb 60</code></li>
</ol>
<p>数据结构实现</p>
<p><img data-src="/mybook.github.io/161783909246759.png"></p>
<ul>
<li>redisDb 结构，表示 Redis 数据库的结构，结构体里存放了指向了 dict 结构的指针；</li>
<li>dict 结构，结构体里存放了 2 个哈希表，正常情况下都是用「哈希表1」，「哈希表2」只有在 rehash 的时候才用，具体什么是 rehash，我在本文的哈希表数据结构会讲；</li>
<li>ditctht 结构，表示哈希表的结构，结构里存放了哈希表数组，数组中的每个元素都是指向一个哈希表节点结构（dictEntry）的指针；</li>
<li>dictEntry 结构，表示哈希表节点的结构，结构里存放了 **void * key 和 void * value 指针， key 指向的是 String 对象，而 value 则可以指向 String 对象，也可以指向集合类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。</li>
</ul>
<p><img data-src="/mybook.github.io/539934514259594.png"></p>
<h1 id="Redis持久化"><a href="#Redis持久化" class="headerlink" title="Redis持久化"></a>Redis持久化</h1><h2 id="RDB快照"><a href="#RDB快照" class="headerlink" title="RDB快照"></a>RDB快照</h2><p>RDB 快照就是记录某一个瞬间的内存数据，记录的是实际数据，并写入.rdb格式的二进制文件保存在磁盘，这样如果服务器崩溃内存内数据丢失，重新连接后redis会自动读取默认名称为dump.rdb（可以在redis.conf内修改为其他名称）的rdb备份文件，恢复其上次备份时redis存在的所有数据。</p>
<ul>
<li>save命令：会在主线程生成 RDB 文件，阻塞当前Redis，直到RDB持久化过程完成为止，若内存实例比较大会造成长时间阻塞，线上环境不建议用它</li>
<li>bgsave命令：redis进程执行fork操作创建子线程，由子线程完成持久化，阻塞时间很短（微秒级），是save的优化, 在执行redis-cli shutdown关闭redis服务时，如果没有开启AOF持久化，自动执行bgsave;</li>
</ul>
<p>Redis 的快照是全量快照，执行的频率不能太频繁，否则会影响 Redis 性能，</p>
<h3 id="执行快照时，数据能被修改吗？"><a href="#执行快照时，数据能被修改吗？" class="headerlink" title="执行快照时，数据能被修改吗？"></a>执行快照时，数据能被修改吗？</h3><p>写时复制技术</p>
<p>如果主线程（父进程）要修改共享数据里的某一块数据（比如键值对 A）时，就会发生写时复制，于是这块数据的物理内存就会被复制一份（键值对 A’），然后主线程在这个数据副本（键值对 A’）进行修改操作。与此同时，bgsave 子进程可以继续把原来的数据（键值对 A）写入到 RDB 文件。</p>
<p>注意：<strong>发生了写时复制后，RDB 快照保存的是原本的内存数据，而主线程刚修改的数据，是没办法在这一时间写入 RDB 文件的</strong>，只能交由下一次的 bgsave 快照。</p>
<p>快照的频率不好把握：</p>
<ul>
<li>如果频率太低，两次快照间一旦服务器发生宕机，就可能会比较多的数据丢失；</li>
<li>如果频率太高，频繁写入磁盘和创建子进程会带来额外的性能开销。</li>
</ul>
<h2 id="AOF日志持久化"><a href="#AOF日志持久化" class="headerlink" title="AOF日志持久化"></a>AOF日志持久化</h2><p><img data-src="/mybook.github.io/217274914256149.png"></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">*3</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta prompt_">$</span><span class="language-bash">7</span></span><br><span class="line">xiaolin</span><br></pre></td></tr></table></figure>
<p>「*3」表示当前命令有三个部分，每部分都是以「$+数字」开头，后面紧跟着具体的命令、键或值。然后，这里的「数字」表示这部分中的命令、键或值一共有多少字节。例如，「$3 set」表示这部分有 3 个字节，也就是「set」命令这个字符串的长度。</p>
<p>先执行写操作命令后，才记录到 AOF 日志<br>好处：</p>
<ol>
<li>避免额外的检查开销。</li>
<li>不会阻塞当前写操作命令的执行</li>
</ol>
<p>坏处：</p>
<ol>
<li>服务器发生宕机，这个数据就会有丢失的风险</li>
<li>可能会给「下一个」命令带来阻塞风险</li>
</ol>
<h3 id="AOF何时写回磁盘？"><a href="#AOF何时写回磁盘？" class="headerlink" title="AOF何时写回磁盘？"></a>AOF何时写回磁盘？</h3><p>此操作在主进程中，是同步的</p>
<p><img data-src="/mybook.github.io/144465514251903.png"></p>
<p><img data-src="/mybook.github.io/523995614269783.png"></p>
<p>在 redis.conf 配置文件中的 appendfsync 配置项可以有以下 3 种参数可填：</p>
<p>Always，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；<br>Everysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；<br>No，意味着不由 Redis 控制写回硬盘的时机，<strong>转交给操作系统控制写回的时机</strong>，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。</p>
<p><img data-src="/mybook.github.io/281445814267387.png"></p>
<p>这三种策略控制的是fsync()系统调用的时机，详情参照《操作系统》</p>
<p><img data-src="/mybook.github.io/29525914264889.png"></p>
<h3 id="AOF重写机制"><a href="#AOF重写机制" class="headerlink" title="AOF重写机制"></a>AOF重写机制</h3><p>使用重写机制后，就会读取 name 最新的 value（键值对） ，然后用最新的命令值记录到新的 AOF 文件，最终也只需要根据这个「键值对」当前的最新状态，然后用一条命令去记录键值对，如果 AOF 重写过程中失败了，放弃新的AOF文件</p>
<h4 id="AOF后台重写"><a href="#AOF后台重写" class="headerlink" title="AOF后台重写"></a>AOF后台重写</h4><p>写时复制技术</p>
<p>重写 AOF 过程是由后台子进程 bgrewriteaof 来完成的<br>子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；<br>为何使用子进程？不是线程？（考虑写时复制和共享数据）</p>
<p>修改的数据量比较大的 key-value 的时候，这时写时复制的物理内存数据的过程就会比较耗时，有阻塞主进程的风险。<br>所以Redis 设置了一个 AOF 重写缓冲区，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」。</p>
<p><img data-src="/mybook.github.io/403101515246130.png"></p>
<p>在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:</p>
<ol>
<li>执行客户端发来的命令；</li>
<li>将执行后的写命令追加到 「AOF 缓冲区」；</li>
<li>将执行后的写命令追加到 「AOF 重写缓冲区」；</li>
</ol>
<p>AOF重写完成后：<br>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；（两个缓冲区的作用是一样的）<br>新的 AOF 的文件进行改名，覆盖现有的 AOF 文件</p>
<p><strong>在整个 AOF 后台重写过程中，除了发生写时复制会对主进程造成阻塞，还有信号处理函数执行时也会对主进程造成阻塞，在其他时候，AOF 后台重写都不会阻塞主进程。</strong></p>
<p>针对RDB不适合实时持久化，redis提供了AOF持久化方式来解决</p>
<p>AOF持久化采取的是日志式添加记录每次修改操作的方式，每次执行修改后，AOF持久化只需要将新执行的操作添加到appendonly.aof文件的末尾，对文件进行简单的append操作的IO消耗很小，这种文件是可读的，也就意味着可以被手动修改，拥有更强的灵活性。</p>
<p>比如Redis不小心执行了flushall指令，清空了所有数据，只要是aof没有被rewrite，只需要复制一份aof文件，去掉最后的flushall命令，再重启redis，redis会自动读取aof文件进行恢复（即从头到尾依次执行记录的操作）。</p>
<p>AOF持久化默认不开启，需要在redis.conf配置文件中将appendonly no改为appendonly yes开启。可以设置为每秒进行一次，或每次修改都进行持久化。</p>
<p>相同数据产生的AOF文件比RDB文件更大，而且开启AOF持久化对Redis主线程的性能影响也比RDB更大，但是可以更好保证数据完整性。</p>
<h2 id="双剑合璧"><a href="#双剑合璧" class="headerlink" title="双剑合璧"></a>双剑合璧</h2><p>如果想要开启混合持久化功能，可以在 Redis 配置文件将下面这个配置项设置成 yes：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aof-use-rdb-preamble yes</span><br></pre></td></tr></table></figure>

<p>混合持久化工作在 AOF 日志重写过程。</p>
<p>当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p>
<p>简单来说，如下图：其它与AOF重写一致<br>AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。</p>
<p><img data-src="/mybook.github.io/138633315268570.png"></p>
<h2 id="大key对持久化的影响"><a href="#大key对持久化的影响" class="headerlink" title="大key对持久化的影响"></a>大key对持久化的影响</h2><p>大 Key 对 AOF 日志的影响：参照 fsync() 系统调用函数<br>大 Key 对 AOF 重写的影响：考虑频繁触发重写，写时复制的性能<br>大 Key 对 RDB 快照的影响：考虑写时复制的性能</p>
<p><strong>如果 Linux 开启了内存大页，会影响 Redis 的性能的。</strong><br>常规的内存页分配是按 4KB 的粒度来执行的。内存大页机制支持 2MB 大小的内存页分配</p>
<p>禁用方法如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo never &gt;  /sys/kernel/mm/transparent_hugepage/enabled</span><br></pre></td></tr></table></figure>

<h1 id="Redis的内存策略"><a href="#Redis的内存策略" class="headerlink" title="Redis的内存策略"></a>Redis的内存策略</h1><h2 id="如何判定-key-已过期了？"><a href="#如何判定-key-已过期了？" class="headerlink" title="如何判定 key 已过期了？"></a>如何判定 key 已过期了？</h2><p>每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个过期字典（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。</p>
<p>过期字典存储在 redisDb 结构中，如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">redisDb</span> &#123;</span><br><span class="line">    dict *dict;    <span class="comment">/* 数据库键空间，存放着所有的键值对 */</span></span><br><span class="line">    dict *expires; <span class="comment">/* 键的过期时间 */</span></span><br><span class="line">    ....</span><br><span class="line">&#125; redisDb;</span><br></pre></td></tr></table></figure>

<p>过期字典数据结构结构如下：</p>
<p><img data-src="/mybook.github.io/170314415263706.png"></p>
<p>过期字典的 key 是一个指针，指向某个键对象；<br>过期字典的 value 是一个 long long 类型的整数，这个整数保存了 key 的过期时间；</p>
<h2 id="过期删除策略有哪些？"><a href="#过期删除策略有哪些？" class="headerlink" title="过期删除策略有哪些？"></a>过期删除策略有哪些？</h2><p>定时删除：在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。<strong>对内存友好，对CPU不友好</strong><br>惰性删除：不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。<strong>对CPU友好，对内存不友好</strong><br>定期删除：隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。<strong>减少对CPU影响，难以确定删除操作执行的时长和频率</strong></p>
<h2 id="Redis-过期删除策略是什么？"><a href="#Redis-过期删除策略是什么？" class="headerlink" title="Redis 过期删除策略是什么？"></a>Redis 过期删除策略是什么？</h2><p> Redis 选择「惰性删除+定期删除」这两种策略配和使用</p>
<p>惰性删除：<br>Redis 在访问或者修改 key 之前，都会调用 expireIfNeeded 函数对其进行检查，检查 key 是否过期：如果过期，则删除该 key，至于选择异步删除，还是选择同步删除，根据 lazyfree_lazy_expire 参数配置决定，然后返回 null 客户端；如果没有过期，不做任何处理，然后返回正常的键值对给客户端；<br>定期删除：<br>1、这个间隔检查的时间是多长呢？<br>在 Redis 中，默认每秒进行 10 次过期检查一次数据库<br>2、随机抽查的数量是多少呢？<br>定期删除的实现在 expire.c 文件下的 activeExpireCycle 函数中，其中随机抽查的数量由 ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP 定义的，它是写死在代码中的，数值是 20。</p>
<p> Redis 的定期删除的流程：</p>
<ol>
<li>从过期字典中随机抽取 20 个 key；</li>
<li>检查这 20 个 key 是否过期，并删除已过期的 key；</li>
<li>如果本轮检查的已过期 key 的数量，超过 5 个（20&#x2F;4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。</li>
<li>定期删除是一个循环的流程。Redis 为了保证定期删除不会出现循环过度，导致线程卡死现象，为此增加了定期删除循环流程的时间上限，默认不会超过 25ms。</li>
</ol>
<h2 id="内存淘汰策略"><a href="#内存淘汰策略" class="headerlink" title="内存淘汰策略"></a>内存淘汰策略</h2><p>1、不进行数据淘汰的策略<br>noeviction（Redis3.0之后，默认的内存淘汰策略） ：</p>
<p>2、进行数据淘汰的策略<br>针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。</p>
<p>在设置了过期时间的数据中进行淘汰：</p>
<ol>
<li>volatile-random：随机淘汰设置了过期时间的任意键值；</li>
<li>volatile-ttl：优先淘汰更早过期的键值。</li>
<li>volatile-lru（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；</li>
<li>volatile-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；</li>
</ol>
<p>在所有数据范围内进行淘汰：</p>
<ol>
<li>allkeys-random：随机淘汰任意键值;</li>
<li>allkeys-lru：淘汰整个键值中最久未使用的键值；</li>
<li>allkeys-lfu（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。</li>
</ol>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; config get maxmemory-policy</span><br><span class="line">1) &quot;maxmemory-policy&quot;</span><br><span class="line">2) &quot;noeviction&quot;</span><br></pre></td></tr></table></figure>
<h2 id="LRU和LFU"><a href="#LRU和LFU" class="headerlink" title="LRU和LFU"></a>LRU和LFU</h2><p><strong>Redis 实现的是一种近似 LRU 算法</strong>，目的是为了更好的节约内存，它的实现方式是在 Redis 的对象结构体中<strong>添加一个额外的字段，用于记录此数据的最后一次访问时间。</strong><br>当 Redis 进行内存淘汰时，会使用随机采样的方式来淘汰数据，它是随机取 5 个值（此值可配置），然后淘汰最久没有使用的那个。<strong>但无法解决缓存污染问题</strong></p>
<p>LFU 全称是 Least Frequently Used 翻译为最近最不常用，LFU 算法是根据数据访问次数来淘汰数据的，它的核心思想是“<strong>如果数据过去被访问多次，那么将来被访问的频率也更高</strong>”。<br><strong>LFU 算法会记录每个数据的访问次数。当一个数据被再次访问时，就会增加该数据的访问次数</strong>。这样就解决了偶尔被访问一次之后，数据留存在缓存中很长一段时间的问题，相比于 LRU 算法也更合理一些。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">redisObject</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">      </span><br><span class="line">    <span class="comment">// 24 bits，用于记录对象的访问信息</span></span><br><span class="line">    <span class="type">unsigned</span> lru:<span class="number">24</span>;  </span><br><span class="line">    ...</span><br><span class="line">&#125; robj;</span><br></pre></td></tr></table></figure>

<p>Redis 对象头中的 lru 字段，在 LRU 算法下和 LFU 算法下使用方式并不相同。<br>在 LRU 算法中，Redis 对象头的 24 bits 的 lru 字段是用来记录 key 的访问时间戳，因此在 LRU 模式下，Redis可以根据对象头中的 lru 字段记录的值，来比较最后一次 key 的访问时间长，从而淘汰最久未被使用的 key。<br>在 LFU 算法中，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，低 8bit 存储 logc(Logistic Counter)。</p>
<p><img data-src="/mybook.github.io/587813417257252.png"></p>
<p>注意，logc 并不是单纯的访问次数，而是访问频次（访问频率），因为 logc 会随时间推移而衰减的。</p>
<p>在每次 key 被访问时，<strong>会先对 logc 做一个衰减操作</strong>，衰减的值跟前后访问时间的差距有关系，<strong>如果上一次访问的时间与这一次访问的时间差距很大，那么衰减的值就越大</strong>，这样实现的 LFU 算法是根据访问频率来淘汰数据的，而不只是访问次数。访问频率需要考虑 key 的访问是多长时间段内发生的。key 的先前访问距离当前时间越长，那么这个 key 的访问频率相应地也就会降低，这样被淘汰的概率也会更大。</p>
<p>对 logc 做完衰减操作后，就开始对 logc 进行增加操作，增加操作并不是单纯的 + 1，而是<strong>根据概率增加</strong>，如果 logc 越大的 key，它的 logc 就越难再增加。</p>
<p>redis.conf 提供了两个配置项，用于调整 LFU 算法从而控制 logc 的增长和衰减：<br>lfu-decay-time 用于调整 logc 的衰减速度，它是一个以分钟为单位的数值，默认值为1，lfu-decay-time 值越大，衰减越慢；<br>lfu-log-factor 用于调整 logc 的增长速度，lfu-log-factor 值越大，logc 增长越慢。</p>
<h1 id="Redis的高可用"><a href="#Redis的高可用" class="headerlink" title="Redis的高可用"></a>Redis的高可用</h1><h2 id="主从结构"><a href="#主从结构" class="headerlink" title="主从结构"></a>主从结构</h2><p><img data-src="/mybook.github.io/488184417250386.png"></p>
<p>在服务器 B 上执行下面这条命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">replicaof &lt;服务器 A 的 IP 地址&gt; &lt;服务器 A 的 Redis 端口号&gt;</span><br></pre></td></tr></table></figure>
<p>接着，服务器 B 就会变成服务器 A 的「从服务器」，然后与主服务器进行第一次同步。</p>
<p>主从服务器间的第一次同步的过程可分为三个阶段：</p>
<p><img data-src="/mybook.github.io/150742911246842.png"></p>
<h3 id="全量同步"><a href="#全量同步" class="headerlink" title="全量同步"></a>全量同步</h3><ol>
<li>第一阶段是建立链接、协商同步</li>
</ol>
<p>从服务器会给主服务器发送 psync 命令，表示要进行数据同步。psync 命令包含两个参数，分别是<strong>主服务器的 runID <strong>和</strong>复制进度 offset</strong>。</p>
<ul>
<li>runID，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。当从服务器和主服务器第一次同步时，因为不知道主服务器的 run ID，所以将其设置为 “?”。</li>
<li>offset，表示复制的进度，第一次同步时，其值为 -1。</li>
</ul>
<p>主服务器收到 psync 命令后，会用 FULLRESYNC 作为响应命令返回给对方。并且这个响应命令会带上这两个参数。从服务器收到响应后，会记录这两个值。FULLRESYNC 响应命令的意图是<strong>采用全量复制的方式</strong></p>
<ol start="2">
<li>第二阶段是主服务器同步数据给从服务器；</li>
</ol>
<p>主服务器会执行 bgsave 命令（异步）来生成 RDB 文件，然后把文件发送给从服务器。从服务器收到 RDB 文件后，会先清空当前的数据，然后载入 RDB 文件。<br>但是，这期间的写操作命令并没有记录到刚刚生成的 RDB 文件中，这时主从服务器间的数据就不一致了。<br>为了保证主从服务器的数据一致性，主服务器在下面这三个时间间隙中将收到的写操作命令，写入到<strong>replication buffer 缓冲区</strong>里：</p>
<ul>
<li>主服务器生成 RDB 文件期间；</li>
<li>主服务器发送 RDB 文件给从服务器期间；</li>
<li>「从服务器」加载 RDB 文件期间；</li>
</ul>
<ol start="3">
<li>第三阶段是主服务器发送新写操作命令给从服务器。</li>
</ol>
<p>从服务器完成 RDB 的载入后，会回复一个确认消息给主服务器。主服务器将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，从服务器执行来自主服务器 replication buffer 缓冲区里发来的命令，这时主从服务器的数据就一致了。</p>
<h3 id="命令传播"><a href="#命令传播" class="headerlink" title="命令传播"></a>命令传播</h3><p>主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接，而且这个连接是长连接的，<strong>目的是避免频繁的 TCP 连接和断开带来的性能开销</strong>。</p>
<h3 id="分摊主服务器的压力"><a href="#分摊主服务器的压力" class="headerlink" title="分摊主服务器的压力"></a>分摊主服务器的压力</h3><p>主服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会带来两个问题：</p>
<ol>
<li>bgsave生成 RDB文件的，主服务器就会忙于使用 fork() 创建子进程，如果主服务器的内存数据很大，在执行 fork() 函数时会阻塞主线程，从而使得 Redis 无法正常处理请求</li>
<li>传输 RDB 文件会占用主服务器的网络带宽，会对主服务器响应命令请求产生影响。</li>
</ol>
<p>从服务器可以有自己的从服务器，可以把拥有从服务器的从服务器当作<strong>经理角色</strong>，它不仅可以接收主服务器的同步数据，自己也可以同时作为主服务器的形式将数据同步给从服务器，<strong>主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器</strong></p>
<p><img data-src="/mybook.github.io/49241511240549.png"></p>
<p>在「从服务器」上执行下面这条命令，使其作为目标服务器的从服务器：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">replicaof &lt;目标服务器的IP&gt; 6379</span><br></pre></td></tr></table></figure>



<h3 id="增量同步"><a href="#增量同步" class="headerlink" title="增量同步"></a>增量同步</h3><p>如果主从服务器间的网络连接断开了，那么就无法进行命令传播了，这时从服务器的数据就没办法和主服务器保持一致了，客户端就可能从「从服务器」读到旧的数据。<br>从 Redis 2.8 开始，网络断开又恢复后，从主从服务器会采用增量复制的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。</p>
<p><img data-src="/mybook.github.io/252172211258975.png"></p>
<ol>
<li>从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；</li>
<li>主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；</li>
<li>然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。</li>
</ol>
<p><strong>主服务器怎么知道要将哪些增量数据发送给从服务器呢？</strong><br>repl_backlog_buffer，是一个「环形」缓冲区，用于主从服务器断连后，从中找到差异的数据；<br>replication offset，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master_repl_offset 来记录自己「写」到的位置，从服务器使用 slave_repl_offset 来记录自己「读」到的位置。</p>
<p>从Redis完成初始化后，每一个对主Redis的操作会被发送到从Redis执行相同操作，这被称为增量同步，以保证主从Redis数据一致性。<br>默认情况下，slave只读不写，所以一般对Redis的读操作都在slave上进行，以达到分担master压力的目的，master上只进行写操作。</p>
<p><strong>repl_backlog_buffer 缓冲区是什么时候写入的呢？</strong></p>
<p>在主服务器<strong>进行命令传播时</strong>，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。</p>
<p>网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作：从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用增量同步的方式；相反，主服务器将采用全量同步的方式。</p>
<p>repl_backlog_buffer 缓行缓冲区的默认大小是 1M，为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，应该调整repl_backlog_buffer 缓冲区大小，尽可能的大一些，减少出现从服务器要读取的数据被覆盖的概率，从而使得主服务器采用增量同步的方式。<br><img data-src="/mybook.github.io/554712018267008.png"></p>
<h3 id="主从同步策略"><a href="#主从同步策略" class="headerlink" title="主从同步策略"></a>主从同步策略</h3><p>主从刚刚连接的时候，进行全量同步；全同步结束后，进行增量同步。如果有需要，slave 在任何时候都可以发起全量同步。redis 策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。</p>
<h3 id="如何应对主从数据不一致？"><a href="#如何应对主从数据不一致？" class="headerlink" title="如何应对主从数据不一致？"></a><font color="red">如何应对主从数据不一致？</font></h3><p>主从节点间的命令复制是异步进行的，所以会主从数据不一致</p>
<ol>
<li><p>保证主从节点间的网络连接状况良好，避免主从节点在不同的机房。</p>
</li>
<li><p>可以开发一个外部程序来监控主从节点间的复制进度。具体做法：<br>Redis 的 INFO replication 命令可以查看主节点接收写命令的进度信息（master_repl_offset）和从节点复制写命令的进度信息（slave_repl_offset），所以，我们就可以开发一个监控程序，先用 INFO replication 命令查到主、从节点的进度，这样就能得到从节点和主节点间的复制进度差值了。<br>如果某个从节点的进度差值大于我们预设的阈值，我们可以让客户端不再和这个从节点连接进行数据读取，这样就可以减少读到不一致数据的情况。不过，为了避免出现客户端和所有从节点都不能连接的情况，我们需要把复制进度差值的阈值设置得大一些。</p>
</li>
</ol>
<h2 id="哨兵机制"><a href="#哨兵机制" class="headerlink" title="哨兵机制"></a>哨兵机制</h2><h3 id="哨兵的职责"><a href="#哨兵的职责" class="headerlink" title="哨兵的职责"></a>哨兵的职责</h3><p>哨兵节点主要负责三件事情：监控、通知、选主。</p>
<ol>
<li>检测主从节点是否运转正常</li>
<li>收集主从节点信息，出错的时候可以通过API通知系统管理员</li>
<li>自动failover：当一个master节点出现了问题，多个哨兵需要沟通是否真的确认出现问题，确认出现问题要检查其他slave节点的情况，自动选举新的适合充当master节点的slave，改变其状态成为新的master，继续提供服务并管理其他slave</li>
</ol>
<p><mark>第三个职责自动failover是哨兵最重要的职责，配合主从架构很好的保证了系统的高可用性，</mark>前面讲过主从架构中所有master和slave的数据都是一致的，所以当提供主要服务的master宕机，可以立刻把拥有相同数据的slave推举为新的master继续提供服务，而不会造成业务的不可用。</p>
<p>注：一个哨兵可以设置监测多个redis节点，但是没必要设置监测slave节点，监测master节点时会自动获取到slave节点的信息。</p>
<h3 id="如何判断主节点真的故障了？"><a href="#如何判断主节点真的故障了？" class="headerlink" title="如何判断主节点真的故障了？"></a>如何判断主节点真的故障了？</h3><p><img data-src="/mybook.github.io/460293209259679.png"></p>
<ol>
<li>主管下线<br>如果主节点或者从节点没有在规定的时间内发送PONG，响应哨兵的 PING 命令，哨兵就会将它们标记为<strong>「主观下线」</strong>（sdown状态）。这个「规定的时间」是配置项 down-after-milliseconds 参数设定的</li>
<li>客观下线<br>可能只是因为主节点的系统压力比较大或者网络发送了拥塞，当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令（is-master-down-by-addr），其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。<br>如果超过规定数量的哨兵将该Redis节点标注成了sdown状态，即可确定这个服务确实成为了不可用状态，将该状态改为odown，也就是客观的不可用状态，准备进行新master节点的推举来代替该redis节点继续提供服务。</li>
</ol>
<p><img data-src="/mybook.github.io/425823609256234.png"></p>
<h3 id="由哪个哨兵进行主从故障转移？"><a href="#由哪个哨兵进行主从故障转移？" class="headerlink" title="由哪个哨兵进行主从故障转移？"></a>由哪个哨兵进行主从故障转移？</h3><p>需要在哨兵集群中选出一个 leader，让 leader 来执行主从切换。哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者。</p>
<p>任何一个「候选者」，要满足两个条件：</p>
<ul>
<li>第一，拿到半数以上的赞成票；</li>
<li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li>
</ul>
<p><strong>如果某个时间点，刚好有两个哨兵节点判断到主节点为客观下线？</strong><br>每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求。投票者先收到谁的投票请求，就会先投票给它，如果投票者用完投票机会后，就会拒绝投票。</p>
<h3 id="三个哨兵原则"><a href="#三个哨兵原则" class="headerlink" title="三个哨兵原则"></a>三个哨兵原则</h3><p>哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成哨兵集群（最少需要三台机器来部署哨兵集群），通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</p>
<p>一个高可用的架构应该至少包括三个部署在不同服务器上的哨兵，因为如果只有两个哨兵，有一台服务器挂了，哨兵也就只剩下了一个，即使能确定服务器上redis服务的odown状态，也没有超过半数（超过2&#x2F;2 &#x3D; 1个哨兵）的哨兵来选举出哨兵执行failover，因此一个合理的系统至少有三台服务器，三个哨兵来保证系统的高可用性</p>
<p><strong>Redis 1 主 4 从，5 个哨兵，quorum 设置为 3，如果 2 个哨兵故障，当主节点宕机时，哨兵能否判断主节点“客观下线”？主从能否自动切换？</strong><br>哨兵集群可以判定主节点“客观下线”。哨兵集群还剩下 3 个哨兵，当一个哨兵判断主节点“主观下线”后，询问另外 2 个哨兵后，<strong>有可能能拿到 3 张赞同票，这时就达到了 quorum 的值</strong>，因此，哨兵集群可以判定主节点为“客观下线”。</p>
<p>哨兵集群可以完成主从切换。当有个哨兵标记主节点为「客观下线」后，就会进行选举 Leader 的过程，因为此时哨兵集群还剩下 3 个哨兵，<strong>那么还是可以拿到半数以上（5&#x2F;2+1&#x3D;3）的票，而且也达到了 quorum 值</strong>，满足了选举 Leader 的两个条件，所以就能选举成功，因此哨兵集群可以完成主从切换。</p>
<p>如果 quorum 设置为 2，并且如果有 3 个哨兵故障的话。此时哨兵集群还是可以判定主节点为“客观下线”，但是哨兵不能完成主从切换了，大家可以自己推演下。</p>
<p>如果 quorum 设置为 3，并且如果有 3 个哨兵故障的话，哨兵集群即不能判定主节点为“客观下线”，也不能完成主从切换了。</p>
<p><strong>quorum 的值建议设置为哨兵个数的二分之一加 1，例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且哨兵节点的数量应该是奇数。</strong></p>
<h3 id="脑裂现象"><a href="#脑裂现象" class="headerlink" title="脑裂现象"></a>脑裂现象</h3><p>如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的。<br>这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据，此时这些数据被主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。<br>这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在从节点中选举出一个 leeder 作为主节点，这时集群就有两个主节点了 —— 脑裂出现了。</p>
<h3 id="主从切换如何减少数据丢失？"><a href="#主从切换如何减少数据丢失？" class="headerlink" title="主从切换如何减少数据丢失？"></a><font color="red">主从切换如何减少数据丢失？</font></h3><ol>
<li><p>异步复制同步丢失<br>当客户端发送写请求给主节点的时候，客户端会返回 ok，接着主节点将写请求异步同步给各个从节点，但是如果此时主节点还没来得及同步给从节点时发生了断电，那么主节点内存中的数据会丢失。<br>Redis 配置里有一个参数 min-slaves-max-lag，表示一旦所有的从节点数据复制和同步的延迟都超过了 min-slaves-max-lag 定义的值，那么主节点就会拒绝接收任何请求，即使 master 宕机也只是这未复制的 10s 数据。<br>当客户端发现 master 不可写后，可以采取降级措施，将数据暂时写入本地缓存、磁盘、kafka 消息队列中，在一段时间（等 master 恢复正常）后重新写入 master 来保证数据不丢失。</p>
</li>
<li><p>集群产生脑裂数据丢失<br>脑裂现象产生后，这时候网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，因为第一次同步是全量同步的方式，<strong>此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步</strong>。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题。<br>解决方案：<br>当主节点发现「从节点下线的数量太多」，或者「网络延迟太大」的时候，那么主节点会禁止写操作，直接把错误返回给客户端。</p>
</li>
</ol>
<p>在 Redis 的配置文件中有两个参数我们可以设置：</p>
<ol>
<li>min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。</li>
<li>min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果主从同步的延迟超过 x 秒，主节点会禁止写数据。<br>分别给它们设置一定的阈值，假设为 N 和 T。这两个配置项组合后的要求是，<strong>主节点连接的从节点中至少有 N 个从节点，「并且」主节点进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主节点就不会再接收客户端的写请求了</strong>。</li>
</ol>
<p>等到新主节点上线时，就只有新主节点能接收和处理客户端请求，此时，新写的数据会被直接写到新主节点中。而原主节点会被哨兵降为从节点，即使它的数据被清空了，也不会有新数据丢失。</p>
<h2 id="高可用架构"><a href="#高可用架构" class="headerlink" title="高可用架构"></a>高可用架构</h2><h3 id="主从故障转移的过程是怎样的？"><a href="#主从故障转移的过程是怎样的？" class="headerlink" title="主从故障转移的过程是怎样的？"></a>主从故障转移的过程是怎样的？</h3><p>主从故障转移操作包含以下四个步骤：</p>
<ol>
<li>在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。</li>
<li>让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；</li>
<li>将新主节点的 IP 地址和信息，通过「发布者&#x2F;订阅者机制」通知给客户端；</li>
<li>继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；</li>
</ol>
<h4 id="选出新主节点"><a href="#选出新主节点" class="headerlink" title="选出新主节点"></a>选出新主节点</h4><p>故障转移操作第一步要做的就是在已下线主节点属下的所有「从节点」中，挑选出一个状态良好、数据完整的从节点，然后向这个「从节点」发送 SLAVEOF no one 命令，将这个「从节点」转换为「主节点」。</p>
<p><strong>那么多「从节点」，到底选择哪个从节点作为新主节点的？</strong></p>
<p>先进行网络过滤<br>Redis 有个叫 down-after-milliseconds * 10 配置项，其 down-after-milliseconds 是主从节点断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从节点的网络状况不好，不适合作为新主节点。</p>
<p>再进行三轮考察：优先级、复制进度、ID 号。</p>
<ol>
<li><p>哨兵首先会根据从节点的优先级来进行排序，优先级越小排名越靠前，<br>Redis 有个叫 slave-priority 配置项，可以给从节点设置优先级。如果「A 从节点」的物理内存是所有从节点中最大的，那么我们可以把「A 从节点」的优先级设置成最高。</p>
</li>
<li><p>如果优先级相同，则查看复制的下标，哪个从「主节点」接收的复制数据多，哪个就靠前。<br>如果某个从节点的 slave_repl_offset 最接近 master_repl_offset，说明它的复制进度是最靠前的，于是就可以将它选为新主节点。</p>
</li>
<li><p>如果优先级和下标都相同，就选择从节点 ID 较小的那个。<br>每个从节点都有一个编号，这个编号就是 ID 号，是用来唯一标识从节点的。</p>
</li>
</ol>
<p>如下图，哨兵 leader 向被选中的从节点 server2 发送 SLAVEOF no one 命令，将该从节点升级为新主节点。</p>
<p><img data-src="/mybook.github.io/99025809251988.png"></p>
<p>在发送 SLAVEOF no one 命令之后，哨兵 leader 会以每秒一次的频率向被升级的从节点发送 INFO 命令（没进行故障转移之前，INFO 命令的频率是每十秒一次），并观察命令回复中的角色信息，当被升级节点的角色信息从原来的 slave 变为 master 时，哨兵 leader 就知道被选中的从节点已经顺利升级为主节点了。</p>
<h4 id="将从节点指向新主节点"><a href="#将从节点指向新主节点" class="headerlink" title="将从节点指向新主节点"></a>将从节点指向新主节点</h4><p>向「从节点」发送 SLAVEOF 命令来实现。</p>
<p><img data-src="/mybook.github.io/493510010269868.png"></p>
<h4 id="通知客户的主节点已更换"><a href="#通知客户的主节点已更换" class="headerlink" title="通知客户的主节点已更换"></a>通知客户的主节点已更换</h4><p>通过 Redis 的发布者&#x2F;订阅者机制来实现，主从切换完成后，哨兵就会向 +switch-master 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了。</p>
<p><img data-src="/mybook.github.io/414930110267472.png"></p>
<h4 id="将旧主节点变为从节点"><a href="#将旧主节点变为从节点" class="headerlink" title="将旧主节点变为从节点"></a>将旧主节点变为从节点</h4><p>继续监视旧主节点，当旧主节点重新上线时，哨兵集群就会向它发送 SLAVEOF 命令，让它成为新主节点的从节点</p>
<p><img data-src="/mybook.github.io/443500610264974.png"></p>
<h3 id="哨兵集群是如何组成的？"><a href="#哨兵集群是如何组成的？" class="headerlink" title="哨兵集群是如何组成的？"></a>哨兵集群是如何组成的？</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt; </span><br></pre></td></tr></table></figure>

<p><strong>为什么只需要执行命令设置主节点名字、主节点的 IP 地址和端口号以及 quorum 值，就能搭建哨兵集群？</strong></p>
<p>在主从集群中，主节点上有一个名为__sentinel__:hello的频道，不同哨兵就是通过它来相互发现，实现互相通信的。</p>
<p>哨兵 A 把自己的 IP 地址和端口的信息发布到__sentinel__:hello 频道上，哨兵 B 和 C 订阅了该频道。那么此时，哨兵 B 和 C 就可以从这个频道直接获取哨兵 A 的 IP 地址和端口号。然后，哨兵 B、C 可以和哨兵 A 建立网络连接。</p>
<p><img data-src="/mybook.github.io/53561010246215.png"></p>
<p><strong>那哨兵集群如何知道「从节点」的信息？</strong></p>
<p>主节点知道所有「从节点」的信息，所以哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。</p>
<h1 id="Redis的缓存机制"><a href="#Redis的缓存机制" class="headerlink" title="Redis的缓存机制"></a>Redis的缓存机制</h1><h2 id="缓存污染和预读失效"><a href="#缓存污染和预读失效" class="headerlink" title="缓存污染和预读失效"></a>缓存污染和预读失效</h2><p>详情请见操作系统–内存篇</p>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><ol>
<li>大量缓存数据在同一时间过期（失效）</li>
<li>Redis 故障宕机<br>此时如果有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，<strong>从而导致数据库的压力骤增，严重的会造成数据库宕机</strong>，从而形成一系列连锁反应，造成整个系统崩溃。</li>
</ol>
<h3 id="大量数据同时过期"><a href="#大量数据同时过期" class="headerlink" title="大量数据同时过期"></a>大量数据同时过期</h3><h4 id="均匀设置过期时间"><a href="#均匀设置过期时间" class="headerlink" title="均匀设置过期时间"></a>均匀设置过期时间</h4><p>如果要给缓存数据设置过期时间，应该避免将大量的数据设置成同一个过期时间。我们可以在对缓存数据设置过期时间时，<strong>给这些数据的过期时间加上一个随机数</strong>，这样就保证数据不会在同一时间过期。</p>
<h4 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h4><p>当业务线程在处理用户请求时，<strong>如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存（从数据库读取数据，再将数据更新到 Redis 里）</strong>，当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</p>
<p><strong>实现互斥锁的时候，最好设置超时时间，</strong>不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。</p>
<h4 id="后台更新缓存"><a href="#后台更新缓存" class="headerlink" title="后台更新缓存"></a>后台更新缓存</h4><p>业务线程不再负责更新缓存，缓存也不设置有效期，而是<strong>让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新。</strong></p>
<p>事实上，缓存数据不设置有效期，<strong>并不是意味着数据一直能在内存里，因为当系统内存紧张的时候，有些缓存数据会被淘汰</strong>，而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了。</p>
<ol>
<li><strong>后台线程不仅负责定时更新缓存，而且也负责频繁地检测缓存是否有效</strong>，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据，并更新到缓存。</li>
</ol>
<p>这种方式的检测时间间隔不能太长，太长也导致用户获取的数据是一个空值而不是真正的数据，所以检测的间隔最好是毫秒级的，但是总归是有个间隔时间，用户体验一般。</p>
<ol start="2">
<li>在业务线程发现缓存数据失效后（缓存数据被淘汰），<strong>通过消息队列发送一条消息通知后台线程更新缓存</strong>，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。</li>
</ol>
<h4 id="缓存预热"><a href="#缓存预热" class="headerlink" title="缓存预热"></a>缓存预热</h4><p>在业务刚上线的时候，我提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的缓存预热，后台更新缓存的机制刚好也适合干这个事情。<br>Redis自带缓存预读，注意甄别区别</p>
<h3 id="Redis-故障宕机"><a href="#Redis-故障宕机" class="headerlink" title="Redis 故障宕机"></a>Redis 故障宕机</h3><h4 id="服务熔断或请求限流机制"><a href="#服务熔断或请求限流机制" class="headerlink" title="服务熔断或请求限流机制"></a>服务熔断或请求限流机制</h4><ul>
<li><p>可以启动服务熔断机制，<strong>暂停业务应用对缓存服务的访问</strong>，直接返回错误，不用再继续访问数据库，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。</p>
</li>
<li><p>为了减少对业务的影响，可以<strong>启用请求限流机制</strong>，只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。</p>
</li>
</ul>
<h4 id="构建-Redis-缓存高可靠集群"><a href="#构建-Redis-缓存高可靠集群" class="headerlink" title="构建 Redis 缓存高可靠集群"></a>构建 Redis 缓存高可靠集群</h4><p>主从节点的方式构建 Redis 缓存高可靠集群。</p>
<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p>热点数据过期，大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮。<br>可以认为缓存击穿是缓存雪崩的一个子集。应对缓存击穿可以采取前面说到两种方案：</p>
<ol>
<li>互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</li>
<li>不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；</li>
</ol>
<h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p><strong>当用户访问的数据，既不在缓存中，也不在数据库中</strong>，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，<strong>没办法构建缓存数据</strong>，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。</p>
<p>缓存穿透的发生一般有这两种情况：</p>
<ol>
<li>业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；</li>
<li>黑客恶意攻击，故意大量访问某些读取不存在数据的业务；</li>
</ol>
<p>应对缓存穿透的方案，常见的方案有三种。</p>
<h3 id="非法请求的限制"><a href="#非法请求的限制" class="headerlink" title="非法请求的限制"></a>非法请求的限制</h3><p>在入口处进行参数校验，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。</p>
<h3 id="缓存空值或者默认值"><a href="#缓存空值或者默认值" class="headerlink" title="缓存空值或者默认值"></a>缓存空值或者默认值</h3><p>可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。</p>
<h3 id="布隆过滤器快速判断数据是否存在"><a href="#布隆过滤器快速判断数据是否存在" class="headerlink" title="布隆过滤器快速判断数据是否存在"></a>布隆过滤器快速判断数据是否存在</h3><p>可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在。<br>即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。</p>
<h4 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h4><p>布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。</p>
<p>布隆过滤器会通过 3 个操作完成标记：</p>
<ol>
<li>使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；</li>
<li>将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。</li>
<li>将每个哈希值在位图数组的对应位置的值设置为 1；</li>
</ol>
<p>假设有一个位图数组长度为 8，哈希函数 3 个的布隆过滤器。</p>
<p><img data-src="/mybook.github.io/41684310268655.png"></p>
<p>当应用要查询数据 x 是否数据库时，通过布隆过滤器只要查到位图数组的第 1、4、6 位置的值是否全为 1，只要有一个为 0，就认为数据 x 不在数据库中。</p>
<p>布隆过滤器由于是基于哈希函数实现查找的，高效查找的同时<strong>存在哈希冲突的可能性</strong>，比如数据 x 和数据 y 可能都落在第 1、4、6 位置，而事实上，可能数据库中并不存在数据 y，存在误判的情况。</p>
<p><strong>查询布隆过滤器查询到数据不存在，数据库中一定就不存在这个数据，数据存在，并不一定证明数据库中存在这个数据。</strong></p>
<h1 id="Redis的系统设计"><a href="#Redis的系统设计" class="headerlink" title="Redis的系统设计"></a>Redis的系统设计</h1><h2 id="数据库和缓存的数据如何保持一致性"><a href="#数据库和缓存的数据如何保持一致性" class="headerlink" title="数据库和缓存的数据如何保持一致性"></a>数据库和缓存的数据如何保持一致性</h2><h3 id="先更新数据库，再更新缓存？"><a href="#先更新数据库，再更新缓存？" class="headerlink" title="先更新数据库，再更新缓存？"></a>先更新数据库，再更新缓存？</h3><p>并发问题导致：</p>
<p><img data-src="/mybook.github.io/241604910263791.png"></p>
<h3 id="先更新缓存，再更新数据库？"><a href="#先更新缓存，再更新数据库？" class="headerlink" title="先更新缓存，再更新数据库？"></a>先更新缓存，再更新数据库？</h3><p><img data-src="/mybook.github.io/376975010257337.png"></p>
<p>如果业务对缓存命中率有很高的要求，可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况。<br>在更新缓存前先加个分布式锁，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。<br>在更新完缓存时，给缓存加上较短的过期时间，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。</p>
<h3 id="所以先更新数据库，还是先删除缓存？"><a href="#所以先更新数据库，还是先删除缓存？" class="headerlink" title="所以先更新数据库，还是先删除缓存？"></a>所以先更新数据库，还是先删除缓存？</h3><p>是否可以借用cpu三级缓存失效策略？可以，详情请见操作系统–cpu篇</p>
<p>Cache Aside 策略(旁路缓存策略):不更新缓存，而是删除缓存中的数据。然后，到读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。</p>
<p><img data-src="/mybook.github.io/304165210250471.png"></p>
<p>这样的话在写时又会带来两个问题</p>
<h4 id="先删除缓存，再更新数据库"><a href="#先删除缓存，再更新数据库" class="headerlink" title="先删除缓存，再更新数据库?"></a>先删除缓存，再更新数据库?</h4><p><img data-src="/mybook.github.io/470005410241001.png"></p>
<p>先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题。</p>
<p>解决方法可以使用延迟双删，延迟双删实现的伪代码如下：</p>
<figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#删除缓存</span><br><span class="line">redis.delKey(X)</span><br><span class="line">#更新数据库</span><br><span class="line">db.update(X)</span><br><span class="line">#睡眠</span><br><span class="line">Thread.sleep(N)</span><br><span class="line">#再删除缓存</span><br><span class="line">redis.delKey(X)</span><br></pre></td></tr></table></figure>
<p>请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。但是具体睡眠多久其实是个玄学，</p>
<h4 id="先更新数据库，再删除缓存"><a href="#先更新数据库，再删除缓存" class="headerlink" title="先更新数据库，再删除缓存?"></a>先更新数据库，再删除缓存?</h4><p><img data-src="/mybook.github.io/318075510243505.png"></p>
<p>先更新数据库，再删除缓存也是会出现数据不一致性的问题</p>
<p><strong>但是：</strong><br>redis运行在内存中，数据库实例在磁盘中，内存的速度远大于磁盘，所以上述的情况基本不存在，<strong>「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的</strong>。<br>为了确保万无一失，还可以给缓存数据加上了「过期时间」，就算在这期间存在缓存数据不一致，有过期时间来兜底，这样也能达到最终一致。</p>
<p>问题：<br><strong>明明更新了数据，但是数据要过一段时间才生效，客户接受不了。</strong><br>如果在删除缓存（第二个操作）的时候失败了，会导致缓存中的数据是旧值。加上了过期时间，所以才会出现客户说的过一段时间才更新生效的现象，假设如果没有这个过期时间的兜底，那后续的请求读到的就会一直是缓存中的旧数据，这样问题就更大了。</p>
<p><img data-src="/mybook.github.io/525772711245337.png"></p>
<p><strong>如何保证「先更新数据库 ，再删除缓存」这两个操作能执行成功</strong>？<br>其实不管是先操作数据库，还是先操作缓存，只要第二个操作失败都会出现数据一致的问题。有两种方法：都是采用异步操作缓存。</p>
<ul>
<li><p>重试机制。<br>可以引入消息队列，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。<br>如果应用删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。<br>如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。</p>
</li>
<li><p>订阅 MySQL binlog，再操作缓存。<br>第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。<br>Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。</p>
</li>
</ul>
<p><img data-src="/mybook.github.io/19073311245946.png"></p>
<h1 id="Redis常见面试题和总结"><a href="#Redis常见面试题和总结" class="headerlink" title="Redis常见面试题和总结"></a>Redis常见面试题和总结</h1><h2 id="Redis-和-Memcached-有什么区别？"><a href="#Redis-和-Memcached-有什么区别？" class="headerlink" title="Redis 和 Memcached 有什么区别？"></a>Redis 和 Memcached 有什么区别？</h2><ul>
<li>Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型；</li>
<li>Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；</li>
<li>Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；</li>
<li>Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；</li>
</ul>
<h2 id="为什么用-Redis-作为-MySQL-的缓存？"><a href="#为什么用-Redis-作为-MySQL-的缓存？" class="headerlink" title="为什么用 Redis 作为 MySQL 的缓存？"></a>为什么用 Redis 作为 MySQL 的缓存？</h2><ol>
<li><p>Redis 具备高性能<br>运行在内存中</p>
</li>
<li><p>Redis 具备高并发<br>单台设备的 Redis 的 QPS（Query Per Second，每秒钟处理完请求的次数） 是 MySQL 的 10 倍，Redis 单机的 QPS 能轻松破 10w，而 MySQL 单机的 QPS 很难破 1w。</p>
</li>
</ol>
<h2 id="Redis-6-0-之前为什么使用单线程？"><a href="#Redis-6-0-之前为什么使用单线程？" class="headerlink" title="Redis 6.0 之前为什么使用单线程？"></a>Redis 6.0 之前为什么使用单线程？</h2><p>CPU 并不是制约 Redis 性能表现的瓶颈所在，更多情况下是受到内存大小和网络I&#x2F;O的限制，</p>
<h2 id="Redis-6-0-之后为什么引入了多线程？"><a href="#Redis-6-0-之后为什么引入了多线程？" class="headerlink" title="Redis 6.0 之后为什么引入了多线程？"></a>Redis 6.0 之后为什么引入了多线程？</h2><p>Redis 的性能瓶颈有时会出现在网络 I&#x2F;O 的处理上。Redis 6.0 版本引入的多线程 I&#x2F;O 特性对性能提升至少是一倍以上。</p>
<p>默认情况下 I&#x2F;O 多线程只针对发送响应数据（write client socket），并不会以多线程的方式处理读请求（read client socket）。要想开启多线程处理客户端读请求，就需要把 Redis.conf 配置文件中的 io-threads-do-reads 配置项设为 yes。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//读请求也使用io多线程</span><br><span class="line">io-threads-do-reads yes </span><br></pre></td></tr></table></figure>



<p>同时， Redis.conf 配置文件中提供了 IO 多线程个数的配置项。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// io-threads N，表示启用 N-1 个 I/O 多线程（主线程也算一个 I/O 线程）</span><br><span class="line">io-threads 4 </span><br></pre></td></tr></table></figure>

<p>默认情况下会额外创建 6 个线程（这里的线程数不包括主线程）：</p>
<ul>
<li>Redis-server ： Redis的主线程，主要负责执行命令；</li>
<li>bio_close_file、bio_aof_fsync、bio_lazy_free：三个后台线程，分别异步处理关闭文件任务、AOF刷盘任务、释放内存任务；</li>
<li>io_thd_1、io_thd_2、io_thd_3：三个 I&#x2F;O 线程，io-threads 默认是 4 ，所以会启动 3（4-1）个 I&#x2F;O 多线程，用来分担 Redis 网络 I&#x2F;O 的压力。</li>
</ul>
<h2 id="怎么判断-Redis-某个节点是否正常工作？"><a href="#怎么判断-Redis-某个节点是否正常工作？" class="headerlink" title="怎么判断 Redis 某个节点是否正常工作？"></a>怎么判断 Redis 某个节点是否正常工作？</h2><p>Redis 判断节点是否正常工作，基本都是通过互相的 ping-pong 心态检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。</p>
<p>Redis 主从节点发送的心态间隔是不一样的，而且作用也有一点区别：</p>
<p>Redis 主节点默认每隔 10 秒对从节点发送 ping 命令，判断从节点的存活性和连接状态，可通过参数repl-ping-slave-period控制发送频率。<br>Redis 从节点每隔 1 秒发送 replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量，目的是为了：<br>实时监测主从节点网络状态；<br>上报自身复制偏移量， 检查复制数据是否丢失， 如果从节点数据丢失， 再从主节点的复制缓冲区中拉取丢失数据。</p>
<h2 id="主从复制架构中，过期key如何处理？"><a href="#主从复制架构中，过期key如何处理？" class="headerlink" title="主从复制架构中，过期key如何处理？"></a>主从复制架构中，过期key如何处理？</h2><p>主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。</p>
<h2 id="主从复制中两个Buffer有什么区别？"><a href="#主从复制中两个Buffer有什么区别？" class="headerlink" title="主从复制中两个Buffer有什么区别？"></a>主从复制中两个Buffer有什么区别？</h2><p>replication buffer 、repl backlog buffer 区别如下：</p>
<ul>
<li><p>出现的阶段不一样：<br>repl backlog buffer 是在增量复制阶段出现，<strong>一个主节点只分配一个 repl backlog buffer</strong>；<br>replication buffer 是在全量复制阶段和增量复制阶段都会出现，<strong>主节点会给每个新连接的从节点，分配一个 replication buffer</strong>；</p>
</li>
<li><p>这两个 Buffer 都有大小限制的，当缓冲区满了之后，发生的事情不一样：<br>当 repl backlog buffer 满了，因为是环形结构，<strong>会直接覆盖起始位置数据</strong>;<br>当 replication buffer 满了，会导致连接断开，删除缓存，从节点重新连接，<strong>重新开始全量复制</strong>。</p>
</li>
</ul>
<h2 id="Redis-主从模式中，对过期键会如何处理？"><a href="#Redis-主从模式中，对过期键会如何处理？" class="headerlink" title="Redis 主从模式中，对过期键会如何处理？"></a>Redis 主从模式中，对过期键会如何处理？</h2><p>当 Redis 运行在主从模式下时，从库不会进行过期扫描，从库对过期的处理是被动的。也就是即使从库中的 key 过期了，如果有客户端访问从库时，依然可以得到 key 对应的值，像未过期的键值对一样返回。</p>
<p>从库的过期键处理依靠主服务器控制，主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。</p>
<h2 id="Redis-内存满了，会发生什么？"><a href="#Redis-内存满了，会发生什么？" class="headerlink" title="Redis 内存满了，会发生什么？"></a>Redis 内存满了，会发生什么？</h2><p>在 Redis 的运行内存达到了某个阀值，就会触发内存淘汰机制(OOM)，这个阀值就是我们设置的最大运行内存，此值在 Redis 的配置文件中可以找到，配置项为 maxmemory。</p>
<h2 id="如何设计一个缓存策略，可以动态缓存热点数据呢？"><a href="#如何设计一个缓存策略，可以动态缓存热点数据呢？" class="headerlink" title="如何设计一个缓存策略，可以动态缓存热点数据呢？"></a>如何设计一个缓存策略，可以动态缓存热点数据呢？</h2><p>由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，<strong>而只是将其中一部分热点数据缓存起来</strong>，所以我们要设计一个热点数据动态缓存的策略。</p>
<p>热点数据动态缓存的策略总体思路：<strong>通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据</strong>。</p>
<p>以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品。具体细节如下：</p>
<p>先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前；<br>同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；<br>这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。<br>在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。</p>
<h2 id="Redis-如何实现延迟队列？"><a href="#Redis-如何实现延迟队列？" class="headerlink" title="Redis 如何实现延迟队列？"></a>Redis 如何实现延迟队列？</h2><p>延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：</p>
<ul>
<li>在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；</li>
<li>打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；</li>
<li>点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单；</li>
</ul>
<p>在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，<strong>ZSet 有一个 Score 属性可以用来存储延迟执行的时间</strong>。</p>
<p>使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。</p>
<p><img data-src="/mybook.github.io/199813014258977.png"></p>
<h2 id="Redis-的大-key-如何处理？"><a href="#Redis-的大-key-如何处理？" class="headerlink" title="Redis 的大 key 如何处理？"></a>Redis 的大 key 如何处理？</h2><p>key 对应的 value 很大。String 类型的值大于 10 KB；Hash、List、Set、ZSet 类型的元素的个数超过 5000个；<br>大 key 会带来以下四种影响：</p>
<ul>
<li>客户端超时阻塞。<br>由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li>
<li>引发网络阻塞。<br>每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li>
<li>阻塞工作线程。<br>如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li>
<li>内存分布不均。<br>集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li>
</ul>
<h3 id="如何查找大key"><a href="#如何查找大key" class="headerlink" title="如何查找大key"></a>如何查找大key</h3><h4 id="redis-cli-–bigkeys-查找大key"><a href="#redis-cli-–bigkeys-查找大key" class="headerlink" title="redis-cli –bigkeys 查找大key"></a>redis-cli –bigkeys 查找大key</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h 127.0.0.1 -p6379 -a &quot;password&quot; -- bigkeys</span><br></pre></td></tr></table></figure>

<p>注意事项：<br><strong>最好选择在从节点上执行该命令。因为主节点上执行时，会阻塞主节点</strong>；<br>如果没有从节点，那么可以选择在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；或者可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能。</p>
<p>该方式的不足之处：</p>
<p>这个方法只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的 bigkey；<br>对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。但是，<strong>一个集合中的元素个数多，并不一定占用的内存就多</strong>。因为，有可能每个元素占用的内存很小，这样的话，即使元素个数有很多，总内存开销也不大；</p>
<h4 id="使用-SCAN-命令查找大-key"><a href="#使用-SCAN-命令查找大-key" class="headerlink" title="使用 SCAN 命令查找大 key"></a>使用 SCAN 命令查找大 key</h4><p>使用 SCAN 命令对数据库扫描，然后用 TYPE 命令获取返回的每一个 key 的类型。</p>
<p>对于 String 类型，可以直接使用 STRLEN 命令获取字符串的长度，也就是占用的内存空间字节数。</p>
<p>对于集合类型来说，有两种方法可以获得它占用的内存大小：</p>
<p>如果能够预先从业务层知道集合元素的平均大小，那么，可以使用下面的命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小了。List 类型：LLEN 命令；Hash 类型：HLEN 命令；Set 类型：SCARD 命令；Sorted Set 类型：ZCARD 命令；<br>如果不能提前知道写入集合的元素大小，可以使用 MEMORY USAGE 命令（需要 Redis 4.0 及以上版本），查询一个键值对占用的内存空间。</p>
<h4 id="使用-RdbTools-工具查找大-key"><a href="#使用-RdbTools-工具查找大-key" class="headerlink" title="使用 RdbTools 工具查找大 key"></a>使用 RdbTools 工具查找大 key</h4><p>使用 RdbTools 第三方开源工具，可以用来解析 Redis 快照（RDB）文件，找到其中的大 key。<br>比如，下面这条命令，将大于 10 kb 的  key  输出到一个表格文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdb dump.rdb -c memory --bytes 10240 -f redis.csv</span><br></pre></td></tr></table></figure>


<h3 id="如何删除大key？"><a href="#如何删除大key？" class="headerlink" title="如何删除大key？"></a>如何删除大key？</h3><p>在应用程序释放内存时，操作系统需要把释放掉的内存块插入一个空闲内存块的链表，以便后续进行管理和再分配。这个过程本身需要一定时间，而且会阻塞当前释放内存的应用程序。</p>
<p>如果一下子释放了大量内存，空闲内存块链表操作时间就会增加，<strong>相应地就会造成 Redis 主线程的阻塞</strong>，如果主线程发生了阻塞，其他所有请求可能都会超时，超时越来越多，会造成 Redis 连接耗尽，产生各种异常。</p>
<h4 id="分批次删除"><a href="#分批次删除" class="headerlink" title="分批次删除"></a>分批次删除</h4><p>对于删除大 Hash，使用 hscan 命令，每次获取 100 个字段，再用 hdel 命令，每次删除 1 个字段。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">del_large_hash</span>():</span><br><span class="line">  r = redis.StrictRedis(host=<span class="string">&#x27;redis-host1&#x27;</span>, port=<span class="number">6379</span>)</span><br><span class="line">    large_hash_key =<span class="string">&quot;xxx&quot;</span> <span class="comment">#要删除的大hash键名</span></span><br><span class="line">    cursor = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">    <span class="keyword">while</span> cursor != <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 使用 hscan 命令，每次获取 100 个字段</span></span><br><span class="line">        cursor, data = r.hscan(large_hash_key, cursor=cursor, count=<span class="number">100</span>)</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> data.items():</span><br><span class="line">                <span class="comment"># 再用 hdel 命令，每次删除1个字段</span></span><br><span class="line">                r.hdel(large_hash_key, item[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<p>对于删除大 List，通过 ltrim 命令，每次删除少量元素。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">del_large_list</span>():</span><br><span class="line">  r = redis.StrictRedis(host=<span class="string">&#x27;redis-host1&#x27;</span>, port=<span class="number">6379</span>)</span><br><span class="line">  large_list_key = <span class="string">&#x27;xxx&#x27;</span>  <span class="comment">#要删除的大list的键名</span></span><br><span class="line">  <span class="keyword">while</span> r.llen(large_list_key)&gt;<span class="number">0</span>:</span><br><span class="line">      <span class="comment">#每次只删除最右100个元素</span></span><br><span class="line">      r.ltrim(large_list_key, <span class="number">0</span>, -<span class="number">101</span>) </span><br></pre></td></tr></table></figure>

<p>对于删除大 Set，使用 sscan 命令，每次扫描集合中 100 个元素，再用 srem 命令每次删除一个键。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">del_large_set</span>():</span><br><span class="line">  r = redis.StrictRedis(host=<span class="string">&#x27;redis-host1&#x27;</span>, port=<span class="number">6379</span>)</span><br><span class="line">  large_set_key = <span class="string">&#x27;xxx&#x27;</span>   <span class="comment"># 要删除的大set的键名</span></span><br><span class="line">  cursor = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">  <span class="keyword">while</span> cursor != <span class="number">0</span>:</span><br><span class="line">    <span class="comment"># 使用 sscan 命令，每次扫描集合中 100 个元素</span></span><br><span class="line">    cursor, data = r.sscan(large_set_key, cursor=cursor, count=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> data:</span><br><span class="line">      <span class="comment"># 再用 srem 命令每次删除一个键</span></span><br><span class="line">      r.srem(large_size_key, item)</span><br></pre></td></tr></table></figure>

<p>对于删除大 ZSet，使用 zremrangebyrank 命令，每次删除 top 100个元素。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">del_large_sortedset</span>():</span><br><span class="line">  r = redis.StrictRedis(host=<span class="string">&#x27;large_sortedset_key&#x27;</span>, port=<span class="number">6379</span>)</span><br><span class="line">  large_sortedset_key=<span class="string">&#x27;xxx&#x27;</span></span><br><span class="line">  <span class="keyword">while</span> r.zcard(large_sortedset_key)&gt;<span class="number">0</span>:</span><br><span class="line">    <span class="comment"># 使用 zremrangebyrank 命令，每次删除 top 100个元素</span></span><br><span class="line">    r.zremrangebyrank(large_sortedset_key,<span class="number">0</span>,<span class="number">99</span>) </span><br></pre></td></tr></table></figure>

<h4 id="异步删除"><a href="#异步删除" class="headerlink" title="异步删除"></a>异步删除</h4><p>用 unlink 命令代替 del 来删除。这样 Redis 会将这个 key 放入到一个异步线程中进行删除，这样不会阻塞主线程。</p>
<ul>
<li>lazyfree-lazy-eviction：表示当 Redis 运行内存超过 maxmeory 时，是否开启 lazy free 机制删除；</li>
<li>lazyfree-lazy-expire：表示设置了过期时间的键值，当过期之后是否开启 lazy free 机制删除；</li>
<li>lazyfree-lazy-server-del：有些指令在处理已存在的键时，会带有一个隐式的 del 键的操作，比如 rename 命令，当目标键已存在，Redis 会先删除目标键，如果这些目标键是一个 big key，就会造成阻塞删除的问题，此配置表示在这种场景中是否开启 lazy free 机制删除；</li>
<li>slave-lazy-flush：针对 slave (从节点) 进行全量数据同步，slave 在加载 master 的 RDB 文件前，会运行 flushall 来清理自己的数据，它表示此时是否开启 lazy free 机制删除。</li>
</ul>
<p>建议开启其中的 lazyfree-lazy-eviction、lazyfree-lazy-expire、lazyfree-lazy-server-del 等配置，这样就可以有效的提高主线程的执行效率。</p>
<h2 id="Redis-事务支持回滚吗？"><a href="#Redis-事务支持回滚吗？" class="headerlink" title="Redis 事务支持回滚吗？"></a>Redis 事务支持回滚吗？</h2><p>Redis 中并没有提供回滚机制，Redis 并不一定保证原子性</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">获取name原本的值</span></span><br><span class="line">127.0.0.1:6379&gt; GET name</span><br><span class="line">&quot;xiaolin&quot;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">开启事务</span></span><br><span class="line">127.0.0.1:6379&gt; MULTI</span><br><span class="line">OK</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置新值</span></span><br><span class="line">127.0.0.1:6379(TX)&gt; SET name xialincoding</span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">注意，这条命令是错误的</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">expire 过期时间正确来说是数字，并不是‘10s’字符串，但是还是入队成功了</span></span><br><span class="line">127.0.0.1:6379(TX)&gt; EXPIRE name 10s</span><br><span class="line">QUEUED</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">提交事务，执行报错</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">可以看到 <span class="built_in">set</span> 执行成功，而 expire 执行错误。</span></span><br><span class="line">127.0.0.1:6379(TX)&gt; EXEC</span><br><span class="line">1) OK</span><br><span class="line">2) (error) ERR value is not an integer or out of range</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">可以看到，name 还是被设置为新值了</span></span><br><span class="line">127.0.0.1:6379&gt; GET name</span><br><span class="line">&quot;xialincoding&quot;</span><br></pre></td></tr></table></figure>

<p>作者不支持事务回滚的原因有以下两个：</p>
<ol>
<li>他认为 Redis 事务的执行时，错误通常都是编程错误造成的，这种错误通常只会出现在开发环境中，而很少会在实际的生产环境中出现，所以他认为没有必要为 Redis 开发事务回滚功能；</li>
<li>不支持事务回滚是因为这种复杂的功能和 Redis 追求的简单高效的设计主旨不符合。这里不支持事务回滚，指的是不支持事务运行时错误的事务回滚。</li>
</ol>
<h2 id="如何用-Redis-实现分布式锁的？"><a href="#如何用-Redis-实现分布式锁的？" class="headerlink" title="如何用 Redis 实现分布式锁的？"></a>如何用 Redis 实现分布式锁的？</h2><p>Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：</p>
<p>如果 key 不存在，则显示插入成功，可以用来表示加锁成功；<br>如果 key 存在，则会显示插入失败，可以用来表示加锁失败。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET lock_key unique_value NX PX|EX 10000</span><br></pre></td></tr></table></figure>

<p>解锁的时候，要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放</span><br><span class="line">if redis.call(&quot;get&quot;,KEYS[1]) == ARGV[1] then</span><br><span class="line">    return redis.call(&quot;del&quot;,KEYS[1])</span><br><span class="line">else</span><br><span class="line">    return 0</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<p><strong>Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性</strong>，如果在 Redis 主节点获取到锁后，在没有同步到其他节点时，Redis 主节点宕机了，此时新的 Redis 主节点依然可以获取锁，所以多个应用服务就可以同时获取到锁。</p>
<h3 id="Redis-如何解决集群情况下分布式锁的可靠性？"><a href="#Redis-如何解决集群情况下分布式锁的可靠性？" class="headerlink" title="Redis 如何解决集群情况下分布式锁的可靠性？"></a>Redis 如何解决集群情况下分布式锁的可靠性？</h3><p>分布式锁算法 Redlock（红锁）,官方推荐是至少部署 5 个 Redis 节点，而且都是主节点，它们之间没有任何关系，都是一个个孤立的节点。</p>
<p>Redlock 算法的基本思路，是让客户端和多个独立的 Redis 节点依次请求申请加锁，如果客户端能够和半数以上的节点成功地完成加锁操作，那么我们就认为，客户端成功地获得分布式锁，否则加锁失败。<br>条件一：客户端从超过半数（大于等于 N&#x2F;2+1）的 Redis 节点上成功获取到了锁；<br>条件二：客户端从大多数节点获取锁的总耗时（t2-t1）小于锁设置的过期时间。</p>
<p>Redlock 算法加锁三个过程：</p>
<ol>
<li>客户端获取当前时间（t1）。</li>
<li>客户端按顺序依次向 N 个 Redis 节点执行加锁操作：<br>如果某个 Redis 节点发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，需要给「加锁操作」设置一个超时时间（<strong>不是对「锁」设置超时时间，而是对「加锁操作」设置超时时间</strong>），加锁操作的超时时间需要远远地小于锁的过期时间，一般也就是设置为几十毫秒。</li>
<li>一旦客户端从超过半数（大于等于 N&#x2F;2+1）的 Redis 节点上成功获取到了锁，就再次获取当前时间（t2），然后计算计算整个加锁过程的总耗时（t2-t1）。如果 t2-t1 &lt; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。</li>
</ol>
<p>加锁成功后，客户端需要重新计算这把锁的有效时间，计算的结果是「锁最初设置的过期时间」减去「客户端从大多数节点获取锁的总耗时（t2-t1）」。如果计算的结果已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况。</p>
<p>加锁失败后，客户端向所有 Redis 节点发起释放锁的操作，释放锁的操作和在单节点上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了。</p>
<link rel="stylesheet" href="/mybook.github.io/css/spoiler.css" type="text/css"><script src="/mybook.github.io/js/spoiler.js" type="text/javascript" async></script>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">徐川</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/mybook.github.io/archives/">
        
          <span class="site-state-item-count">5</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">徐川</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> 强力驱动
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/mybook.github.io/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="/mybook.github.io/lib/velocity/velocity.min.js"></script>
  <script src="/mybook.github.io/lib/velocity/velocity.ui.min.js"></script>

<script src="/mybook.github.io/js/utils.js"></script>

<script src="/mybook.github.io/js/motion.js"></script>


<script src="/mybook.github.io/js/schemes/muse.js"></script>


<script src="/mybook.github.io/js/next-boot.js"></script>




  




  
<script src="/mybook.github.io/js/local-search.js"></script>













  

  

</body>
</html>
